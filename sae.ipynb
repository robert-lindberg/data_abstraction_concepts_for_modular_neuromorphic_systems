{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d92a1ab",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1efbb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import typing as t\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import utils as utls\n",
    "from torch.profiler import profile, record_function, ProfilerActivity, schedule\n",
    "\n",
    "import snntorch as snn\n",
    "from snntorch import utils\n",
    "from snntorch import surrogate\n",
    "\n",
    "import tonic\n",
    "import tonic.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "import seaborn as sns\n",
    "import umap\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style='white', context='notebook', rc={'figure.figsize':(25,15)})\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f11183d",
   "metadata": {},
   "source": [
    "## 2. Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "189d3d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General settings\n",
    "base_path = 'E:/LTU/X7013E/'\n",
    "\n",
    "# Dataloader arguments\n",
    "batch_size = 64\n",
    "sensor_size = tonic.datasets.NMNIST.sensor_size\n",
    "cropped_size = (32, 32)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.CenterCrop(sensor_size=sensor_size, size=cropped_size),\n",
    "    transforms.ToFrame(sensor_size=(*cropped_size, 2), n_time_bins=32), #time_window=10000), # us to 1 ms\n",
    "    ])\n",
    "\n",
    "# Training data\n",
    "train_dataset = tonic.datasets.NMNIST(save_to=base_path + 'data/nmnist', transform=transform, train=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=tonic.collation.PadTensors(batch_first=True), shuffle=True)\n",
    "\n",
    "# Testing data\n",
    "#test_dataset = tonic.datasets.NMNIST(save_to=base_path + 'data/nmnist', train=False)\n",
    "#test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b312cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "\n",
    "# Used to find maximum batch size without overflowing the memory\n",
    "def get_max_batch_size(\n",
    "    model: nn.Module,\n",
    "    device: torch.device,\n",
    "    optimizer: torch.optim,\n",
    "    input_shape: t.Tuple[int, int, int],\n",
    "    output_shape: t.Tuple[int],\n",
    "    dataset_size: int,\n",
    "    max_batch_size: int = None,\n",
    "    num_iterations: int = 5,\n",
    ") -> int:\n",
    "    model.to(device)\n",
    "    model.train(True)\n",
    "\n",
    "    batch_size = 2\n",
    "    while True:\n",
    "        if max_batch_size is not None and batch_size >= max_batch_size:\n",
    "            batch_size = max_batch_size\n",
    "            break\n",
    "        if batch_size >= dataset_size:\n",
    "            batch_size = batch_size // 2\n",
    "            break\n",
    "        try:\n",
    "            for _ in range(num_iterations):\n",
    "                # dummy inputs and targets\n",
    "                inputs = torch.rand(*(batch_size, *input_shape), device=device)\n",
    "                targets = torch.rand(*(batch_size, *output_shape), device=device)\n",
    "                outputs = model(inputs)\n",
    "                loss = F.mse_loss(targets, outputs)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            batch_size *= 2\n",
    "        except RuntimeError:\n",
    "            batch_size //= 2\n",
    "            break\n",
    "    del model, optimizer\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f'Maximum batch size achieved: {batch_size}')\n",
    "    print('Remember to restart kernel before continuing to free up memory!')\n",
    "    \n",
    "    return batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92ff7305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting functions\n",
    "def plot_2d_hist(image_3d, frames=None):\n",
    "    \"\"\" Expect input image_3d in form of (channels, time/frames, y/rows, x/cols)\n",
    "        Frames variable expects a list of frames to show (no list = all frames)\n",
    "    \"\"\"\n",
    "    channels, depth, height, width = image_3d.shape\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=channels, figsize=(5*channels, 5))\n",
    "    ax[0].set_title(\"On-spikes\")\n",
    "    ax[1].set_title(\"Off-spikes\")\n",
    "    \n",
    "    for i in range(channels):\n",
    "        events = np.array(np.where(image_3d[i]==1.0))\n",
    "        \n",
    "        event_depth = np.array(events[0])\n",
    "        \n",
    "        if frames:\n",
    "            mask = np.zeros(event_depth.shape)\n",
    "            # Add all frame masks together\n",
    "            for frame in frames:\n",
    "                mask = np.add(mask, event_depth == frame).astype(bool)\n",
    "        else:\n",
    "            mask = np.ones(event_depth.shape).astype(bool)\n",
    "        \n",
    "        event_width = np.array(events[2])[mask]\n",
    "        event_height = np.array(events[1])[mask]\n",
    "        \n",
    "        data, x, y = np.histogram2d(event_width, event_height, bins=(32,32), range=([[0, width-1], [0, height-1]]))\n",
    "\n",
    "        plt.subplot(1, channels, i + 1)\n",
    "        plt.imshow(data.T)\n",
    "        \n",
    "def plot_3d_scatter(image_3d):\n",
    "    \"\"\" Expect input in form of (batches, channels, time, y/rows, x/cols)\n",
    "    \"\"\"\n",
    "    batch_size, channels, depth, height, width = image_3d.shape\n",
    "    \n",
    "    nrows = 25\n",
    "    ncols = int(np.ceil(batch_size/25))\n",
    "    \n",
    "    fig = plt.figure(figsize=(10*ncols, 5*nrows))\n",
    "    # Handle batches\n",
    "    for i in range(batch_size):\n",
    "        ax = fig.add_subplot(nrows, ncols, i+1, projection=\"3d\")\n",
    "        events = np.where(image_3d[i][0]==1.0)\n",
    "        \n",
    "        event_width = events[2]\n",
    "        event_height = events[1]\n",
    "        event_depth = events[0]\n",
    "\n",
    "        ax.scatter(event_width, event_depth, event_height, marker=\".\", c=event_depth, cmap=\"tab10\")\n",
    "        #ax.set_title(f\"Digit {label}\")\n",
    "        ax.set_title(f\"Batch {i+1}\")\n",
    "        ax.set_xlabel(\"x\")\n",
    "        ax.set_ylabel(\"Time [s]\")\n",
    "        ax.set_zlabel(\"y\")\n",
    "        \n",
    "        ax.set_xlim(0, width)\n",
    "        ax.set_ylim(0, depth)\n",
    "        ax.set_zlim(0, height)\n",
    "        ax.invert_zaxis()\n",
    "        #print(f\"Digit {index} is represented by {len(events)} events\")\n",
    "        break\n",
    "    \n",
    "    plt.tight_layout()  # Adjust subplot layout to prevent overlapping\n",
    "    plt.show()\n",
    "    \n",
    "def animate_plot(images_3d):\n",
    "    \"\"\" Expect input in form of a list of images with\n",
    "        format per image as (channels, time/frames, y/rows, x/cols)\n",
    "    \"\"\"\n",
    "    n_images = len(images_3d)\n",
    "    n_channels = images_3d[0].shape[0]\n",
    "    n_frames = images_3d[0].shape[1]\n",
    "    fig, ax = plt.subplots(nrows=n_channels, ncols=n_images, figsize=(5*n_images, 10))\n",
    "        \n",
    "    def animate(frame):\n",
    "        for i, image_3d in enumerate(images_3d):\n",
    "            channels, depth, height, width = image_3d.shape\n",
    "            events_pos = np.array(np.where(image_3d[0] >= 0.5))\n",
    "            events_neg = np.array(np.where(image_3d[1] >= 0.5))\n",
    "    \n",
    "            # On-spikes\n",
    "            mask = events_pos[0] == frame # depth\n",
    "            x = events_pos[2][mask] # width\n",
    "            y = events_pos[1][mask] # height\n",
    "            data, _, _ = np.histogram2d(x, y, bins=(width,height), range=([[0, width-1], [0, height-1]]))\n",
    "            plt.subplot(n_channels, n_images, 1+i*n_channels)\n",
    "            plt.imshow(data.T)\n",
    "            plt.ylabel(\"On-spikes\")\n",
    "            \n",
    "            # Off-spikes\n",
    "            mask = events_neg[0] == frame # depth\n",
    "            x = events_neg[2][mask] # width\n",
    "            y = events_neg[1][mask] # height  \n",
    "            data, _, _ = np.histogram2d(x, y, bins=(width,height), range=([[0, width-1], [0, height-1]])) \n",
    "            plt.subplot(n_channels, n_images, 2+i*n_channels)\n",
    "            plt.imshow(data.T)\n",
    "            plt.ylabel(\"Off-spikes\")\n",
    "\n",
    "    ani = animation.FuncAnimation(fig=fig, func=animate, frames=n_frames)\n",
    "    return ani\n",
    "\n",
    "# Encode data and collect latent representations\n",
    "# !!! Need some fixing !!!\n",
    "def plot_latent_dim(net, dataloader):\n",
    "    latent_data = []\n",
    "    latent_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels) in enumerate(dataloader):\n",
    "            images = images.permute(0, 2, 1, 3, 4).to(device) # Swap channel and depth pos\n",
    "            encoded = net.forward_encode(images)\n",
    "            latent_data.append(encoded)\n",
    "            latent_labels.append(labels)\n",
    "            if batch_idx >= 10:\n",
    "                break\n",
    "                   \n",
    "    latent_data = torch.cat(latent_data, dim=0).to('cpu').numpy()\n",
    "    print(latent_data.shape)\n",
    "    latent_labels = torch.cat(latent_labels, dim=0).to('cpu').numpy()\n",
    "    \n",
    "    # Apply UMAP to reduce dimensionality\n",
    "    latent_data_flattened = latent_data.reshape(latent_data.shape[0], -1)     \n",
    "    reducer = umap.UMAP()\n",
    "    embedding = reducer.fit_transform(latent_data_flattened)\n",
    "    \n",
    "    plt.scatter(embedding[:, 0], embedding[:, 1], c=latent_labels, cmap='Spectral', s=5)\n",
    "    plt.gca().set_aspect('equal', 'datalim')\n",
    "    plt.colorbar(boundaries=np.arange(11)-0.5).set_ticks(np.arange(10))\n",
    "    plt.title('UMAP projection of AE latent layer', fontsize=24)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de519255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for events, labels in train_loader:\\n    output = events.permute(0, 2, 1, 3, 4)\\n    break\\n\\nimages = [output[0]] # Select one image from batch\\n\\n# Plot image\\nplot_2d_hist(output[0]) # \\nplot_3d_scatter(output)\\n\\n#ani = animate_plot(images)\\n#HTML(ani.to_jshtml()) # Required for interactive animation in notebook\\n#ani.save(filename=base_path + f\\'figures/training/test.html\\', writer=\"html\")'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch one batch of events from dataloader\n",
    "'''for events, labels in train_loader:\n",
    "    output = events.permute(0, 2, 1, 3, 4)\n",
    "    break\n",
    "\n",
    "images = [output[0]] # Select one image from batch\n",
    "\n",
    "# Plot image\n",
    "plot_2d_hist(output[0]) # \n",
    "plot_3d_scatter(output)\n",
    "\n",
    "#ani = animate_plot(images)\n",
    "#HTML(ani.to_jshtml()) # Required for interactive animation in notebook\n",
    "#ani.save(filename=base_path + f'figures/training/test.html', writer=\"html\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2db8162",
   "metadata": {},
   "source": [
    "## 3. SAE Models:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9632032",
   "metadata": {},
   "source": [
    "#### Fully connected layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7daa238e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAE_FC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(2*34*34, 128),\n",
    "            #nn.BatchNorm2d(32),\n",
    "            snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True, threshold=thresh),\n",
    "            #nn.Linear(128, 64),\n",
    "            #nn.BatchNorm2d(64),\n",
    "            #snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True, threshold=thresh),\n",
    "            #nn.Linear(64, 32),\n",
    "            #nn.BatchNorm2d(128),\n",
    "            #snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True, threshold=thresh),\n",
    "            nn.Linear(128, 16), #this needs to be the final layer output size (channels * pixels * pixels)\n",
    "            snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True, output=True, threshold=thresh)\n",
    "            )\n",
    "\n",
    "        #Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(16, 128),\n",
    "            #nn.BatchNorm2d(64),\n",
    "            snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True, threshold=thresh),\n",
    "            #nn.Linear(32, 64),\n",
    "            #nn.BatchNorm2d(32),\n",
    "            #snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True, threshold=thresh),\n",
    "            #nn.Linear(64, 128),\n",
    "            #snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True, threshold=thresh),\n",
    "            nn.Linear(128, 2*34*34),\n",
    "            snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True, output=True,threshold=20000), #make large so membrane can be trained\n",
    "            )\n",
    "        \n",
    "    def forward(self, x): #Dimensions: [Batch,Channels,Width,Length]\n",
    "        utils.reset(self.encoder) #need to reset the hidden states of LIF \n",
    "        utils.reset(self.decoder)\n",
    "        #utils.reset(self.linearNet)\n",
    "        #print(f'x shape: {x.shape}')\n",
    "        num_steps = x.shape[0]\n",
    "\n",
    "        spk_mem=[]; spk_rec=[]; encoded_x=[]\n",
    "        spk_mem2=[]; spk_rec2=[]; decoded_x=[]\n",
    "        \n",
    "        for step in range(num_steps): #for t in time\n",
    "            #encode\n",
    "            spk_x, mem_x = self.encode(x[step]) #Output spike trains and neuron membrane states\n",
    "            spk_rec.append(spk_x) \n",
    "            spk_mem.append(mem_x)\n",
    "            \n",
    "            #decode\n",
    "            x_recon, x_mem_recon = self.decode(spk_x)\n",
    "            spk_rec2.append(x_recon)\n",
    "            spk_mem2.append(x_mem_recon)\n",
    "                     \n",
    "        spk_rec=torch.stack(spk_rec, dim=0)\n",
    "        spk_mem=torch.stack(spk_mem, dim=0) # Dimensions:[Time, Batch, Channels]\n",
    "        \n",
    "        spk_rec2=torch.stack(spk_rec2, dim=0)\n",
    "        spk_mem2=torch.stack(spk_mem2, dim=0) # Dimensions:[Time, Batch, Channels]\n",
    "        \n",
    "        out = spk_mem2#[:,:,:,:,-1] #return the membrane potential of the output neuron at t = -1 (last t)\n",
    "        return out #Dimensions:[Batch,Channels,Width,Length]\n",
    "\n",
    "    def encode(self, x):\n",
    "        spk_latent_x, mem_latent_x = self.encoder(x) \n",
    "        return spk_latent_x, mem_latent_x\n",
    "\n",
    "    def decode(self, x):\n",
    "        #spk_x,mem_x = self.linearNet(x) #convert latent dimension back to total size of features in encoder final layer\n",
    "        spk_x2, mem_x2 = self.decoder(x)\n",
    "        return spk_x2, mem_x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "546dc6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fc(network, trainloader, optimizer, epoch): \n",
    "    \n",
    "    network = network.train()\n",
    "    train_loss_hist=[]\n",
    "    for batch_idx, (events, labels) in enumerate(trainloader):\n",
    "        events = events.to(device)\n",
    "        events_flattened = events.reshape(events.shape[0], events.shape[1], -1).to(device) # Image flattened so polarity, height and width (2, 34, 34)-> (2312)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        #Pass data into network, and return reconstructed image from Membrane Potential at t = -1\n",
    "        events_recon = network(events_flattened) #Dimensions passed in: [Timesteps, Batch_size, Flattened_image] \n",
    "        events_recon = events_recon.reshape(events.shape)\n",
    "        \n",
    "        #Calculate loss        \n",
    "        loss_val = F.mse_loss(events_recon, events)\n",
    "                \n",
    "        print(f'Train[{epoch}/{max_epoch}][{batch_idx}/{len(trainloader)}] Loss: {loss_val.item()}')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #Save reconstructed images every at the end of the epoch\n",
    "        if batch_idx == 10: #len(trainloader)-1:\n",
    "            events_for_image = events[99, :, :, :, :]\n",
    "            events_for_image_recon = events_recon[99, :, :, :, :]\n",
    "            utls.save_image((events_for_image + 1) / 2, base_path + f'figures/training/epoch{epoch}_finalbatch_inputs.png') \n",
    "            utls.save_image((events_for_image_recon + 1) / 2, base_path + f'figures/training/epoch{epoch}_finalbatch_recon.png')\n",
    "    return loss_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1016eafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(network, testloader, opti, epoch):\n",
    "    network=network.eval()\n",
    "    test_loss_hist=[]\n",
    "    with torch.no_grad(): #no gradient this time\n",
    "        for batch_idx, (real_img, labels) in enumerate(testloader):   \n",
    "            real_img = real_img.to(device)#\n",
    "            labels = labels.to(device)\n",
    "            x_recon = network(real_img)\n",
    "\n",
    "            loss_val = F.mse_loss(x_recon, real_img)\n",
    "\n",
    "            print(f'Test[{epoch}/{max_epoch}][{batch_idx}/{len(testloader)}]  Loss: {loss_val.item()}')#, RECONS: {recons_meter.avg}, DISTANCE: {dist_meter.avg}')\n",
    "                \n",
    "            if batch_idx == len(testloader)-1:\n",
    "                utls.save_image((real_img+1)/2, f'figures/testing/epoch{epoch}_finalbatch_inputs.png')\n",
    "                utls.save_image((x_recon+1)/2, f'figures/testing/epoch{epoch}_finalbatch_recons.png')\n",
    "    return loss_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698354f1",
   "metadata": {},
   "source": [
    "There are a couple of ways to calculate loss with spiking neural networks. Here, we are simply taking the membrane potential of the final fully-connected layer of neurons at the last time step ($t = 5$). \n",
    "\n",
    "Therefore, we only need to compare each original image with its corresponding decoded, reconstructed image once per epoch. We can also return the membrane potentials at each time step, and create t different versions of the reconstructed image, and then compare each of them with the original image and take the average loss. For those of you interested in this, you can replace the loss function above with something like this:\n",
    "\n",
    "(*note this will fail to run as we have not defined any of the variables yet, it is just here for illustrative purposes*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8384ee4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train_loss_hist=[]\\nloss_val = torch.zeros((1), dtype=dtype, device=device)\\nfor step in range(num_steps):\\n    loss_val += F.mse_loss(x_recon, real_img)\\ntrain_loss_hist.append(loss_val.item())\\navg_loss=loss_val/num_steps'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''train_loss_hist=[]\n",
    "loss_val = torch.zeros((1), dtype=dtype, device=device)\n",
    "for step in range(num_steps):\n",
    "    loss_val += F.mse_loss(x_recon, real_img)\n",
    "train_loss_hist.append(loss_val.item())\n",
    "avg_loss=loss_val/num_steps'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c92b65",
   "metadata": {},
   "source": [
    "#### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29f57f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model_path = self.create_folders()\n",
    "        \n",
    "        # Hyperparameters\n",
    "        #self.spike_grad = surrogate.atan(alpha=2.0)# alternate surrogate gradient fast_sigmoid(slope=25) \n",
    "        self.spike_grad = surrogate.fast_sigmoid(slope=25)\n",
    "        self.beta = 0.5 # Decay rate of neurons \n",
    "        self.num_steps = 5\n",
    "        self.latent_dim = 32 # Dimension of latent layer (how compressed we want the information)\n",
    "        self.thresh = 1 # Spiking threshold (lower = more spikes are let through)\n",
    "        \n",
    "        # Network layers are defined per specific network below\n",
    "        \n",
    "    def forward(self, x): #Dimensions: [Batch,Channels,Width,Length]\n",
    "        # Reset hidden states of LIF \n",
    "        utils.reset(self.encoder)\n",
    "        utils.reset(self.decoder)\n",
    "        utils.reset(self.linearNet) \n",
    "        \n",
    "        # Encode\n",
    "        spk_mem = []\n",
    "        spk_rec = []\n",
    "        for step in range(self.num_steps): # For t in time\n",
    "            spk_x, mem_x = self.encode(x) # Output spike trains and neuron membrane states\n",
    "            spk_rec.append(spk_x) \n",
    "            spk_mem.append(mem_x)\n",
    "        spk_rec=torch.stack(spk_rec, dim=2)\n",
    "        spk_mem=torch.stack(spk_mem, dim=2) # Dimensions:[Batch, Channels, Width, Length, Time]\n",
    "        #spk_mem=torch.sum(spk_mem, dim=2) # Summing all spikes \n",
    "        #print(spk_mem.shape)\n",
    "        encoding = spk_mem[...,step].squeeze()\n",
    "        \n",
    "        # Decode\n",
    "        spk_mem2=[]\n",
    "        spk_rec2=[]\n",
    "        for step in range(self.num_steps): #for t in time\n",
    "            x_recon, x_mem_recon = self.decode(spk_rec[...,step]) \n",
    "            spk_rec2.append(x_recon) \n",
    "            spk_mem2.append(x_mem_recon)\n",
    "        spk_rec2 = torch.stack(spk_rec2, dim=4)\n",
    "        spk_mem2 = torch.stack(spk_mem2, dim=4) # Dimensions:[Batch, Channels, Width, Length, Time]  \n",
    "        out = spk_mem2[:,:,:,:,-1] # Return the membrane potential of the output neuron at t = -1 (last t)\n",
    "        return out, encoding # Dimensions:[Batch, Channels, Width, Length]\n",
    "    \n",
    "    def forward_encode(self, x):\n",
    "        utils.reset(self.encoder) # Need to reset the hidden states of LIF\n",
    "        \n",
    "        # Encode\n",
    "        spk_mem = []\n",
    "        spk_rec = []\n",
    "        for step in range(self.num_steps): # For t in time\n",
    "            spk_x, mem_x = self.encode(x) #Output spike trains and neuron membrane states\n",
    "            spk_rec.append(spk_x) \n",
    "            spk_mem.append(mem_x)\n",
    "        spk_rec=torch.stack(spk_rec, dim=2).squeeze()\n",
    "        spk_mem=torch.stack(spk_mem, dim=2).squeeze() #Dimensions:[Batch, Channels, Width, Length, Time]\n",
    "        return spk_mem\n",
    "\n",
    "    def encode(self, x):\n",
    "        spk_latent_x, mem_latent_x = self.encoder(x) \n",
    "        return spk_latent_x, mem_latent_x\n",
    "\n",
    "    def decode(self, x):\n",
    "        spk_x, mem_x = self.linearNet(x) # Convert latent dimension back to total size of features in encoder final layer\n",
    "        spk_x2, mem_x2 = self.decoder(spk_x)\n",
    "        return spk_x2, mem_x2\n",
    "    \n",
    "    def train_net(self, trainloader, optimizer, max_batch, start_epoch, max_epoch, save_output=False, save_model=False):\n",
    "        self.train()\n",
    "        train_loss_hist= []\n",
    "        latent_data = []\n",
    "        latent_labels = []\n",
    "        for epoch in range(start_epoch, max_epoch):\n",
    "            for batch_idx, (real_img, labels) in enumerate(trainloader):\n",
    "                # Stop if max batches reached\n",
    "                if batch_idx >= max_batch:\n",
    "                    break\n",
    "                \n",
    "                real_img = self.preprocess_image(real_img).to(device)\n",
    "                \n",
    "                # Pass data into network, and return reconstructed image from Membrane Potential at t = -1\n",
    "                x_recon, encoding = self(real_img)\n",
    "                latent_data.append(encoding.detach())\n",
    "                latent_labels.append(labels)\n",
    "                \n",
    "                # Calculate loss        \n",
    "                loss = F.mse_loss(x_recon, real_img)\n",
    "                loss_val = loss.item()\n",
    "                train_loss_hist.append(loss_val)\n",
    "                        \n",
    "                print(f'Train[{epoch}/{max_epoch}][{batch_idx}/{len(trainloader)}] Loss: {loss_val}')\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                if (batch_idx == len(trainloader) - 1) and save_output:\n",
    "                #if (batch_idx == max_batch - 1) and save_output:\n",
    "                    # Save output\n",
    "                    self.save_output(real_img, x_recon, epoch, mode=\"training\")\n",
    "                    self.plot_umap(latent_data, latent_labels, epoch, mode=\"training\")\n",
    "\n",
    "                    # Store model\n",
    "                    if save_model:\n",
    "                        torch.save(self.state_dict(), f'{self.model_path}/models/epoch{epoch}.pth')               \n",
    "\n",
    "        return train_loss_hist\n",
    "    \n",
    "    def test_net(self, testloader, max_batch, start_epoch, max_epoch, save_output=False):\n",
    "        self.eval()\n",
    "        test_loss_hist= []\n",
    "        latent_data = []\n",
    "        latent_labels = []\n",
    "        with torch.no_grad():\n",
    "            for epoch in range(start_epoch, max_epoch):\n",
    "                for batch_idx, (real_img, labels) in enumerate(testloader):\n",
    "                    # Stop if max batches reached\n",
    "                    if batch_idx >= max_batch:\n",
    "                        break\n",
    "                \n",
    "                    real_img = self.preprocess_image(real_img).to(device)\n",
    "                    \n",
    "                    # Pass data into network, and return reconstructed image from Membrane Potential at t = -1\n",
    "                    x_recon, encoding = self(real_img)\n",
    "                    latent_data.append(encoding)\n",
    "                    latent_labels.append(labels)\n",
    "\n",
    "                    # Calculate loss        \n",
    "                    loss = F.mse_loss(x_recon, real_img)\n",
    "                    loss_val = loss.item()\n",
    "                    test_loss_hist.append(loss_val)\n",
    "\n",
    "                    print(f'Test[{epoch}/{max_epoch}][{batch_idx}/{len(testloader)}] Loss: {loss_val}')\n",
    "                        \n",
    "                    if (batch_idx == len(testloader) - 1) and save_output:\n",
    "                        # Save output\n",
    "                        self.save_output(real_img, x_recon, epoch, mode=\"testing\")\n",
    "                \n",
    "                # Plot latent layer\n",
    "                if save_output:\n",
    "                    self.plot_umap(latent_data, latent_labels, epoch, moce=\"testing\")\n",
    "        return loss_val\n",
    "    \n",
    "    # Encode data and collect latent representations\n",
    "    def plot_umap(self, data, labels, epoch, mode):                            \n",
    "        data = torch.cat(data, dim=0).to('cpu').numpy()\n",
    "        labels = torch.cat(labels, dim=0).to('cpu').numpy()\n",
    "        \n",
    "        # Apply UMAP to reduce dimensionality\n",
    "        reducer = umap.UMAP()\n",
    "        embedding = reducer.fit_transform(data)\n",
    "        \n",
    "        plt.scatter(embedding[:, 0], embedding[:, 1], c=labels, cmap='Spectral', s=10)\n",
    "        plt.gca().set_aspect('equal', 'datalim')\n",
    "        plt.colorbar(boundaries=np.arange(11)-0.5).set_ticks(np.arange(10))\n",
    "        plt.title('UMAP projection of AE latent layer', fontsize=24)\n",
    "        plt.savefig(f'{self.model_path}/figures/{mode}/UMAP_{epoch}.png')\n",
    "        plt.close()\n",
    "    \n",
    "    def create_folders(self):\n",
    "        # Create necessary folders in the specified base_path\n",
    "        model_path = f'{base_path}/{type(self).__name__}'\n",
    "        \n",
    "        if not os.path.isdir(f'{model_path}/figures/training'):\n",
    "            os.makedirs(f'{model_path}/figures/training')\n",
    "        if not os.path.isdir(f'{model_path}/figures/testing'):\n",
    "            os.makedirs(f'{model_path}/figures/testing')\n",
    "        if not os.path.isdir(f'{model_path}/models'):\n",
    "            os.makedirs(f'{model_path}/models')\n",
    "        \n",
    "        return model_path\n",
    "    \n",
    "    def preprocess_image(self, image):\n",
    "        # Define this for each network below\n",
    "        # If no preprocess is defined, do nothing\n",
    "        return image\n",
    "    \n",
    "    def save_output(self, real_img, x_recon, epoch):\n",
    "        # Define this for each network below\n",
    "        # If no save output is defined, do nothing\n",
    "        pass\n",
    "    \n",
    "    def load_model(self, epoch):\n",
    "        try:\n",
    "            self.load_state_dict(torch.load(f'{self.model_path}/models/epoch{epoch}.pth'))\n",
    "        except FileNotFoundError:\n",
    "            print(\"Error: Model file not found.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71366054",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAE_2Dconv(SAE):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(nn.Conv2d(1, 32, 3, padding=1, stride=2),\n",
    "                          nn.BatchNorm2d(32),\n",
    "                          snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=True, threshold=self.thresh),\n",
    "                          nn.Conv2d(32, 64, 3, padding=1, stride=2),\n",
    "                          nn.BatchNorm2d(64),\n",
    "                          snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=True, threshold=self.thresh),\n",
    "                          nn.Conv2d(64, 128, 3, padding=1, stride=2),\n",
    "                          nn.BatchNorm2d(128),\n",
    "                          snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=True, threshold=self.thresh),\n",
    "                          nn.Flatten(start_dim = 1, end_dim = 3),\n",
    "                          nn.Linear(128*4*4, self.latent_dim), #this needs to be the final layer output size (channels * pixels * pixels)\n",
    "                          snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=True, output=True, threshold=self.thresh)\n",
    "                          )\n",
    "        # From latent back to tensor for convolution\n",
    "        self.linearNet= nn.Sequential(nn.Linear(self.latent_dim, 128*4*4),\n",
    "                               snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=True, output=True,threshold=self.thresh))        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(nn.Unflatten(1, (128, 4, 4)), \n",
    "                          snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=True, threshold=self.thresh),\n",
    "                          nn.ConvTranspose2d(128, 64, 3, padding=1, stride=(2,2), output_padding=1),\n",
    "                          nn.BatchNorm2d(64),\n",
    "                          snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=True, threshold=self.thresh),\n",
    "                          nn.ConvTranspose2d(64, 32, 3, padding=1, stride=(2,2), output_padding=1),\n",
    "                          nn.BatchNorm2d(32),\n",
    "                          snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=True, threshold=self.thresh),\n",
    "                          nn.ConvTranspose2d(32, 1, 3, padding=1, stride=(2,2), output_padding=1),\n",
    "                          snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=True, output=True, threshold=20000) #make large so membrane can be trained\n",
    "                          )\n",
    "    \n",
    "    def preprocess_image(self, image):\n",
    "        # Data returned as: [Batch_size, Channels, Image_Height, Image_Width]\n",
    "        return image[:,0,0,:,:].unsqueeze(1)\n",
    "    \n",
    "    def save_output(self, real_img, x_recon, epoch, mode):\n",
    "        #Save reconstructed images every at the end of the epoch\n",
    "        # NOTE: you need to create training/ and testing/ folders in your chosen path\n",
    "            utls.save_image((real_img + 1) / 2, f'{self.model_path}/figures/{mode}/epoch{epoch}_finalbatch_inputs.png')\n",
    "            utls.save_image((x_recon + 1) / 2, f'{self.model_path}/figures/{mode}/epoch{epoch}_finalbatch_recon.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6edba10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAE_2DconvTT(SAE):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(nn.Conv2d(2, 32, 3, padding=1, stride=2),\n",
    "                          nn.BatchNorm2d(32),\n",
    "                          snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=True, threshold=self.thresh),\n",
    "                          nn.Conv2d(32, 64, 3, padding=1, stride=2),\n",
    "                          nn.BatchNorm2d(64),\n",
    "                          snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=True, threshold=self.thresh),\n",
    "                          nn.Conv2d(64, 128, 3, padding=1, stride=2),\n",
    "                          nn.BatchNorm2d(128),\n",
    "                          snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=True, threshold=self.thresh),\n",
    "                          nn.Flatten(start_dim = 1, end_dim = 3),\n",
    "                          nn.Linear(128*4*4, self.latent_dim), #this needs to be the final layer output size (channels * pixels * pixels)\n",
    "                          snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=True, output=True, threshold=self.thresh)\n",
    "                          )\n",
    "        # From latent back to tensor for convolution\n",
    "        self.linearNet= nn.Sequential(nn.Linear(self.latent_dim, 128*4*4),\n",
    "                               snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=True, output=True,threshold=self.thresh))        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(nn.Unflatten(1, (128, 4, 4)), \n",
    "                          snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=True, threshold=self.thresh),\n",
    "                          nn.ConvTranspose2d(128, 64, 3, padding=1, stride=(2,2), output_padding=1),\n",
    "                          nn.BatchNorm2d(64),\n",
    "                          snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=True, threshold=self.thresh),\n",
    "                          nn.ConvTranspose2d(64, 32, 3, padding=1, stride=(2,2), output_padding=1),\n",
    "                          nn.BatchNorm2d(32),\n",
    "                          snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=True, threshold=self.thresh),\n",
    "                          nn.ConvTranspose2d(32, 2, 3, padding=1, stride=(2,2), output_padding=1),\n",
    "                          snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=True, output=True, threshold=20000) #make large so membrane can be trained\n",
    "                          )\n",
    "        \n",
    "    def train_net(self, trainloader, optimizer, max_batch, start_epoch, max_epoch, save_output=False, save_model=False):\n",
    "        self.train()\n",
    "        train_loss_hist= []\n",
    "        latent_data = []\n",
    "        latent_labels = []\n",
    "        for epoch in range(start_epoch, max_epoch):\n",
    "            for batch_idx, (real_img, labels) in enumerate(trainloader):\n",
    "                # Stop if max batches reached\n",
    "                if batch_idx >= max_batch:\n",
    "                    break\n",
    "                \n",
    "                real_img = self.preprocess_image(real_img).to(device)\n",
    "                \n",
    "                frames_recon = []\n",
    "                for i in range(real_img.shape[2]):\n",
    "                    # Pass data into network, and return reconstructed image from Membrane Potential at t = -1\n",
    "                    frame = real_img[:,:,i,:,:]                \n",
    "                    frame_recon, encoding = self(frame)\n",
    "                    frames_recon.append(frame_recon)\n",
    "                    \n",
    "                    latent_data.append(encoding.detach())\n",
    "                    latent_labels.append(labels)\n",
    "                \n",
    "                #x_recon.unsqueeze(2)\n",
    "                x_recon = torch.stack(frames_recon, dim=2)\n",
    "                    \n",
    "                # Calculate loss        \n",
    "                loss = F.mse_loss(x_recon, real_img)\n",
    "                loss_val = loss.item()\n",
    "                train_loss_hist.append(loss_val)\n",
    "                        \n",
    "                print(f'Train[{epoch}/{max_epoch}][{batch_idx}/{len(trainloader)}] Loss: {loss_val}')\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                if (batch_idx == len(trainloader) - 1) and save_output:\n",
    "                #if (batch_idx == max_batch - 1) and save_output:\n",
    "                    # Save output\n",
    "                    self.save_output(real_img, x_recon, epoch, mode=\"training\")\n",
    "                    self.plot_umap(latent_data, latent_labels, epoch, mode=\"training\")\n",
    "\n",
    "            # Store model\n",
    "            if save_model:\n",
    "                torch.save(self.state_dict(), f'{self.model_path}/models/epoch{epoch}.pth')               \n",
    "\n",
    "        return train_loss_hist\n",
    "    \n",
    "    def preprocess_image(self, image):\n",
    "        # Data returned as: [Batch_size, Channels, Image_Depth, Image_Height, Image_Width]\n",
    "        return image.permute(0, 2, 1, 3, 4)\n",
    "    \n",
    "    def save_output(self, real_img, x_recon, epoch, mode):\n",
    "        # Save animation of one digit at the end of each epoch\n",
    "        images = [real_img[0].cpu(), x_recon[0].cpu()]\n",
    "        ani = animate_plot(images)\n",
    "        #HTML(ani.to_jshtml())\n",
    "        ani.save(filename=f'{self.model_path}/figures/{mode}/epoch{epoch}_image0.html', writer=\"html\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a9c0faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAE_3Dconv(SAE):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(nn.Conv3d(2, 32, 3, padding=1, stride=2),\n",
    "                          nn.BatchNorm3d(32),\n",
    "                          snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=True, threshold=self.thresh),\n",
    "                          nn.Conv3d(32, 64, 3, padding=1,stride=2),\n",
    "                          nn.BatchNorm3d(64),\n",
    "                          snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=True, threshold=self.thresh),\n",
    "                          nn.Conv3d(64, 128, 3, padding=1,stride=2),\n",
    "                          nn.BatchNorm3d(128),\n",
    "                          snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=True, threshold=self.thresh),\n",
    "                          nn.Flatten(start_dim = 1, end_dim = 4),\n",
    "                          nn.Linear(128*4*4*4, self.latent_dim), #this needs to be the final layer output size (channels * pixels * pixels)\n",
    "                          snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=True, output=True, threshold=self.thresh)\n",
    "                          )\n",
    "        # From latent back to tensor for convolution\n",
    "        self.linearNet= nn.Sequential(nn.Linear(self.latent_dim, 128*4*4*4),\n",
    "                               snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=True, output=True,threshold=self.thresh))        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(nn.Unflatten(1, (128, 4, 4, 4)), \n",
    "                          snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=True, threshold=self.thresh),\n",
    "                          nn.ConvTranspose3d(128, 64, 3, padding=1, stride=(2,2,2), output_padding=1),\n",
    "                          nn.BatchNorm3d(64),\n",
    "                          snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=True, threshold=self.thresh),\n",
    "                          nn.ConvTranspose3d(64, 32, 3, padding=1, stride=(2,2,2), output_padding=1),\n",
    "                          nn.BatchNorm3d(32),\n",
    "                          snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=True, threshold=self.thresh),\n",
    "                          nn.ConvTranspose3d(32, 2, 3, padding=1, stride=(2,2,2), output_padding=1),\n",
    "                          snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=True, output=True, threshold=20000) #make large so membrane can be trained\n",
    "                          )\n",
    "        \n",
    "    def preprocess_image(self, image):\n",
    "        # Data returned as: [Batch_size, Channels, Image_Depth, Image_Height, Image_Width]\n",
    "        return image.permute(0, 2, 1, 3, 4)\n",
    "    \n",
    "    def save_output(self, real_img, x_recon, epoch, mode):\n",
    "        # Save animation of one digit at the end of each epoch\n",
    "        images = [real_img[0].cpu(), x_recon[0].cpu()]\n",
    "        ani = animate_plot(images)\n",
    "        #HTML(ani.to_jshtml())\n",
    "        ani.save(filename=f'{self.model_path}/figures/{mode}/epoch{epoch}_image0.html', writer=\"html\")\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8762cacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAE_3DconvTT(SAE):\n",
    "    def __init__(self):\n",
    "        super().__init__()    \n",
    "        # Encoder\n",
    "        self.conv1 = nn.Conv3d(2, 32, 3, padding=1, stride=2)\n",
    "        self.bn1 = nn.ModuleList([nn.BatchNorm3d(32) for i in range(self.num_steps)])\n",
    "        self.lif1 = snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=False, threshold=self.thresh)\n",
    "        self.conv2 = nn.Conv3d(32, 64, 3, padding=1, stride=2)\n",
    "        self.bn2 = nn.ModuleList([nn.BatchNorm3d(64) for i in range(self.num_steps)])\n",
    "        self.lif2 = snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=False, threshold=self.thresh)\n",
    "        self.conv3 = nn.Conv3d(64, 128, 3, padding=1, stride=2)\n",
    "        self.bn3 = nn.ModuleList([nn.BatchNorm3d(128) for i in range(self.num_steps)])\n",
    "        self.lif3 = snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=False, threshold=self.thresh)\n",
    "        self.flatten = nn.Flatten(start_dim = 1, end_dim = 4)\n",
    "        self.fc1 = nn.Linear(128*4*4*4, self.latent_dim) #this needs to be the final layer output size (channels * pixels * pixels)\n",
    "        self.lif4 = snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=False, output=True, threshold=self.thresh)\n",
    "        \n",
    "        # From latent back to tensor for convolution\n",
    "        self.fc2 = nn.Linear(self.latent_dim, 128*4*4*4)\n",
    "        self.lif5 = snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=False, output=True, threshold=self.thresh)\n",
    "             \n",
    "        # Decoder\n",
    "        self.unflatten = nn.Unflatten(1, (128, 4, 4, 4))\n",
    "        self.lif6 = snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=False, threshold=self.thresh)\n",
    "        self.convT1 = nn.ConvTranspose3d(128, 64, 3, padding=1, stride=(2,2,2), output_padding=1)\n",
    "        self.bn4 = nn.ModuleList([nn.BatchNorm3d(64) for i in range(self.num_steps)])\n",
    "        self.lif7 = snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=False, threshold=self.thresh)\n",
    "        self.convT2 = nn.ConvTranspose3d(64, 32, 3, padding=1, stride=(2,2,2), output_padding=1)\n",
    "        self.bn5 = nn.ModuleList([nn.BatchNorm3d(32) for i in range(self.num_steps)])\n",
    "        self.lif8 = snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=False, threshold=self.thresh)\n",
    "        self.convT3 = nn.ConvTranspose3d(32, 2, 3, padding=1, stride=(2,2,2), output_padding=1)\n",
    "        self.lif9 = snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=False, output=True, threshold=20000) #make large so membrane can be trained\n",
    "        \n",
    "        self.lif_list = [self.lif1, self.lif2, self.lif3, self.lif4, self.lif5, self.lif6, self.lif7, self.lif8, self.lif9]\n",
    "        self.bn_list = [self.bn1, self.bn2, self.bn3, self.bn4, self.bn5]\n",
    "        \n",
    "        self.apply(self._init_weights)\n",
    "     \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=1.0)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "    \n",
    "    def forward(self, x): #Dimensions: [Batch,Channels,Width,Length]\n",
    "        # Reset hidden states of LIF\n",
    "        mem1 = self.lif1.init_leaky() # reset/init hidden states at t=0\n",
    "        mem2 = self.lif2.init_leaky() # reset/init hidden states at t=0\n",
    "        mem3 = self.lif1.init_leaky() # reset/init hidden states at t=0\n",
    "        mem4 = self.lif2.init_leaky() # reset/init hidden states at t=0\n",
    "        mem5 = self.lif1.init_leaky() # reset/init hidden states at t=0\n",
    "        mem6 = self.lif2.init_leaky() # reset/init hidden states at t=0\n",
    "        mem7 = self.lif1.init_leaky() # reset/init hidden states at t=0\n",
    "        mem8 = self.lif2.init_leaky() # reset/init hidden states at t=0\n",
    "        mem9 = self.lif1.init_leaky() # reset/init hidden states at t=0\n",
    "        \n",
    "        # Encode\n",
    "        spk_mem = []\n",
    "        spk_rec = []\n",
    "        for step in range(self.num_steps): # For t in time\n",
    "            # Encoder\n",
    "            cur1 = self.conv1(x)\n",
    "            cur1 = self.bn1[step](cur1)\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.conv2(spk1)\n",
    "            cur2 = self.bn2[step](cur2)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            cur3 = self.conv3(spk2)\n",
    "            cur3 = self.bn3[step](cur3)\n",
    "            spk3, mem3 = self.lif3(cur3, mem3)\n",
    "            spk3 = self.flatten(spk3)\n",
    "            cur4 = self.fc1(spk3)\n",
    "            spk_enc, mem_enc = self.lif4(cur4, mem4) # Output spike trains and neuron membrane states\n",
    "            \n",
    "            spk_rec.append(spk_enc)\n",
    "            spk_mem.append(mem_enc)\n",
    "            \n",
    "        spk_rec=torch.stack(spk_rec, dim=2)\n",
    "        spk_mem=torch.stack(spk_mem, dim=2) # Dimensions:[Batch, Channels, Width, Length, Time]\n",
    "        \n",
    "        encoding = spk_mem[...,step].squeeze()\n",
    "        \n",
    "        # Decode\n",
    "        spk_mem2=[]\n",
    "        spk_rec2=[]\n",
    "        for step in range(self.num_steps): #for t in time\n",
    "            # Latent\n",
    "            cur5 = self.fc2(spk_rec[...,step])\n",
    "            spk5, mem5 = self.lif5(cur5, mem5)\n",
    "            \n",
    "            # Decoder\n",
    "            cur6 = self.unflatten(spk5)\n",
    "            spk6, mem6 = self.lif6(cur6, mem6)\n",
    "            cur7 = self.convT1(spk6)\n",
    "            cur7 = self.bn4[step](cur7)\n",
    "            spk7, mem7 = self.lif7(cur7, mem7)\n",
    "            cur8 = self.convT2(spk7)\n",
    "            cur8 = self.bn5[step](cur8)\n",
    "            spk8, mem8 = self.lif8(cur8, mem8)\n",
    "            cur9 = self.convT3(spk8)\n",
    "            spk9, mem9 = self.lif9(cur9, mem9) #make large so membrane can be trained\n",
    "            \n",
    "            spk_rec2.append(spk9) \n",
    "            spk_mem2.append(mem9)\n",
    "        spk_rec2 = torch.stack(spk_rec2, dim=4)\n",
    "        spk_mem2 = torch.stack(spk_mem2, dim=4) # Dimensions:[Batch, Channels, Width, Length, Time]  \n",
    "        out = spk_mem2[:,:,:,:,-1] # Return the membrane potential of the output neuron at t = -1 (last t)\n",
    "        return out, encoding # Dimensions:[Batch, Channels, Width, Length]\n",
    "        \n",
    "    def preprocess_image(self, image):\n",
    "        # Data returned as: [Batch_size, Channels, Image_Depth, Image_Height, Image_Width]\n",
    "        return image.permute(0, 2, 1, 3, 4)\n",
    "    \n",
    "    def save_output(self, real_img, x_recon, epoch, mode):\n",
    "        # Save animation of one digit at the end of each epoch\n",
    "        images = [real_img[0].cpu(), x_recon[0].cpu()]\n",
    "        ani = animate_plot(images)\n",
    "        #HTML(ani.to_jshtml())\n",
    "        ani.save(filename=f'{self.model_path}/figures/{mode}/epoch{epoch}_image0.html', writer=\"html\")\n",
    "        plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f69defa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAE_2DconvTT(SAE):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.num_time_steps = 32\n",
    "        \n",
    "        # Encoder\n",
    "        self.conv1 = nn.Conv2d(2, 32, 3, padding=1, stride=2)\n",
    "        self.bn1 = nn.ModuleList([nn.BatchNorm2d(32) for i in range(self.num_time_steps)])\n",
    "        self.lif1 = snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=False, threshold=self.thresh)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1, stride=2)\n",
    "        self.bn2 = nn.ModuleList([nn.BatchNorm2d(64) for i in range(self.num_time_steps)])\n",
    "        self.lif2 = snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=False, threshold=self.thresh)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1, stride=2)\n",
    "        self.bn3 = nn.ModuleList([nn.BatchNorm2d(128) for i in range(self.num_time_steps)])\n",
    "        self.lif3 = snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=False, threshold=self.thresh)\n",
    "        self.flatten = nn.Flatten(start_dim = 1, end_dim = 3)\n",
    "        self.fc1 = nn.Linear(128*4*4, self.latent_dim) #this needs to be the final layer output size (channels * pixels * pixels)\n",
    "        self.lif4 = snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=False, output=True, threshold=self.thresh)\n",
    "        \n",
    "        # From latent back to tensor for convolution\n",
    "        self.fc2 = nn.Linear(self.latent_dim, 128*4*4)\n",
    "        self.lif5 = snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=False, output=True, threshold=self.thresh)\n",
    "        \n",
    "        # Decoder\n",
    "        self.unflatten = nn.Unflatten(1, (128, 4, 4))\n",
    "        self.lif6 = snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=False, threshold=self.thresh)\n",
    "        self.convT1 = nn.ConvTranspose2d(128, 64, 3, padding=1, stride=(2,2), output_padding=1)\n",
    "        self.bn4 = nn.ModuleList([nn.BatchNorm2d(64) for i in range(self.num_time_steps)])\n",
    "        self.lif7 = snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=False, threshold=self.thresh)\n",
    "        self.convT2 = nn.ConvTranspose2d(64, 32, 3, padding=1, stride=(2,2), output_padding=1)\n",
    "        self.bn5 = nn.ModuleList([nn.BatchNorm2d(32) for i in range(self.num_time_steps)])\n",
    "        self.lif8 = snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=False, threshold=self.thresh)\n",
    "        self.convT3 = nn.ConvTranspose2d(32, 2, 3, padding=1, stride=(2,2), output_padding=1)\n",
    "        self.lif9 = snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=False, output=True, threshold=1) #make large so membrane can be trained\n",
    "        \n",
    "        self.lif_list = [self.lif1, self.lif2, self.lif3, self.lif4, self.lif5, self.lif6, self.lif7, self.lif8, self.lif9]\n",
    "        self.bn_list = [self.bn1, self.bn2, self.bn3, self.bn4, self.bn5]\n",
    "    \n",
    "    \n",
    "    def forward(self, x): #Dimensions: [Batch,Channels,Width,Length]\n",
    "        # Reset hidden states of LIF\n",
    "        mem1 = self.lif1.init_leaky() # reset/init hidden states at t=0\n",
    "        mem2 = self.lif2.init_leaky() # reset/init hidden states at t=0\n",
    "        mem3 = self.lif3.init_leaky() # reset/init hidden states at t=0\n",
    "        mem4 = self.lif4.init_leaky() # reset/init hidden states at t=0\n",
    "        mem5 = self.lif5.init_leaky() # reset/init hidden states at t=0\n",
    "        mem6 = self.lif6.init_leaky() # reset/init hidden states at t=0\n",
    "        mem7 = self.lif7.init_leaky() # reset/init hidden states at t=0\n",
    "        mem8 = self.lif8.init_leaky() # reset/init hidden states at t=0\n",
    "        mem9 = self.lif9.init_leaky() # reset/init hidden states at t=0\n",
    "        \n",
    "        # Encode\n",
    "        spk_mem = []\n",
    "        spk_rec = []\n",
    "        for step in range(self.num_time_steps):\n",
    "            # Pass data into network, and return reconstructed image from Membrane Potential at t = -1\n",
    "            cur1 = self.conv1(x[:,:,step,:,:]) # Get frame by frame\n",
    "            cur1 = self.bn1[step](cur1)\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.conv2(spk1)\n",
    "            cur2 = self.bn2[step](cur2)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            cur3 = self.conv3(spk2)\n",
    "            cur3 = self.bn3[step](cur3)\n",
    "            spk3, mem3 = self.lif3(cur3, mem3)\n",
    "            spk3 = self.flatten(spk3)\n",
    "            cur4 = self.fc1(spk3)\n",
    "            spk_enc, mem_enc = self.lif4(cur4, mem4) # Output spike trains and neuron membrane states\n",
    "            spk_rec.append(spk_enc)\n",
    "            spk_mem.append(mem_enc)\n",
    "        \n",
    "        spk_rec=torch.stack(spk_rec, dim=2)\n",
    "        spk_mem=torch.stack(spk_mem, dim=2) # Dimensions:[Batch, Channels, Width, Length, Time]\n",
    "        \n",
    "        encoding = spk_mem #[...,step].squeeze()\n",
    "        \n",
    "        # Decode\n",
    "        spk_mem2=[]\n",
    "        spk_rec2=[]\n",
    "        for step in range(self.num_time_steps): # Get frame by frame\n",
    "            # Latent\n",
    "            cur5 = self.fc2(spk_rec[...,step])\n",
    "            spk5, mem5 = self.lif5(cur5, mem5)\n",
    "            \n",
    "            # Decoder\n",
    "            cur6 = self.unflatten(spk5)\n",
    "            spk6, mem6 = self.lif6(cur6, mem6)\n",
    "            cur7 = self.convT1(spk6)\n",
    "            cur7 = self.bn4[step](cur7)\n",
    "            spk7, mem7 = self.lif7(cur7, mem7)\n",
    "            cur8 = self.convT2(spk7)\n",
    "            cur8 = self.bn5[step](cur8)\n",
    "            spk8, mem8 = self.lif8(cur8, mem8)\n",
    "            cur9 = self.convT3(spk8)\n",
    "            spk9, mem9 = self.lif9(cur9, mem9) #make large so membrane can be trained\n",
    "            \n",
    "            spk_rec2.append(spk9) \n",
    "            spk_mem2.append(mem9)\n",
    "        spk_rec2 = torch.stack(spk_rec2, dim=4)\n",
    "        spk_mem2 = torch.stack(spk_mem2, dim=4) # Dimensions:[Batch, Channels, Width, Length, Time]  \n",
    "        out = spk_rec2 #[:,:,:,:,-1] # Return the membrane potential of the output neuron at t = -1 (last t)\n",
    "        return out, encoding # Dimensions:[Batch, Channels, Width, Length]\n",
    "    \n",
    "    def forward_encode(self, x): #Dimensions: [Batch,Channels,Width,Length]\n",
    "        # Reset hidden states of LIF\n",
    "        mem1 = self.lif1.init_leaky() # reset/init hidden states at t=0\n",
    "        mem2 = self.lif2.init_leaky() # reset/init hidden states at t=0\n",
    "        mem3 = self.lif1.init_leaky() # reset/init hidden states at t=0\n",
    "        mem4 = self.lif2.init_leaky() # reset/init hidden states at t=0\n",
    "        \n",
    "        # Encode\n",
    "        spk_mem = []\n",
    "        spk_rec = []\n",
    "        for step in range(self.num_time_steps):\n",
    "            # Pass data into network, and return reconstructed image from Membrane Potential at t = -1\n",
    "            cur1 = self.conv1(x[:,:,step,:,:]) # Get frame by frame\n",
    "            cur1 = self.bn1[step](cur1)\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.conv2(spk1)\n",
    "            cur2 = self.bn2[step](cur2)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            cur3 = self.conv3(spk2)\n",
    "            cur3 = self.bn3[step](cur3)\n",
    "            spk3, mem3 = self.lif3(cur3, mem3)\n",
    "            spk3 = self.flatten(spk3)\n",
    "            cur4 = self.fc1(spk3)\n",
    "            spk_enc, mem_enc = self.lif4(cur4, mem4) # Output spike trains and neuron membrane states\n",
    "            spk_rec.append(spk_enc)\n",
    "            spk_mem.append(mem_enc)\n",
    "        \n",
    "        spk_rec=torch.stack(spk_rec, dim=2)\n",
    "        spk_mem=torch.stack(spk_mem, dim=2) # Dimensions:[Batch, Channels, Width, Length, Time]\n",
    "        \n",
    "        encoding = spk_mem #[...,step].squeeze()\n",
    "        \n",
    "        return encoding\n",
    "    \n",
    "    def train_net(self, trainloader, optimizer, max_batch, start_epoch, max_epoch, save_output=False, save_model=False):\n",
    "        self.train()\n",
    "        train_loss_hist= []\n",
    "        latent_data = []\n",
    "        latent_labels = []\n",
    "        for epoch in range(start_epoch, max_epoch):\n",
    "            for batch_idx, (real_img, labels) in enumerate(trainloader):\n",
    "                # Stop if max batches reached\n",
    "                if batch_idx >= max_batch:\n",
    "                    break\n",
    "                \n",
    "                real_img = self.preprocess_image(real_img).to(device)\n",
    "                \n",
    "                # Pass data into network, and return reconstructed image from Membrane Potential at t = -1\n",
    "                x_recon, encoding = self(real_img)\n",
    "                latent_data.append(encoding.detach())\n",
    "                latent_labels.append(labels)\n",
    "                \n",
    "                # Calculate loss \n",
    "                train_loss_hist=[]\n",
    "                loss = torch.zeros((1), dtype=dtype, device=device)\n",
    "                for step in range(self.num_time_steps):\n",
    "                    loss += F.mse_loss(x_recon, real_img)\n",
    "                    \n",
    "                loss_val = loss.item()\n",
    "                train_loss_hist.append(loss_val)\n",
    "                avg_loss = loss_val/self.num_time_steps\n",
    "                        \n",
    "                print(f'Train[{epoch}/{max_epoch}][{batch_idx}/{len(trainloader)}] Loss: {avg_loss}')\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                if (batch_idx == len(trainloader) - 1) and save_output:\n",
    "                #if (batch_idx == max_batch - 1) and save_output:\n",
    "                    # Save output\n",
    "                    self.save_output(real_img, x_recon, epoch, mode=\"training\")\n",
    "                    #self.plot_umap(latent_data, latent_labels, epoch, mode=\"training\")\n",
    "\n",
    "                    # Store model\n",
    "                    if save_model:\n",
    "                        torch.save(self.state_dict(), f'{self.model_path}/models/epoch{epoch}.pth')               \n",
    "\n",
    "        return train_loss_hist\n",
    "        \n",
    "    def preprocess_image(self, image):\n",
    "        # Data returned as: [Batch_size, Channels, Image_Depth, Image_Height, Image_Width]\n",
    "        return image.permute(0, 2, 1, 3, 4)\n",
    "    \n",
    "    def save_output(self, real_img, x_recon, epoch, mode):\n",
    "        # Save animation of one digit at the end of each epoch\n",
    "        images = [real_img[0].cpu(), x_recon[0].cpu()]\n",
    "        ani = animate_plot(images)\n",
    "        #HTML(ani.to_jshtml())\n",
    "        ani.save(filename=f'{self.model_path}/figures/{mode}/epoch{epoch}_image0.html', writer=\"html\")\n",
    "        plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "634841bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAE_2DconvTT_small(SAE):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.num_time_steps = 32\n",
    "        \n",
    "        # Encoder\n",
    "        self.conv1 = nn.Conv2d(2, 16, 5, padding=2, stride=2)\n",
    "        self.bn1 = nn.ModuleList([nn.BatchNorm2d(16) for i in range(self.num_time_steps)])\n",
    "        self.lif1 = snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=False, threshold=self.thresh)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5, padding=2, stride=2)\n",
    "        self.bn2 = nn.ModuleList([nn.BatchNorm2d(32) for i in range(self.num_time_steps)])\n",
    "        self.lif2 = snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=False, threshold=self.thresh)\n",
    "        self.flatten = nn.Flatten(start_dim = 1, end_dim = 3)\n",
    "        self.fc1 = nn.Linear(32*8*8, self.latent_dim) #this needs to be the final layer output size (channels * pixels * pixels)\n",
    "        self.lif4 = snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=False, output=True, threshold=self.thresh)\n",
    "        \n",
    "        # From latent back to tensor for convolution\n",
    "        self.fc2 = nn.Linear(self.latent_dim, 32*8*8)\n",
    "        self.lif5 = snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=False, output=True, threshold=self.thresh)\n",
    "        \n",
    "        # Decoder\n",
    "        self.unflatten = nn.Unflatten(1, (32, 8, 8))\n",
    "        self.lif7 = snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=False, threshold=self.thresh)\n",
    "        self.convT2 = nn.ConvTranspose2d(32, 16, 5, padding=2, stride=(2,2), output_padding=1)\n",
    "        self.bn5 = nn.ModuleList([nn.BatchNorm2d(16) for i in range(self.num_time_steps)])\n",
    "        self.lif8 = snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=False, threshold=self.thresh)\n",
    "        self.convT3 = nn.ConvTranspose2d(16, 2, 5, padding=2, stride=(2,2), output_padding=1)\n",
    "        self.lif9 = snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=False, output=True, threshold=1) #make large so membrane can be trained\n",
    "        \n",
    "        self.lif_list = [self.lif1, self.lif2, self.lif4, self.lif5, self.lif7, self.lif8, self.lif9]\n",
    "        self.bn_list = [self.bn1, self.bn2, self.bn5]\n",
    "    \n",
    "    \n",
    "    def forward(self, x): #Dimensions: [Batch,Channels,Width,Length]\n",
    "        # Reset hidden states of LIF\n",
    "        mem1 = self.lif1.init_leaky() # reset/init hidden states at t=0\n",
    "        mem2 = self.lif2.init_leaky() # reset/init hidden states at t=0\n",
    "        mem4 = self.lif4.init_leaky() # reset/init hidden states at t=0\n",
    "        mem5 = self.lif5.init_leaky() # reset/init hidden states at t=0\n",
    "        mem7 = self.lif7.init_leaky() # reset/init hidden states at t=0\n",
    "        mem8 = self.lif8.init_leaky() # reset/init hidden states at t=0\n",
    "        mem9 = self.lif9.init_leaky() # reset/init hidden states at t=0\n",
    "        \n",
    "        # Encode\n",
    "        spk_mem = []\n",
    "        spk_rec = []\n",
    "        for step in range(self.num_time_steps):\n",
    "            # Pass data into network, and return reconstructed image from Membrane Potential at t = -1\n",
    "            cur1 = self.conv1(x[:,:,step,:,:]) # Get frame by frame\n",
    "            cur1 = self.bn1[step](cur1)\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.conv2(spk1)\n",
    "            cur2 = self.bn2[step](cur2)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            spk3 = self.flatten(spk2)\n",
    "            cur4 = self.fc1(spk3)\n",
    "            spk_enc, mem_enc = self.lif4(cur4, mem4) # Output spike trains and neuron membrane states\n",
    "            spk_rec.append(spk_enc)\n",
    "            spk_mem.append(mem_enc)\n",
    "        \n",
    "        spk_rec=torch.stack(spk_rec, dim=2)\n",
    "        spk_mem=torch.stack(spk_mem, dim=2) # Dimensions:[Batch, Channels, Width, Length, Time]\n",
    "        \n",
    "        encoding = spk_mem #[...,step].squeeze()\n",
    "        \n",
    "        # Decode\n",
    "        spk_mem2=[]\n",
    "        spk_rec2=[]\n",
    "        for step in range(self.num_time_steps): # Get frame by frame\n",
    "            # Latent\n",
    "            cur5 = self.fc2(spk_rec[...,step])\n",
    "            spk5, mem5 = self.lif5(cur5, mem5)\n",
    "            \n",
    "            # Decoder\n",
    "            cur6 = self.unflatten(spk5)\n",
    "            spk7, mem7 = self.lif7(cur6, mem7)\n",
    "            cur8 = self.convT2(spk7)\n",
    "            cur8 = self.bn5[step](cur8)\n",
    "            spk8, mem8 = self.lif8(cur8, mem8)\n",
    "            cur9 = self.convT3(spk8)\n",
    "            spk9, mem9 = self.lif9(cur9, mem9) #make large so membrane can be trained\n",
    "            \n",
    "            spk_rec2.append(spk9) \n",
    "            spk_mem2.append(mem9)\n",
    "        spk_rec2 = torch.stack(spk_rec2, dim=4)\n",
    "        spk_mem2 = torch.stack(spk_mem2, dim=4) # Dimensions:[Batch, Channels, Width, Length, Time]  \n",
    "        out = spk_rec2 #[:,:,:,:,-1] # Return the membrane potential of the output neuron at t = -1 (last t)\n",
    "        return out, encoding # Dimensions:[Batch, Channels, Width, Length]\n",
    "    \n",
    "    def forward_encode(self, x): #Dimensions: [Batch,Channels,Width,Length]\n",
    "        # Reset hidden states of LIF\n",
    "        mem1 = self.lif1.init_leaky() # reset/init hidden states at t=0\n",
    "        mem2 = self.lif2.init_leaky() # reset/init hidden states at t=0\n",
    "        mem4 = self.lif4.init_leaky() # reset/init hidden states at t=0\n",
    "        \n",
    "        # Encode\n",
    "        spk_mem = []\n",
    "        spk_rec = []\n",
    "        for step in range(self.num_time_steps):\n",
    "            # Pass data into network, and return reconstructed image from Membrane Potential at t = -1\n",
    "            cur1 = self.conv1(x[:,:,step,:,:]) # Get frame by frame\n",
    "            cur1 = self.bn1[step](cur1)\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.conv2(spk1)\n",
    "            cur2 = self.bn2[step](cur2)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            spk3 = self.flatten(spk2)\n",
    "            cur4 = self.fc1(spk3)\n",
    "            spk_enc, mem_enc = self.lif4(cur4, mem4) # Output spike trains and neuron membrane states\n",
    "            spk_rec.append(spk_enc)\n",
    "            spk_mem.append(mem_enc)\n",
    "        \n",
    "        spk_rec=torch.stack(spk_rec, dim=2)\n",
    "        spk_mem=torch.stack(spk_mem, dim=2) # Dimensions:[Batch, Channels, Width, Length, Time]\n",
    "        \n",
    "        encoding = spk_mem #[...,step].squeeze()\n",
    "        \n",
    "        return encoding\n",
    "    \n",
    "    def train_net(self, trainloader, optimizer, max_batch, start_epoch, max_epoch, save_output=False, save_model=False):\n",
    "        self.train()\n",
    "        train_loss_hist= []\n",
    "        latent_data = []\n",
    "        latent_labels = []\n",
    "        for epoch in range(start_epoch, max_epoch):\n",
    "            for batch_idx, (real_img, labels) in enumerate(trainloader):\n",
    "                # Stop if max batches reached\n",
    "                if batch_idx >= max_batch:\n",
    "                    break\n",
    "                \n",
    "                real_img = self.preprocess_image(real_img).to(device)\n",
    "                \n",
    "                # Pass data into network, and return reconstructed image from Membrane Potential at t = -1\n",
    "                x_recon, encoding = self(real_img)\n",
    "                latent_data.append(encoding.detach())\n",
    "                latent_labels.append(labels)\n",
    "                \n",
    "                # Calculate loss \n",
    "                train_loss_hist=[]\n",
    "                loss = torch.zeros((1), dtype=dtype, device=device)\n",
    "                for step in range(self.num_time_steps):\n",
    "                    loss += F.mse_loss(x_recon, real_img)\n",
    "                    \n",
    "                loss_val = loss.item()\n",
    "                train_loss_hist.append(loss_val)\n",
    "                avg_loss = loss_val/self.num_time_steps\n",
    "                        \n",
    "                print(f'Train[{epoch}/{max_epoch}][{batch_idx}/{len(trainloader)}] Loss: {avg_loss}')\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                if (batch_idx == len(trainloader) - 1) and save_output:\n",
    "                #if (batch_idx == max_batch - 1) and save_output:\n",
    "                    # Save output\n",
    "                    self.save_output(real_img, x_recon, epoch, mode=\"training\")\n",
    "                    self.plot_umap(latent_data, latent_labels, epoch, mode=\"training\")\n",
    "\n",
    "                    # Store model\n",
    "                    if save_model:\n",
    "                        torch.save(self.state_dict(), f'{self.model_path}/models/epoch{epoch}.pth')               \n",
    "\n",
    "        return train_loss_hist\n",
    "        \n",
    "    def preprocess_image(self, image):\n",
    "        # Data returned as: [Batch_size, Channels, Image_Depth, Image_Height, Image_Width]\n",
    "        return image.permute(0, 2, 1, 3, 4)\n",
    "    \n",
    "    def save_output(self, real_img, x_recon, epoch, mode):\n",
    "        # Save animation of one digit at the end of each epoch\n",
    "        images = [real_img[0].cpu(), x_recon[0].cpu()]\n",
    "        ani = animate_plot(images)\n",
    "        #HTML(ani.to_jshtml())\n",
    "        ani.save(filename=f'{self.model_path}/figures/{mode}/epoch{epoch}_image0.html', writer=\"html\")\n",
    "        plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ab347c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAE_2DconvTT_test(SAE):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(nn.Conv2d(2, 32, 3, padding=1, stride=2),\n",
    "                          snn._layers.bntt.BatchNormTT2d(32, 32),\n",
    "                          snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=True, threshold=self.thresh),\n",
    "                          nn.Conv2d(32, 64, 3, padding=1, stride=2),\n",
    "                          snn._layers.bntt.BatchNormTT2d(64, 32),\n",
    "                          snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=True, threshold=self.thresh),\n",
    "                          nn.Conv2d(64, 128, 3, padding=1, stride=2),\n",
    "                          snn._layers.bntt.BatchNormTT2d(128, 32),\n",
    "                          snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=True, threshold=self.thresh),\n",
    "                          nn.Flatten(start_dim = 1, end_dim = 3),\n",
    "                          nn.Linear(128*4*4, self.latent_dim), #this needs to be the final layer output size (channels * pixels * pixels)\n",
    "                          snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=True, output=True, threshold=self.thresh)\n",
    "                          )\n",
    "        # From latent back to tensor for convolution\n",
    "        self.linearNet= nn.Sequential(nn.Linear(self.latent_dim, 128*4*4),\n",
    "                               snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=True, output=True,threshold=self.thresh))        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(nn.Unflatten(1, (128, 4, 4)), \n",
    "                          snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=True, threshold=self.thresh),\n",
    "                          nn.ConvTranspose2d(128, 64, 3, padding=1, stride=(2,2), output_padding=1),\n",
    "                          snn._layers.bntt.BatchNormTT2d(64, 32),\n",
    "                          snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=True, threshold=self.thresh),\n",
    "                          nn.ConvTranspose2d(64, 32, 3, padding=1, stride=(2,2), output_padding=1),\n",
    "                          snn._layers.bntt.BatchNormTT2d(32, 32),\n",
    "                          snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=True, threshold=self.thresh),\n",
    "                          nn.ConvTranspose2d(32, 2, 3, padding=1, stride=(2,2), output_padding=1),\n",
    "                          snn.Leaky(beta=self.beta, spike_grad=self.spike_grad, init_hidden=True, output=True, threshold=20000) #make large so membrane can be trained\n",
    "                          )\n",
    "        \n",
    "    def train_net(self, trainloader, optimizer, max_batch, start_epoch, max_epoch, save_output=False, save_model=False):\n",
    "        self.train()\n",
    "        train_loss_hist= []\n",
    "        latent_data = []\n",
    "        latent_labels = []\n",
    "        for epoch in range(start_epoch, max_epoch):\n",
    "            for batch_idx, (real_img, labels) in enumerate(trainloader):\n",
    "                # Stop if max batches reached\n",
    "                if batch_idx >= max_batch:\n",
    "                    break\n",
    "                \n",
    "                real_img = self.preprocess_image(real_img).to(device)\n",
    "                \n",
    "                frames_recon = []\n",
    "                for i in range(real_img.shape[2]):\n",
    "                    # Pass data into network, and return reconstructed image from Membrane Potential at t = -1\n",
    "                    frame = real_img[:,:,i,:,:]                \n",
    "                    frame_recon, encoding = self(frame)\n",
    "                    frames_recon.append(frame_recon)\n",
    "                    \n",
    "                    latent_data.append(encoding.detach())\n",
    "                    latent_labels.append(labels)\n",
    "                \n",
    "                #x_recon.unsqueeze(2)\n",
    "                x_recon = torch.stack(frames_recon, dim=2)\n",
    "                    \n",
    "                # Calculate loss        \n",
    "                loss = F.mse_loss(x_recon, real_img)\n",
    "                loss_val = loss.item()\n",
    "                train_loss_hist.append(loss_val)\n",
    "                        \n",
    "                print(f'Train[{epoch}/{max_epoch}][{batch_idx}/{len(trainloader)}] Loss: {loss_val}')\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                if (batch_idx == len(trainloader) - 1) and save_output:\n",
    "                #if (batch_idx == max_batch - 1) and save_output:\n",
    "                    # Save output\n",
    "                    self.save_output(real_img, x_recon, epoch, mode=\"training\")\n",
    "                    self.plot_umap(latent_data, latent_labels, epoch, mode=\"training\")\n",
    "\n",
    "            # Store model\n",
    "            if save_model:\n",
    "                torch.save(self.state_dict(), f'{self.model_path}/models/epoch{epoch}.pth')               \n",
    "\n",
    "        return train_loss_hist\n",
    "    \n",
    "    def preprocess_image(self, image):\n",
    "        # Data returned as: [Batch_size, Channels, Image_Depth, Image_Height, Image_Width]\n",
    "        return image.permute(0, 2, 1, 3, 4)\n",
    "    \n",
    "    def save_output(self, real_img, x_recon, epoch, mode):\n",
    "        # Save animation of one digit at the end of each epoch\n",
    "        images = [real_img[0].cpu(), x_recon[0].cpu()]\n",
    "        ani = animate_plot(images)\n",
    "        #HTML(ani.to_jshtml())\n",
    "        ani.save(filename=f'{self.model_path}/figures/{mode}/epoch{epoch}_image0.html', writer=\"html\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6f66e9",
   "metadata": {},
   "source": [
    "## 4. Run Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe7b4095",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for SAE_3Dconv:\n\tsize mismatch for encoder.10.weight: copying a param with shape torch.Size([32, 8192]) from checkpoint, the shape in current model is torch.Size([512, 8192]).\n\tsize mismatch for encoder.10.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for linearNet.0.weight: copying a param with shape torch.Size([8192, 32]) from checkpoint, the shape in current model is torch.Size([8192, 512]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Define Network and optimizer\u001b[39;00m\n\u001b[0;32m      8\u001b[0m net \u001b[38;5;241m=\u001b[39m SAE_3Dconv()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Load model\u001b[39;00m\n\u001b[0;32m     10\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(net\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m, betas\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.9\u001b[39m, \u001b[38;5;241m0.999\u001b[39m), weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Test maximum batch size possible\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#size_2d = (1,32,32)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#size_3d = (2,32,32,32)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#batch_size = get_max_batch_size(model=net, device=device, optimizer=optimizer, input_shape=size_3d, output_shape=size_3d, dataset_size=60000)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[10], line 187\u001b[0m, in \u001b[0;36mSAE.load_model\u001b[1;34m(self, epoch)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, epoch):\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 187\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/models/epoch\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[0;32m    189\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: Model file not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32me:\\Dev\\envs\\snn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2152\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2147\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2148\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2149\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[0;32m   2151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2153\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   2154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for SAE_3Dconv:\n\tsize mismatch for encoder.10.weight: copying a param with shape torch.Size([32, 8192]) from checkpoint, the shape in current model is torch.Size([512, 8192]).\n\tsize mismatch for encoder.10.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for linearNet.0.weight: copying a param with shape torch.Size([8192, 32]) from checkpoint, the shape in current model is torch.Size([8192, 512])."
     ]
    }
   ],
   "source": [
    "# Simulation parameters\n",
    "max_batch = 999 # Limit number of batches per epoch\n",
    "start_epoch = 3\n",
    "epochs = 7\n",
    "max_epoch = start_epoch + epochs\n",
    "\n",
    "# Define Network and optimizer\n",
    "net = SAE_3Dconv().to(device)\n",
    "net.load_model(epoch=9) # Load model\n",
    "optimizer = torch.optim.AdamW(net.parameters(), lr=0.0001, betas=(0.9, 0.999), weight_decay=0.001)\n",
    "\n",
    "# Test maximum batch size possible\n",
    "#size_2d = (1,32,32)\n",
    "#size_3d = (2,32,32,32)\n",
    "#batch_size = get_max_batch_size(model=net, device=device, optimizer=optimizer, input_shape=size_3d, output_shape=size_3d, dataset_size=60000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be94d40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train[3/10][0/938] Loss: 0.13040924072265625\n",
      "Train[3/10][1/938] Loss: 0.1181793212890625\n",
      "Train[3/10][2/938] Loss: 0.12218213081359863\n",
      "Train[3/10][3/938] Loss: 0.11579442024230957\n",
      "Train[3/10][4/938] Loss: 0.11711597442626953\n",
      "Train[3/10][5/938] Loss: 0.1198265552520752\n",
      "Train[3/10][6/938] Loss: 0.12080121040344238\n",
      "Train[3/10][7/938] Loss: 0.13155126571655273\n",
      "Train[3/10][8/938] Loss: 0.12053036689758301\n",
      "Train[3/10][9/938] Loss: 0.11947345733642578\n",
      "Train[3/10][10/938] Loss: 0.11649823188781738\n",
      "Train[3/10][11/938] Loss: 0.11902141571044922\n",
      "Train[3/10][12/938] Loss: 0.1179053783416748\n",
      "Train[3/10][13/938] Loss: 0.12098407745361328\n",
      "Train[3/10][14/938] Loss: 0.12026619911193848\n",
      "Train[3/10][15/938] Loss: 0.11789083480834961\n",
      "Train[3/10][16/938] Loss: 0.12425065040588379\n",
      "Train[3/10][17/938] Loss: 0.12044548988342285\n",
      "Train[3/10][18/938] Loss: 0.1188046932220459\n",
      "Train[3/10][19/938] Loss: 0.11795282363891602\n",
      "Train[3/10][20/938] Loss: 0.12029218673706055\n",
      "Train[3/10][21/938] Loss: 0.12030315399169922\n",
      "Train[3/10][22/938] Loss: 0.12800860404968262\n",
      "Train[3/10][23/938] Loss: 0.1306142807006836\n",
      "Train[3/10][24/938] Loss: 0.12575840950012207\n",
      "Train[3/10][25/938] Loss: 0.12430834770202637\n",
      "Train[3/10][26/938] Loss: 0.1163167953491211\n",
      "Train[3/10][27/938] Loss: 0.12213969230651855\n",
      "Train[3/10][28/938] Loss: 0.13074111938476562\n",
      "Train[3/10][29/938] Loss: 0.13254380226135254\n",
      "Train[3/10][30/938] Loss: 0.12273645401000977\n",
      "Train[3/10][31/938] Loss: 0.12755084037780762\n",
      "Train[3/10][32/938] Loss: 0.11307740211486816\n",
      "Train[3/10][33/938] Loss: 0.12601375579833984\n",
      "Train[3/10][34/938] Loss: 0.12243366241455078\n",
      "Train[3/10][35/938] Loss: 0.12414002418518066\n",
      "Train[3/10][36/938] Loss: 0.12206673622131348\n",
      "Train[3/10][37/938] Loss: 0.1259152889251709\n",
      "Train[3/10][38/938] Loss: 0.12220311164855957\n",
      "Train[3/10][39/938] Loss: 0.12651705741882324\n",
      "Train[3/10][40/938] Loss: 0.12199187278747559\n",
      "Train[3/10][41/938] Loss: 0.12329721450805664\n",
      "Train[3/10][42/938] Loss: 0.11269688606262207\n",
      "Train[3/10][43/938] Loss: 0.12329626083374023\n",
      "Train[3/10][44/938] Loss: 0.12211012840270996\n",
      "Train[3/10][45/938] Loss: 0.11870288848876953\n",
      "Train[3/10][46/938] Loss: 0.1131138801574707\n",
      "Train[3/10][47/938] Loss: 0.12410306930541992\n",
      "Train[3/10][48/938] Loss: 0.12114596366882324\n",
      "Train[3/10][49/938] Loss: 0.12497806549072266\n",
      "Train[3/10][50/938] Loss: 0.12740445137023926\n",
      "Train[3/10][51/938] Loss: 0.12410855293273926\n",
      "Train[3/10][52/938] Loss: 0.11726522445678711\n",
      "Train[3/10][53/938] Loss: 0.12576651573181152\n",
      "Train[3/10][54/938] Loss: 0.11887502670288086\n",
      "Train[3/10][55/938] Loss: 0.12088465690612793\n",
      "Train[3/10][56/938] Loss: 0.1230173110961914\n",
      "Train[3/10][57/938] Loss: 0.11515378952026367\n",
      "Train[3/10][58/938] Loss: 0.11693000793457031\n",
      "Train[3/10][59/938] Loss: 0.11048483848571777\n",
      "Train[3/10][60/938] Loss: 0.11677193641662598\n",
      "Train[3/10][61/938] Loss: 0.11736774444580078\n",
      "Train[3/10][62/938] Loss: 0.12144637107849121\n",
      "Train[3/10][63/938] Loss: 0.12496304512023926\n",
      "Train[3/10][64/938] Loss: 0.12140226364135742\n",
      "Train[3/10][65/938] Loss: 0.11961627006530762\n",
      "Train[3/10][66/938] Loss: 0.1256880760192871\n",
      "Train[3/10][67/938] Loss: 0.12085628509521484\n",
      "Train[3/10][68/938] Loss: 0.12473058700561523\n",
      "Train[3/10][69/938] Loss: 0.11228585243225098\n",
      "Train[3/10][70/938] Loss: 0.1321563720703125\n",
      "Train[3/10][71/938] Loss: 0.11143279075622559\n",
      "Train[3/10][72/938] Loss: 0.1199953556060791\n",
      "Train[3/10][73/938] Loss: 0.11907505989074707\n",
      "Train[3/10][74/938] Loss: 0.12067508697509766\n",
      "Train[3/10][75/938] Loss: 0.11643552780151367\n",
      "Train[3/10][76/938] Loss: 0.11748123168945312\n",
      "Train[3/10][77/938] Loss: 0.1288294792175293\n",
      "Train[3/10][78/938] Loss: 0.12038755416870117\n",
      "Train[3/10][79/938] Loss: 0.13063931465148926\n",
      "Train[3/10][80/938] Loss: 0.1165318489074707\n",
      "Train[3/10][81/938] Loss: 0.1158599853515625\n",
      "Train[3/10][82/938] Loss: 0.11808896064758301\n",
      "Train[3/10][83/938] Loss: 0.12267374992370605\n",
      "Train[3/10][84/938] Loss: 0.1259758472442627\n",
      "Train[3/10][85/938] Loss: 0.11494660377502441\n",
      "Train[3/10][86/938] Loss: 0.12153291702270508\n",
      "Train[3/10][87/938] Loss: 0.12029719352722168\n",
      "Train[3/10][88/938] Loss: 0.11336278915405273\n",
      "Train[3/10][89/938] Loss: 0.12109827995300293\n",
      "Train[3/10][90/938] Loss: 0.13558411598205566\n",
      "Train[3/10][91/938] Loss: 0.11597943305969238\n",
      "Train[3/10][92/938] Loss: 0.1230471134185791\n",
      "Train[3/10][93/938] Loss: 0.12060713768005371\n",
      "Train[3/10][94/938] Loss: 0.1285257339477539\n",
      "Train[3/10][95/938] Loss: 0.12018156051635742\n",
      "Train[3/10][96/938] Loss: 0.12402486801147461\n",
      "Train[3/10][97/938] Loss: 0.11559414863586426\n",
      "Train[3/10][98/938] Loss: 0.12408876419067383\n",
      "Train[3/10][99/938] Loss: 0.12268590927124023\n",
      "Train[3/10][100/938] Loss: 0.12268304824829102\n",
      "Train[3/10][101/938] Loss: 0.11800289154052734\n",
      "Train[3/10][102/938] Loss: 0.11905932426452637\n",
      "Train[3/10][103/938] Loss: 0.11998581886291504\n",
      "Train[3/10][104/938] Loss: 0.11926007270812988\n",
      "Train[3/10][105/938] Loss: 0.12206554412841797\n",
      "Train[3/10][106/938] Loss: 0.12677240371704102\n",
      "Train[3/10][107/938] Loss: 0.12465476989746094\n",
      "Train[3/10][108/938] Loss: 0.11772799491882324\n",
      "Train[3/10][109/938] Loss: 0.11521053314208984\n",
      "Train[3/10][110/938] Loss: 0.11921000480651855\n",
      "Train[3/10][111/938] Loss: 0.1090691089630127\n",
      "Train[3/10][112/938] Loss: 0.12297177314758301\n",
      "Train[3/10][113/938] Loss: 0.11219501495361328\n",
      "Train[3/10][114/938] Loss: 0.12529325485229492\n",
      "Train[3/10][115/938] Loss: 0.1270003318786621\n",
      "Train[3/10][116/938] Loss: 0.12524867057800293\n",
      "Train[3/10][117/938] Loss: 0.1205441951751709\n",
      "Train[3/10][118/938] Loss: 0.11208820343017578\n",
      "Train[3/10][119/938] Loss: 0.11369824409484863\n",
      "Train[3/10][120/938] Loss: 0.12012219429016113\n",
      "Train[3/10][121/938] Loss: 0.11648702621459961\n",
      "Train[3/10][122/938] Loss: 0.12325096130371094\n",
      "Train[3/10][123/938] Loss: 0.11852645874023438\n",
      "Train[3/10][124/938] Loss: 0.12444591522216797\n",
      "Train[3/10][125/938] Loss: 0.11944055557250977\n",
      "Train[3/10][126/938] Loss: 0.11784839630126953\n",
      "Train[3/10][127/938] Loss: 0.1160738468170166\n",
      "Train[3/10][128/938] Loss: 0.11957573890686035\n",
      "Train[3/10][129/938] Loss: 0.11706709861755371\n",
      "Train[3/10][130/938] Loss: 0.11355113983154297\n",
      "Train[3/10][131/938] Loss: 0.11482048034667969\n",
      "Train[3/10][132/938] Loss: 0.11927342414855957\n",
      "Train[3/10][133/938] Loss: 0.12419986724853516\n",
      "Train[3/10][134/938] Loss: 0.12077116966247559\n",
      "Train[3/10][135/938] Loss: 0.12621831893920898\n",
      "Train[3/10][136/938] Loss: 0.11992502212524414\n",
      "Train[3/10][137/938] Loss: 0.12236380577087402\n",
      "Train[3/10][138/938] Loss: 0.12151765823364258\n",
      "Train[3/10][139/938] Loss: 0.12555313110351562\n",
      "Train[3/10][140/938] Loss: 0.11586904525756836\n",
      "Train[3/10][141/938] Loss: 0.11576080322265625\n",
      "Train[3/10][142/938] Loss: 0.1165616512298584\n",
      "Train[3/10][143/938] Loss: 0.12283086776733398\n",
      "Train[3/10][144/938] Loss: 0.11456704139709473\n",
      "Train[3/10][145/938] Loss: 0.12307548522949219\n",
      "Train[3/10][146/938] Loss: 0.11407780647277832\n",
      "Train[3/10][147/938] Loss: 0.11612915992736816\n",
      "Train[3/10][148/938] Loss: 0.11294937133789062\n",
      "Train[3/10][149/938] Loss: 0.12177109718322754\n",
      "Train[3/10][150/938] Loss: 0.1260089874267578\n",
      "Train[3/10][151/938] Loss: 0.12488126754760742\n",
      "Train[3/10][152/938] Loss: 0.12307000160217285\n",
      "Train[3/10][153/938] Loss: 0.122039794921875\n",
      "Train[3/10][154/938] Loss: 0.12179374694824219\n",
      "Train[3/10][155/938] Loss: 0.12140202522277832\n",
      "Train[3/10][156/938] Loss: 0.12380146980285645\n",
      "Train[3/10][157/938] Loss: 0.12052512168884277\n",
      "Train[3/10][158/938] Loss: 0.12079548835754395\n",
      "Train[3/10][159/938] Loss: 0.11948752403259277\n",
      "Train[3/10][160/938] Loss: 0.11800551414489746\n",
      "Train[3/10][161/938] Loss: 0.12148761749267578\n",
      "Train[3/10][162/938] Loss: 0.11975622177124023\n",
      "Train[3/10][163/938] Loss: 0.12135744094848633\n",
      "Train[3/10][164/938] Loss: 0.12018179893493652\n",
      "Train[3/10][165/938] Loss: 0.12356901168823242\n",
      "Train[3/10][166/938] Loss: 0.11875462532043457\n",
      "Train[3/10][167/938] Loss: 0.11631035804748535\n",
      "Train[3/10][168/938] Loss: 0.1228489875793457\n",
      "Train[3/10][169/938] Loss: 0.12217497825622559\n",
      "Train[3/10][170/938] Loss: 0.11520075798034668\n",
      "Train[3/10][171/938] Loss: 0.11579537391662598\n",
      "Train[3/10][172/938] Loss: 0.12116670608520508\n",
      "Train[3/10][173/938] Loss: 0.12582850456237793\n",
      "Train[3/10][174/938] Loss: 0.12101125717163086\n",
      "Train[3/10][175/938] Loss: 0.11280584335327148\n",
      "Train[3/10][176/938] Loss: 0.12296223640441895\n",
      "Train[3/10][177/938] Loss: 0.1191704273223877\n",
      "Train[3/10][178/938] Loss: 0.12318634986877441\n",
      "Train[3/10][179/938] Loss: 0.11897873878479004\n",
      "Train[3/10][180/938] Loss: 0.12412357330322266\n",
      "Train[3/10][181/938] Loss: 0.11316466331481934\n",
      "Train[3/10][182/938] Loss: 0.11980772018432617\n",
      "Train[3/10][183/938] Loss: 0.12549209594726562\n",
      "Train[3/10][184/938] Loss: 0.12221884727478027\n",
      "Train[3/10][185/938] Loss: 0.12263679504394531\n",
      "Train[3/10][186/938] Loss: 0.11213088035583496\n",
      "Train[3/10][187/938] Loss: 0.12320590019226074\n",
      "Train[3/10][188/938] Loss: 0.11804795265197754\n",
      "Train[3/10][189/938] Loss: 0.12476968765258789\n",
      "Train[3/10][190/938] Loss: 0.12186074256896973\n",
      "Train[3/10][191/938] Loss: 0.12251853942871094\n",
      "Train[3/10][192/938] Loss: 0.12204837799072266\n",
      "Train[3/10][193/938] Loss: 0.11276412010192871\n",
      "Train[3/10][194/938] Loss: 0.12097740173339844\n",
      "Train[3/10][195/938] Loss: 0.1215822696685791\n",
      "Train[3/10][196/938] Loss: 0.11818575859069824\n",
      "Train[3/10][197/938] Loss: 0.12243962287902832\n",
      "Train[3/10][198/938] Loss: 0.11571645736694336\n",
      "Train[3/10][199/938] Loss: 0.12471842765808105\n",
      "Train[3/10][200/938] Loss: 0.12503790855407715\n",
      "Train[3/10][201/938] Loss: 0.11831927299499512\n",
      "Train[3/10][202/938] Loss: 0.1233065128326416\n",
      "Train[3/10][203/938] Loss: 0.11360526084899902\n",
      "Train[3/10][204/938] Loss: 0.11579680442810059\n",
      "Train[3/10][205/938] Loss: 0.11597275733947754\n",
      "Train[3/10][206/938] Loss: 0.10820960998535156\n",
      "Train[3/10][207/938] Loss: 0.11965751647949219\n",
      "Train[3/10][208/938] Loss: 0.12446379661560059\n",
      "Train[3/10][209/938] Loss: 0.11871552467346191\n",
      "Train[3/10][210/938] Loss: 0.11919164657592773\n",
      "Train[3/10][211/938] Loss: 0.12374758720397949\n",
      "Train[3/10][212/938] Loss: 0.11556792259216309\n",
      "Train[3/10][213/938] Loss: 0.12112998962402344\n",
      "Train[3/10][214/938] Loss: 0.12163329124450684\n",
      "Train[3/10][215/938] Loss: 0.12111043930053711\n",
      "Train[3/10][216/938] Loss: 0.12084746360778809\n",
      "Train[3/10][217/938] Loss: 0.12175464630126953\n",
      "Train[3/10][218/938] Loss: 0.11472296714782715\n",
      "Train[3/10][219/938] Loss: 0.1218423843383789\n",
      "Train[3/10][220/938] Loss: 0.11585116386413574\n",
      "Train[3/10][221/938] Loss: 0.11795377731323242\n",
      "Train[3/10][222/938] Loss: 0.11823248863220215\n",
      "Train[3/10][223/938] Loss: 0.12138772010803223\n",
      "Train[3/10][224/938] Loss: 0.11526298522949219\n",
      "Train[3/10][225/938] Loss: 0.11788535118103027\n",
      "Train[3/10][226/938] Loss: 0.11729836463928223\n",
      "Train[3/10][227/938] Loss: 0.12807178497314453\n",
      "Train[3/10][228/938] Loss: 0.11833333969116211\n",
      "Train[3/10][229/938] Loss: 0.11341691017150879\n",
      "Train[3/10][230/938] Loss: 0.12181901931762695\n",
      "Train[3/10][231/938] Loss: 0.11833524703979492\n",
      "Train[3/10][232/938] Loss: 0.11344480514526367\n",
      "Train[3/10][233/938] Loss: 0.1218864917755127\n",
      "Train[3/10][234/938] Loss: 0.11548089981079102\n",
      "Train[3/10][235/938] Loss: 0.11163926124572754\n",
      "Train[3/10][236/938] Loss: 0.1243135929107666\n",
      "Train[3/10][237/938] Loss: 0.1092987060546875\n",
      "Train[3/10][238/938] Loss: 0.11324810981750488\n",
      "Train[3/10][239/938] Loss: 0.11372590065002441\n",
      "Train[3/10][240/938] Loss: 0.11875247955322266\n",
      "Train[3/10][241/938] Loss: 0.11467528343200684\n",
      "Train[3/10][242/938] Loss: 0.11079692840576172\n",
      "Train[3/10][243/938] Loss: 0.11626958847045898\n",
      "Train[3/10][244/938] Loss: 0.12290453910827637\n",
      "Train[3/10][245/938] Loss: 0.11776447296142578\n",
      "Train[3/10][246/938] Loss: 0.11834716796875\n",
      "Train[3/10][247/938] Loss: 0.12252283096313477\n",
      "Train[3/10][248/938] Loss: 0.12022733688354492\n",
      "Train[3/10][249/938] Loss: 0.12139129638671875\n",
      "Train[3/10][250/938] Loss: 0.11277890205383301\n",
      "Train[3/10][251/938] Loss: 0.11266231536865234\n",
      "Train[3/10][252/938] Loss: 0.1213376522064209\n",
      "Train[3/10][253/938] Loss: 0.11386394500732422\n",
      "Train[3/10][254/938] Loss: 0.12041425704956055\n",
      "Train[3/10][255/938] Loss: 0.12120223045349121\n",
      "Train[3/10][256/938] Loss: 0.11059761047363281\n",
      "Train[3/10][257/938] Loss: 0.11879873275756836\n",
      "Train[3/10][258/938] Loss: 0.12151837348937988\n",
      "Train[3/10][259/938] Loss: 0.12116122245788574\n",
      "Train[3/10][260/938] Loss: 0.11724019050598145\n",
      "Train[3/10][261/938] Loss: 0.1182866096496582\n",
      "Train[3/10][262/938] Loss: 0.11403417587280273\n",
      "Train[3/10][263/938] Loss: 0.12219476699829102\n",
      "Train[3/10][264/938] Loss: 0.11640477180480957\n",
      "Train[3/10][265/938] Loss: 0.11657476425170898\n",
      "Train[3/10][266/938] Loss: 0.11408066749572754\n",
      "Train[3/10][267/938] Loss: 0.11054372787475586\n",
      "Train[3/10][268/938] Loss: 0.1222529411315918\n",
      "Train[3/10][269/938] Loss: 0.12746238708496094\n",
      "Train[3/10][270/938] Loss: 0.11499190330505371\n",
      "Train[3/10][271/938] Loss: 0.11663341522216797\n",
      "Train[3/10][272/938] Loss: 0.11103510856628418\n",
      "Train[3/10][273/938] Loss: 0.11633539199829102\n",
      "Train[3/10][274/938] Loss: 0.11562132835388184\n",
      "Train[3/10][275/938] Loss: 0.12036299705505371\n",
      "Train[3/10][276/938] Loss: 0.11927676200866699\n",
      "Train[3/10][277/938] Loss: 0.11620545387268066\n",
      "Train[3/10][278/938] Loss: 0.11472320556640625\n",
      "Train[3/10][279/938] Loss: 0.12529325485229492\n",
      "Train[3/10][280/938] Loss: 0.11533689498901367\n",
      "Train[3/10][281/938] Loss: 0.12293410301208496\n",
      "Train[3/10][282/938] Loss: 0.1174309253692627\n",
      "Train[3/10][283/938] Loss: 0.11800503730773926\n",
      "Train[3/10][284/938] Loss: 0.11773824691772461\n",
      "Train[3/10][285/938] Loss: 0.1222221851348877\n",
      "Train[3/10][286/938] Loss: 0.11192488670349121\n",
      "Train[3/10][287/938] Loss: 0.1190786361694336\n",
      "Train[3/10][288/938] Loss: 0.12035179138183594\n",
      "Train[3/10][289/938] Loss: 0.11800527572631836\n",
      "Train[3/10][290/938] Loss: 0.1137244701385498\n",
      "Train[3/10][291/938] Loss: 0.11882829666137695\n",
      "Train[3/10][292/938] Loss: 0.11669516563415527\n",
      "Train[3/10][293/938] Loss: 0.11630773544311523\n",
      "Train[3/10][294/938] Loss: 0.12167668342590332\n",
      "Train[3/10][295/938] Loss: 0.12374043464660645\n",
      "Train[3/10][296/938] Loss: 0.12194967269897461\n",
      "Train[3/10][297/938] Loss: 0.11233329772949219\n",
      "Train[3/10][298/938] Loss: 0.11984729766845703\n",
      "Train[3/10][299/938] Loss: 0.12367582321166992\n",
      "Train[3/10][300/938] Loss: 0.11886334419250488\n",
      "Train[3/10][301/938] Loss: 0.11624717712402344\n",
      "Train[3/10][302/938] Loss: 0.11910796165466309\n",
      "Train[3/10][303/938] Loss: 0.11928462982177734\n",
      "Train[3/10][304/938] Loss: 0.12682199478149414\n",
      "Train[3/10][305/938] Loss: 0.12049436569213867\n",
      "Train[3/10][306/938] Loss: 0.11405014991760254\n",
      "Train[3/10][307/938] Loss: 0.12074947357177734\n",
      "Train[3/10][308/938] Loss: 0.11343765258789062\n",
      "Train[3/10][309/938] Loss: 0.12339591979980469\n",
      "Train[3/10][310/938] Loss: 0.11095833778381348\n",
      "Train[3/10][311/938] Loss: 0.12202191352844238\n",
      "Train[3/10][312/938] Loss: 0.11392617225646973\n",
      "Train[3/10][313/938] Loss: 0.11874508857727051\n",
      "Train[3/10][314/938] Loss: 0.11416435241699219\n",
      "Train[3/10][315/938] Loss: 0.12007999420166016\n",
      "Train[3/10][316/938] Loss: 0.11779332160949707\n",
      "Train[3/10][317/938] Loss: 0.11306953430175781\n",
      "Train[3/10][318/938] Loss: 0.11349010467529297\n",
      "Train[3/10][319/938] Loss: 0.1177372932434082\n",
      "Train[3/10][320/938] Loss: 0.1184089183807373\n",
      "Train[3/10][321/938] Loss: 0.11844539642333984\n",
      "Train[3/10][322/938] Loss: 0.10518860816955566\n",
      "Train[3/10][323/938] Loss: 0.12397360801696777\n",
      "Train[3/10][324/938] Loss: 0.11647772789001465\n",
      "Train[3/10][325/938] Loss: 0.12041783332824707\n",
      "Train[3/10][326/938] Loss: 0.12400197982788086\n",
      "Train[3/10][327/938] Loss: 0.12185335159301758\n",
      "Train[3/10][328/938] Loss: 0.11072301864624023\n",
      "Train[3/10][329/938] Loss: 0.12150979042053223\n",
      "Train[3/10][330/938] Loss: 0.12135124206542969\n",
      "Train[3/10][331/938] Loss: 0.1255931854248047\n",
      "Train[3/10][332/938] Loss: 0.11070871353149414\n",
      "Train[3/10][333/938] Loss: 0.11678743362426758\n",
      "Train[3/10][334/938] Loss: 0.1273813247680664\n",
      "Train[3/10][335/938] Loss: 0.12069010734558105\n",
      "Train[3/10][336/938] Loss: 0.11973834037780762\n",
      "Train[3/10][337/938] Loss: 0.11721205711364746\n",
      "Train[3/10][338/938] Loss: 0.12125420570373535\n",
      "Train[3/10][339/938] Loss: 0.11847257614135742\n",
      "Train[3/10][340/938] Loss: 0.11966395378112793\n",
      "Train[3/10][341/938] Loss: 0.12228798866271973\n",
      "Train[3/10][342/938] Loss: 0.11789584159851074\n",
      "Train[3/10][343/938] Loss: 0.1190187931060791\n",
      "Train[3/10][344/938] Loss: 0.11159849166870117\n",
      "Train[3/10][345/938] Loss: 0.10917067527770996\n",
      "Train[3/10][346/938] Loss: 0.11271810531616211\n",
      "Train[3/10][347/938] Loss: 0.11289143562316895\n",
      "Train[3/10][348/938] Loss: 0.11447525024414062\n",
      "Train[3/10][349/938] Loss: 0.1215822696685791\n",
      "Train[3/10][350/938] Loss: 0.1186830997467041\n",
      "Train[3/10][351/938] Loss: 0.11414456367492676\n",
      "Train[3/10][352/938] Loss: 0.11482906341552734\n",
      "Train[3/10][353/938] Loss: 0.12004733085632324\n",
      "Train[3/10][354/938] Loss: 0.10977721214294434\n",
      "Train[3/10][355/938] Loss: 0.1161801815032959\n",
      "Train[3/10][356/938] Loss: 0.1203761100769043\n",
      "Train[3/10][357/938] Loss: 0.12482190132141113\n",
      "Train[3/10][358/938] Loss: 0.11660623550415039\n",
      "Train[3/10][359/938] Loss: 0.11957430839538574\n",
      "Train[3/10][360/938] Loss: 0.12254476547241211\n",
      "Train[3/10][361/938] Loss: 0.12702727317810059\n",
      "Train[3/10][362/938] Loss: 0.11287117004394531\n",
      "Train[3/10][363/938] Loss: 0.11666417121887207\n",
      "Train[3/10][364/938] Loss: 0.11315083503723145\n",
      "Train[3/10][365/938] Loss: 0.11298847198486328\n",
      "Train[3/10][366/938] Loss: 0.10629630088806152\n",
      "Train[3/10][367/938] Loss: 0.10910487174987793\n",
      "Train[3/10][368/938] Loss: 0.11826777458190918\n",
      "Train[3/10][369/938] Loss: 0.12554526329040527\n",
      "Train[3/10][370/938] Loss: 0.11145710945129395\n",
      "Train[3/10][371/938] Loss: 0.12493205070495605\n",
      "Train[3/10][372/938] Loss: 0.11458015441894531\n",
      "Train[3/10][373/938] Loss: 0.11232423782348633\n",
      "Train[3/10][374/938] Loss: 0.12149810791015625\n",
      "Train[3/10][375/938] Loss: 0.11161684989929199\n",
      "Train[3/10][376/938] Loss: 0.11318445205688477\n",
      "Train[3/10][377/938] Loss: 0.11189889907836914\n",
      "Train[3/10][378/938] Loss: 0.11420202255249023\n",
      "Train[3/10][379/938] Loss: 0.11125707626342773\n",
      "Train[3/10][380/938] Loss: 0.11295700073242188\n",
      "Train[3/10][381/938] Loss: 0.11703085899353027\n",
      "Train[3/10][382/938] Loss: 0.1086428165435791\n",
      "Train[3/10][383/938] Loss: 0.12579822540283203\n",
      "Train[3/10][384/938] Loss: 0.10890626907348633\n",
      "Train[3/10][385/938] Loss: 0.12171769142150879\n",
      "Train[3/10][386/938] Loss: 0.11378812789916992\n",
      "Train[3/10][387/938] Loss: 0.11357426643371582\n",
      "Train[3/10][388/938] Loss: 0.11414217948913574\n",
      "Train[3/10][389/938] Loss: 0.11034488677978516\n",
      "Train[3/10][390/938] Loss: 0.11838889122009277\n",
      "Train[3/10][391/938] Loss: 0.11618781089782715\n",
      "Train[3/10][392/938] Loss: 0.12136006355285645\n",
      "Train[3/10][393/938] Loss: 0.12043190002441406\n",
      "Train[3/10][394/938] Loss: 0.11734533309936523\n",
      "Train[3/10][395/938] Loss: 0.11882781982421875\n",
      "Train[3/10][396/938] Loss: 0.13059663772583008\n",
      "Train[3/10][397/938] Loss: 0.11401104927062988\n",
      "Train[3/10][398/938] Loss: 0.11467242240905762\n",
      "Train[3/10][399/938] Loss: 0.1188364028930664\n",
      "Train[3/10][400/938] Loss: 0.11647534370422363\n",
      "Train[3/10][401/938] Loss: 0.11809754371643066\n",
      "Train[3/10][402/938] Loss: 0.11282205581665039\n",
      "Train[3/10][403/938] Loss: 0.10949110984802246\n",
      "Train[3/10][404/938] Loss: 0.11260819435119629\n",
      "Train[3/10][405/938] Loss: 0.1126260757446289\n",
      "Train[3/10][406/938] Loss: 0.11710286140441895\n",
      "Train[3/10][407/938] Loss: 0.11038661003112793\n",
      "Train[3/10][408/938] Loss: 0.12097334861755371\n",
      "Train[3/10][409/938] Loss: 0.11189603805541992\n",
      "Train[3/10][410/938] Loss: 0.1133112907409668\n",
      "Train[3/10][411/938] Loss: 0.11150836944580078\n",
      "Train[3/10][412/938] Loss: 0.11223101615905762\n",
      "Train[3/10][413/938] Loss: 0.11982083320617676\n",
      "Train[3/10][414/938] Loss: 0.12049007415771484\n",
      "Train[3/10][415/938] Loss: 0.10881257057189941\n",
      "Train[3/10][416/938] Loss: 0.12127351760864258\n",
      "Train[3/10][417/938] Loss: 0.11990666389465332\n",
      "Train[3/10][418/938] Loss: 0.11599016189575195\n",
      "Train[3/10][419/938] Loss: 0.11805272102355957\n",
      "Train[3/10][420/938] Loss: 0.11289286613464355\n",
      "Train[3/10][421/938] Loss: 0.1107943058013916\n",
      "Train[3/10][422/938] Loss: 0.11127805709838867\n",
      "Train[3/10][423/938] Loss: 0.12045598030090332\n",
      "Train[3/10][424/938] Loss: 0.12345099449157715\n",
      "Train[3/10][425/938] Loss: 0.11363863945007324\n",
      "Train[3/10][426/938] Loss: 0.10847663879394531\n",
      "Train[3/10][427/938] Loss: 0.11350274085998535\n",
      "Train[3/10][428/938] Loss: 0.11770915985107422\n",
      "Train[3/10][429/938] Loss: 0.11661362648010254\n",
      "Train[3/10][430/938] Loss: 0.1198129653930664\n",
      "Train[3/10][431/938] Loss: 0.11313557624816895\n",
      "Train[3/10][432/938] Loss: 0.12163352966308594\n",
      "Train[3/10][433/938] Loss: 0.11433696746826172\n",
      "Train[3/10][434/938] Loss: 0.11349725723266602\n",
      "Train[3/10][435/938] Loss: 0.11783075332641602\n",
      "Train[3/10][436/938] Loss: 0.11874675750732422\n",
      "Train[3/10][437/938] Loss: 0.11578106880187988\n",
      "Train[3/10][438/938] Loss: 0.10538554191589355\n",
      "Train[3/10][439/938] Loss: 0.10756945610046387\n",
      "Train[3/10][440/938] Loss: 0.10858559608459473\n",
      "Train[3/10][441/938] Loss: 0.1118781566619873\n",
      "Train[3/10][442/938] Loss: 0.11884140968322754\n",
      "Train[3/10][443/938] Loss: 0.11120319366455078\n",
      "Train[3/10][444/938] Loss: 0.11953449249267578\n",
      "Train[3/10][445/938] Loss: 0.11476969718933105\n",
      "Train[3/10][446/938] Loss: 0.11778831481933594\n",
      "Train[3/10][447/938] Loss: 0.11443710327148438\n",
      "Train[3/10][448/938] Loss: 0.11687684059143066\n",
      "Train[3/10][449/938] Loss: 0.11228203773498535\n",
      "Train[3/10][450/938] Loss: 0.11251258850097656\n",
      "Train[3/10][451/938] Loss: 0.1109168529510498\n",
      "Train[3/10][452/938] Loss: 0.11184048652648926\n",
      "Train[3/10][453/938] Loss: 0.10253739356994629\n",
      "Train[3/10][454/938] Loss: 0.1200246810913086\n",
      "Train[3/10][455/938] Loss: 0.11165523529052734\n",
      "Train[3/10][456/938] Loss: 0.1120157241821289\n",
      "Train[3/10][457/938] Loss: 0.11942481994628906\n",
      "Train[3/10][458/938] Loss: 0.12459993362426758\n",
      "Train[3/10][459/938] Loss: 0.11417412757873535\n",
      "Train[3/10][460/938] Loss: 0.11382555961608887\n",
      "Train[3/10][461/938] Loss: 0.11508440971374512\n",
      "Train[3/10][462/938] Loss: 0.11686038970947266\n",
      "Train[3/10][463/938] Loss: 0.12768840789794922\n",
      "Train[3/10][464/938] Loss: 0.11598873138427734\n",
      "Train[3/10][465/938] Loss: 0.11697959899902344\n",
      "Train[3/10][466/938] Loss: 0.11436057090759277\n",
      "Train[3/10][467/938] Loss: 0.1205441951751709\n",
      "Train[3/10][468/938] Loss: 0.11795854568481445\n",
      "Train[3/10][469/938] Loss: 0.1218268871307373\n",
      "Train[3/10][470/938] Loss: 0.10615921020507812\n",
      "Train[3/10][471/938] Loss: 0.11747145652770996\n",
      "Train[3/10][472/938] Loss: 0.11131048202514648\n",
      "Train[3/10][473/938] Loss: 0.11536288261413574\n",
      "Train[3/10][474/938] Loss: 0.1117546558380127\n",
      "Train[3/10][475/938] Loss: 0.11039137840270996\n",
      "Train[3/10][476/938] Loss: 0.11760830879211426\n",
      "Train[3/10][477/938] Loss: 0.11059212684631348\n",
      "Train[3/10][478/938] Loss: 0.12321877479553223\n",
      "Train[3/10][479/938] Loss: 0.10887312889099121\n",
      "Train[3/10][480/938] Loss: 0.11872124671936035\n",
      "Train[3/10][481/938] Loss: 0.11230778694152832\n",
      "Train[3/10][482/938] Loss: 0.11738848686218262\n",
      "Train[3/10][483/938] Loss: 0.11142563819885254\n",
      "Train[3/10][484/938] Loss: 0.11194777488708496\n",
      "Train[3/10][485/938] Loss: 0.11181211471557617\n",
      "Train[3/10][486/938] Loss: 0.10794496536254883\n",
      "Train[3/10][487/938] Loss: 0.11309480667114258\n",
      "Train[3/10][488/938] Loss: 0.11084747314453125\n",
      "Train[3/10][489/938] Loss: 0.11491036415100098\n",
      "Train[3/10][490/938] Loss: 0.11155819892883301\n",
      "Train[3/10][491/938] Loss: 0.11494684219360352\n",
      "Train[3/10][492/938] Loss: 0.11851882934570312\n",
      "Train[3/10][493/938] Loss: 0.11958909034729004\n",
      "Train[3/10][494/938] Loss: 0.11849141120910645\n",
      "Train[3/10][495/938] Loss: 0.11164617538452148\n",
      "Train[3/10][496/938] Loss: 0.10969758033752441\n",
      "Train[3/10][497/938] Loss: 0.11216020584106445\n",
      "Train[3/10][498/938] Loss: 0.11658787727355957\n",
      "Train[3/10][499/938] Loss: 0.11332583427429199\n",
      "Train[3/10][500/938] Loss: 0.11289358139038086\n",
      "Train[3/10][501/938] Loss: 0.11379480361938477\n",
      "Train[3/10][502/938] Loss: 0.11114287376403809\n",
      "Train[3/10][503/938] Loss: 0.1169276237487793\n",
      "Train[3/10][504/938] Loss: 0.11287450790405273\n",
      "Train[3/10][505/938] Loss: 0.12177586555480957\n",
      "Train[3/10][506/938] Loss: 0.10465431213378906\n",
      "Train[3/10][507/938] Loss: 0.12291145324707031\n",
      "Train[3/10][508/938] Loss: 0.11482524871826172\n",
      "Train[3/10][509/938] Loss: 0.11226177215576172\n",
      "Train[3/10][510/938] Loss: 0.11497330665588379\n",
      "Train[3/10][511/938] Loss: 0.11501741409301758\n",
      "Train[3/10][512/938] Loss: 0.10889530181884766\n",
      "Train[3/10][513/938] Loss: 0.10909008979797363\n",
      "Train[3/10][514/938] Loss: 0.1179206371307373\n",
      "Train[3/10][515/938] Loss: 0.11900925636291504\n",
      "Train[3/10][516/938] Loss: 0.10722661018371582\n",
      "Train[3/10][517/938] Loss: 0.11337065696716309\n",
      "Train[3/10][518/938] Loss: 0.12164044380187988\n",
      "Train[3/10][519/938] Loss: 0.11455178260803223\n",
      "Train[3/10][520/938] Loss: 0.11645388603210449\n",
      "Train[3/10][521/938] Loss: 0.11167097091674805\n",
      "Train[3/10][522/938] Loss: 0.11868906021118164\n",
      "Train[3/10][523/938] Loss: 0.10962510108947754\n",
      "Train[3/10][524/938] Loss: 0.11353349685668945\n",
      "Train[3/10][525/938] Loss: 0.11468887329101562\n",
      "Train[3/10][526/938] Loss: 0.10844039916992188\n",
      "Train[3/10][527/938] Loss: 0.10888004302978516\n",
      "Train[3/10][528/938] Loss: 0.11101913452148438\n",
      "Train[3/10][529/938] Loss: 0.10742926597595215\n",
      "Train[3/10][530/938] Loss: 0.11676430702209473\n",
      "Train[3/10][531/938] Loss: 0.10718727111816406\n",
      "Train[3/10][532/938] Loss: 0.10989856719970703\n",
      "Train[3/10][533/938] Loss: 0.11193966865539551\n",
      "Train[3/10][534/938] Loss: 0.11019587516784668\n",
      "Train[3/10][535/938] Loss: 0.1126246452331543\n",
      "Train[3/10][536/938] Loss: 0.11365079879760742\n",
      "Train[3/10][537/938] Loss: 0.11545062065124512\n",
      "Train[3/10][538/938] Loss: 0.10930538177490234\n",
      "Train[3/10][539/938] Loss: 0.11313819885253906\n",
      "Train[3/10][540/938] Loss: 0.11216211318969727\n",
      "Train[3/10][541/938] Loss: 0.10853195190429688\n",
      "Train[3/10][542/938] Loss: 0.10869359970092773\n",
      "Train[3/10][543/938] Loss: 0.11451125144958496\n",
      "Train[3/10][544/938] Loss: 0.12519311904907227\n",
      "Train[3/10][545/938] Loss: 0.1166684627532959\n",
      "Train[3/10][546/938] Loss: 0.11252236366271973\n",
      "Train[3/10][547/938] Loss: 0.11291027069091797\n",
      "Train[3/10][548/938] Loss: 0.10954785346984863\n",
      "Train[3/10][549/938] Loss: 0.11350250244140625\n",
      "Train[3/10][550/938] Loss: 0.1153862476348877\n",
      "Train[3/10][551/938] Loss: 0.1137533187866211\n",
      "Train[3/10][552/938] Loss: 0.1131277084350586\n",
      "Train[3/10][553/938] Loss: 0.10944676399230957\n",
      "Train[3/10][554/938] Loss: 0.1151266098022461\n",
      "Train[3/10][555/938] Loss: 0.10927462577819824\n",
      "Train[3/10][556/938] Loss: 0.11744332313537598\n",
      "Train[3/10][557/938] Loss: 0.10696196556091309\n",
      "Train[3/10][558/938] Loss: 0.11119842529296875\n",
      "Train[3/10][559/938] Loss: 0.10931634902954102\n",
      "Train[3/10][560/938] Loss: 0.11009550094604492\n",
      "Train[3/10][561/938] Loss: 0.10950613021850586\n",
      "Train[3/10][562/938] Loss: 0.10878658294677734\n",
      "Train[3/10][563/938] Loss: 0.1204078197479248\n",
      "Train[3/10][564/938] Loss: 0.11723113059997559\n",
      "Train[3/10][565/938] Loss: 0.11433267593383789\n",
      "Train[3/10][566/938] Loss: 0.10850310325622559\n",
      "Train[3/10][567/938] Loss: 0.11512184143066406\n",
      "Train[3/10][568/938] Loss: 0.1131134033203125\n",
      "Train[3/10][569/938] Loss: 0.10901188850402832\n",
      "Train[3/10][570/938] Loss: 0.11649608612060547\n",
      "Train[3/10][571/938] Loss: 0.11798310279846191\n",
      "Train[3/10][572/938] Loss: 0.10864734649658203\n",
      "Train[3/10][573/938] Loss: 0.10831642150878906\n",
      "Train[3/10][574/938] Loss: 0.11159300804138184\n",
      "Train[3/10][575/938] Loss: 0.11300849914550781\n",
      "Train[3/10][576/938] Loss: 0.11400890350341797\n",
      "Train[3/10][577/938] Loss: 0.12259578704833984\n",
      "Train[3/10][578/938] Loss: 0.1156156063079834\n",
      "Train[3/10][579/938] Loss: 0.11280107498168945\n",
      "Train[3/10][580/938] Loss: 0.12797284126281738\n",
      "Train[3/10][581/938] Loss: 0.11403632164001465\n",
      "Train[3/10][582/938] Loss: 0.11341261863708496\n",
      "Train[3/10][583/938] Loss: 0.10821843147277832\n",
      "Train[3/10][584/938] Loss: 0.11493897438049316\n",
      "Train[3/10][585/938] Loss: 0.1184244155883789\n",
      "Train[3/10][586/938] Loss: 0.11311674118041992\n",
      "Train[3/10][587/938] Loss: 0.11115503311157227\n",
      "Train[3/10][588/938] Loss: 0.10633182525634766\n",
      "Train[3/10][589/938] Loss: 0.11411666870117188\n",
      "Train[3/10][590/938] Loss: 0.12057209014892578\n",
      "Train[3/10][591/938] Loss: 0.11467885971069336\n",
      "Train[3/10][592/938] Loss: 0.11607789993286133\n",
      "Train[3/10][593/938] Loss: 0.11357808113098145\n",
      "Train[3/10][594/938] Loss: 0.10714268684387207\n",
      "Train[3/10][595/938] Loss: 0.09954285621643066\n",
      "Train[3/10][596/938] Loss: 0.1165616512298584\n",
      "Train[3/10][597/938] Loss: 0.11612749099731445\n",
      "Train[3/10][598/938] Loss: 0.10010480880737305\n",
      "Train[3/10][599/938] Loss: 0.10851073265075684\n",
      "Train[3/10][600/938] Loss: 0.11179876327514648\n",
      "Train[3/10][601/938] Loss: 0.11270999908447266\n",
      "Train[3/10][602/938] Loss: 0.11167144775390625\n",
      "Train[3/10][603/938] Loss: 0.12259578704833984\n",
      "Train[3/10][604/938] Loss: 0.11105799674987793\n",
      "Train[3/10][605/938] Loss: 0.12241053581237793\n",
      "Train[3/10][606/938] Loss: 0.11411690711975098\n",
      "Train[3/10][607/938] Loss: 0.11614727973937988\n",
      "Train[3/10][608/938] Loss: 0.11621499061584473\n",
      "Train[3/10][609/938] Loss: 0.11055493354797363\n",
      "Train[3/10][610/938] Loss: 0.1070871353149414\n",
      "Train[3/10][611/938] Loss: 0.11354231834411621\n",
      "Train[3/10][612/938] Loss: 0.11447024345397949\n",
      "Train[3/10][613/938] Loss: 0.10857439041137695\n",
      "Train[3/10][614/938] Loss: 0.11160874366760254\n",
      "Train[3/10][615/938] Loss: 0.10219645500183105\n",
      "Train[3/10][616/938] Loss: 0.11435389518737793\n",
      "Train[3/10][617/938] Loss: 0.11076116561889648\n",
      "Train[3/10][618/938] Loss: 0.11553645133972168\n",
      "Train[3/10][619/938] Loss: 0.11339712142944336\n",
      "Train[3/10][620/938] Loss: 0.12100052833557129\n",
      "Train[3/10][621/938] Loss: 0.1077418327331543\n",
      "Train[3/10][622/938] Loss: 0.11569786071777344\n",
      "Train[3/10][623/938] Loss: 0.10378813743591309\n",
      "Train[3/10][624/938] Loss: 0.10576272010803223\n",
      "Train[3/10][625/938] Loss: 0.11676669120788574\n",
      "Train[3/10][626/938] Loss: 0.12105703353881836\n",
      "Train[3/10][627/938] Loss: 0.11746644973754883\n",
      "Train[3/10][628/938] Loss: 0.11366987228393555\n",
      "Train[3/10][629/938] Loss: 0.10487794876098633\n",
      "Train[3/10][630/938] Loss: 0.10891413688659668\n",
      "Train[3/10][631/938] Loss: 0.11263370513916016\n",
      "Train[3/10][632/938] Loss: 0.10874819755554199\n",
      "Train[3/10][633/938] Loss: 0.11550736427307129\n",
      "Train[3/10][634/938] Loss: 0.10728096961975098\n",
      "Train[3/10][635/938] Loss: 0.1068265438079834\n",
      "Train[3/10][636/938] Loss: 0.10619235038757324\n",
      "Train[3/10][637/938] Loss: 0.11598396301269531\n",
      "Train[3/10][638/938] Loss: 0.10969042778015137\n",
      "Train[3/10][639/938] Loss: 0.11076641082763672\n",
      "Train[3/10][640/938] Loss: 0.1104879379272461\n",
      "Train[3/10][641/938] Loss: 0.10519719123840332\n",
      "Train[3/10][642/938] Loss: 0.11500787734985352\n",
      "Train[3/10][643/938] Loss: 0.11120152473449707\n",
      "Train[3/10][644/938] Loss: 0.11533331871032715\n",
      "Train[3/10][645/938] Loss: 0.10500049591064453\n",
      "Train[3/10][646/938] Loss: 0.11282181739807129\n",
      "Train[3/10][647/938] Loss: 0.11513829231262207\n",
      "Train[3/10][648/938] Loss: 0.1090536117553711\n",
      "Train[3/10][649/938] Loss: 0.11670780181884766\n",
      "Train[3/10][650/938] Loss: 0.11469078063964844\n",
      "Train[3/10][651/938] Loss: 0.113311767578125\n",
      "Train[3/10][652/938] Loss: 0.10768938064575195\n",
      "Train[3/10][653/938] Loss: 0.11257076263427734\n",
      "Train[3/10][654/938] Loss: 0.10244965553283691\n",
      "Train[3/10][655/938] Loss: 0.1048431396484375\n",
      "Train[3/10][656/938] Loss: 0.10368704795837402\n",
      "Train[3/10][657/938] Loss: 0.10605549812316895\n",
      "Train[3/10][658/938] Loss: 0.11542510986328125\n",
      "Train[3/10][659/938] Loss: 0.11420774459838867\n",
      "Train[3/10][660/938] Loss: 0.1102294921875\n",
      "Train[3/10][661/938] Loss: 0.11103558540344238\n",
      "Train[3/10][662/938] Loss: 0.1167135238647461\n",
      "Train[3/10][663/938] Loss: 0.11204934120178223\n",
      "Train[3/10][664/938] Loss: 0.11182570457458496\n",
      "Train[3/10][665/938] Loss: 0.10684919357299805\n",
      "Train[3/10][666/938] Loss: 0.10256767272949219\n",
      "Train[3/10][667/938] Loss: 0.11091971397399902\n",
      "Train[3/10][668/938] Loss: 0.10677957534790039\n",
      "Train[3/10][669/938] Loss: 0.10407710075378418\n",
      "Train[3/10][670/938] Loss: 0.11896157264709473\n",
      "Train[3/10][671/938] Loss: 0.11558294296264648\n",
      "Train[3/10][672/938] Loss: 0.1157233715057373\n",
      "Train[3/10][673/938] Loss: 0.10881209373474121\n",
      "Train[3/10][674/938] Loss: 0.1152646541595459\n",
      "Train[3/10][675/938] Loss: 0.11287117004394531\n",
      "Train[3/10][676/938] Loss: 0.11699128150939941\n",
      "Train[3/10][677/938] Loss: 0.11042523384094238\n",
      "Train[3/10][678/938] Loss: 0.11231517791748047\n",
      "Train[3/10][679/938] Loss: 0.10614609718322754\n",
      "Train[3/10][680/938] Loss: 0.1179051399230957\n",
      "Train[3/10][681/938] Loss: 0.10611128807067871\n",
      "Train[3/10][682/938] Loss: 0.10987281799316406\n",
      "Train[3/10][683/938] Loss: 0.11684131622314453\n",
      "Train[3/10][684/938] Loss: 0.10447955131530762\n",
      "Train[3/10][685/938] Loss: 0.11300945281982422\n",
      "Train[3/10][686/938] Loss: 0.12038803100585938\n",
      "Train[3/10][687/938] Loss: 0.10218358039855957\n",
      "Train[3/10][688/938] Loss: 0.11340713500976562\n",
      "Train[3/10][689/938] Loss: 0.10866975784301758\n",
      "Train[3/10][690/938] Loss: 0.11101794242858887\n",
      "Train[3/10][691/938] Loss: 0.10884928703308105\n",
      "Train[3/10][692/938] Loss: 0.10800480842590332\n",
      "Train[3/10][693/938] Loss: 0.11164665222167969\n",
      "Train[3/10][694/938] Loss: 0.11959362030029297\n",
      "Train[3/10][695/938] Loss: 0.11482834815979004\n",
      "Train[3/10][696/938] Loss: 0.10372710227966309\n",
      "Train[3/10][697/938] Loss: 0.10833215713500977\n",
      "Train[3/10][698/938] Loss: 0.10804152488708496\n",
      "Train[3/10][699/938] Loss: 0.10585141181945801\n",
      "Train[3/10][700/938] Loss: 0.10593485832214355\n",
      "Train[3/10][701/938] Loss: 0.10109233856201172\n",
      "Train[3/10][702/938] Loss: 0.11133337020874023\n",
      "Train[3/10][703/938] Loss: 0.12223410606384277\n",
      "Train[3/10][704/938] Loss: 0.10731887817382812\n",
      "Train[3/10][705/938] Loss: 0.11425924301147461\n",
      "Train[3/10][706/938] Loss: 0.10545825958251953\n",
      "Train[3/10][707/938] Loss: 0.10806989669799805\n",
      "Train[3/10][708/938] Loss: 0.11586809158325195\n",
      "Train[3/10][709/938] Loss: 0.11083626747131348\n",
      "Train[3/10][710/938] Loss: 0.1111757755279541\n",
      "Train[3/10][711/938] Loss: 0.11481547355651855\n",
      "Train[3/10][712/938] Loss: 0.11090874671936035\n",
      "Train[3/10][713/938] Loss: 0.10107088088989258\n",
      "Train[3/10][714/938] Loss: 0.11803817749023438\n",
      "Train[3/10][715/938] Loss: 0.10986971855163574\n",
      "Train[3/10][716/938] Loss: 0.11272621154785156\n",
      "Train[3/10][717/938] Loss: 0.10715627670288086\n",
      "Train[3/10][718/938] Loss: 0.1150810718536377\n",
      "Train[3/10][719/938] Loss: 0.11120843887329102\n",
      "Train[3/10][720/938] Loss: 0.11718463897705078\n",
      "Train[3/10][721/938] Loss: 0.10817503929138184\n",
      "Train[3/10][722/938] Loss: 0.1086721420288086\n",
      "Train[3/10][723/938] Loss: 0.10733532905578613\n",
      "Train[3/10][724/938] Loss: 0.11556577682495117\n",
      "Train[3/10][725/938] Loss: 0.1038060188293457\n",
      "Train[3/10][726/938] Loss: 0.11732602119445801\n",
      "Train[3/10][727/938] Loss: 0.1017293930053711\n",
      "Train[3/10][728/938] Loss: 0.11957144737243652\n",
      "Train[3/10][729/938] Loss: 0.11014676094055176\n",
      "Train[3/10][730/938] Loss: 0.11620450019836426\n",
      "Train[3/10][731/938] Loss: 0.10423064231872559\n",
      "Train[3/10][732/938] Loss: 0.11065793037414551\n",
      "Train[3/10][733/938] Loss: 0.11084985733032227\n",
      "Train[3/10][734/938] Loss: 0.11162066459655762\n",
      "Train[3/10][735/938] Loss: 0.10622620582580566\n",
      "Train[3/10][736/938] Loss: 0.11475181579589844\n",
      "Train[3/10][737/938] Loss: 0.11649823188781738\n",
      "Train[3/10][738/938] Loss: 0.10795879364013672\n",
      "Train[3/10][739/938] Loss: 0.10537362098693848\n",
      "Train[3/10][740/938] Loss: 0.10787224769592285\n",
      "Train[3/10][741/938] Loss: 0.11239981651306152\n",
      "Train[3/10][742/938] Loss: 0.1054999828338623\n",
      "Train[3/10][743/938] Loss: 0.11110043525695801\n",
      "Train[3/10][744/938] Loss: 0.09976410865783691\n",
      "Train[3/10][745/938] Loss: 0.10619235038757324\n",
      "Train[3/10][746/938] Loss: 0.11003303527832031\n",
      "Train[3/10][747/938] Loss: 0.11329412460327148\n",
      "Train[3/10][748/938] Loss: 0.10808444023132324\n",
      "Train[3/10][749/938] Loss: 0.11642575263977051\n",
      "Train[3/10][750/938] Loss: 0.10495495796203613\n",
      "Train[3/10][751/938] Loss: 0.10490274429321289\n",
      "Train[3/10][752/938] Loss: 0.10614490509033203\n",
      "Train[3/10][753/938] Loss: 0.1110696792602539\n",
      "Train[3/10][754/938] Loss: 0.11451983451843262\n",
      "Train[3/10][755/938] Loss: 0.10525870323181152\n",
      "Train[3/10][756/938] Loss: 0.10361409187316895\n",
      "Train[3/10][757/938] Loss: 0.10552525520324707\n",
      "Train[3/10][758/938] Loss: 0.10718321800231934\n",
      "Train[3/10][759/938] Loss: 0.11769366264343262\n",
      "Train[3/10][760/938] Loss: 0.11191511154174805\n",
      "Train[3/10][761/938] Loss: 0.10740828514099121\n",
      "Train[3/10][762/938] Loss: 0.10620951652526855\n",
      "Train[3/10][763/938] Loss: 0.10611128807067871\n",
      "Train[3/10][764/938] Loss: 0.11234807968139648\n",
      "Train[3/10][765/938] Loss: 0.10176658630371094\n",
      "Train[3/10][766/938] Loss: 0.10862541198730469\n",
      "Train[3/10][767/938] Loss: 0.10704565048217773\n",
      "Train[3/10][768/938] Loss: 0.11505365371704102\n",
      "Train[3/10][769/938] Loss: 0.1058499813079834\n",
      "Train[3/10][770/938] Loss: 0.11542272567749023\n",
      "Train[3/10][771/938] Loss: 0.11768746376037598\n",
      "Train[3/10][772/938] Loss: 0.10300660133361816\n",
      "Train[3/10][773/938] Loss: 0.1107325553894043\n",
      "Train[3/10][774/938] Loss: 0.11207723617553711\n",
      "Train[3/10][775/938] Loss: 0.10616898536682129\n",
      "Train[3/10][776/938] Loss: 0.10509753227233887\n",
      "Train[3/10][777/938] Loss: 0.10735917091369629\n",
      "Train[3/10][778/938] Loss: 0.11095499992370605\n",
      "Train[3/10][779/938] Loss: 0.10238313674926758\n",
      "Train[3/10][780/938] Loss: 0.1128227710723877\n",
      "Train[3/10][781/938] Loss: 0.10663604736328125\n",
      "Train[3/10][782/938] Loss: 0.11042356491088867\n",
      "Train[3/10][783/938] Loss: 0.10477566719055176\n",
      "Train[3/10][784/938] Loss: 0.10202908515930176\n",
      "Train[3/10][785/938] Loss: 0.10372233390808105\n",
      "Train[3/10][786/938] Loss: 0.1096339225769043\n",
      "Train[3/10][787/938] Loss: 0.10492539405822754\n",
      "Train[3/10][788/938] Loss: 0.10435867309570312\n",
      "Train[3/10][789/938] Loss: 0.10101890563964844\n",
      "Train[3/10][790/938] Loss: 0.10906982421875\n",
      "Train[3/10][791/938] Loss: 0.11576366424560547\n",
      "Train[3/10][792/938] Loss: 0.1085360050201416\n",
      "Train[3/10][793/938] Loss: 0.11551070213317871\n",
      "Train[3/10][794/938] Loss: 0.11357593536376953\n",
      "Train[3/10][795/938] Loss: 0.11284613609313965\n",
      "Train[3/10][796/938] Loss: 0.10702204704284668\n",
      "Train[3/10][797/938] Loss: 0.10123395919799805\n",
      "Train[3/10][798/938] Loss: 0.10763144493103027\n",
      "Train[3/10][799/938] Loss: 0.10169339179992676\n",
      "Train[3/10][800/938] Loss: 0.11303234100341797\n",
      "Train[3/10][801/938] Loss: 0.10510540008544922\n",
      "Train[3/10][802/938] Loss: 0.1152198314666748\n",
      "Train[3/10][803/938] Loss: 0.11075091361999512\n",
      "Train[3/10][804/938] Loss: 0.11125802993774414\n",
      "Train[3/10][805/938] Loss: 0.10686206817626953\n",
      "Train[3/10][806/938] Loss: 0.10056471824645996\n",
      "Train[3/10][807/938] Loss: 0.10769319534301758\n",
      "Train[3/10][808/938] Loss: 0.10919570922851562\n",
      "Train[3/10][809/938] Loss: 0.10274291038513184\n",
      "Train[3/10][810/938] Loss: 0.11107349395751953\n",
      "Train[3/10][811/938] Loss: 0.11253976821899414\n",
      "Train[3/10][812/938] Loss: 0.10504651069641113\n",
      "Train[3/10][813/938] Loss: 0.11333656311035156\n",
      "Train[3/10][814/938] Loss: 0.11357545852661133\n",
      "Train[3/10][815/938] Loss: 0.10663414001464844\n",
      "Train[3/10][816/938] Loss: 0.10975241661071777\n",
      "Train[3/10][817/938] Loss: 0.10144639015197754\n",
      "Train[3/10][818/938] Loss: 0.11121416091918945\n",
      "Train[3/10][819/938] Loss: 0.10184907913208008\n",
      "Train[3/10][820/938] Loss: 0.11718487739562988\n",
      "Train[3/10][821/938] Loss: 0.11410689353942871\n",
      "Train[3/10][822/938] Loss: 0.10206866264343262\n",
      "Train[3/10][823/938] Loss: 0.10548591613769531\n",
      "Train[3/10][824/938] Loss: 0.11120009422302246\n",
      "Train[3/10][825/938] Loss: 0.1088247299194336\n",
      "Train[3/10][826/938] Loss: 0.11038947105407715\n",
      "Train[3/10][827/938] Loss: 0.10194277763366699\n",
      "Train[3/10][828/938] Loss: 0.11176776885986328\n",
      "Train[3/10][829/938] Loss: 0.11137056350708008\n",
      "Train[3/10][830/938] Loss: 0.10889720916748047\n",
      "Train[3/10][831/938] Loss: 0.10420703887939453\n",
      "Train[3/10][832/938] Loss: 0.11475872993469238\n",
      "Train[3/10][833/938] Loss: 0.10566854476928711\n",
      "Train[3/10][834/938] Loss: 0.10933542251586914\n",
      "Train[3/10][835/938] Loss: 0.10957765579223633\n",
      "Train[3/10][836/938] Loss: 0.11477923393249512\n",
      "Train[3/10][837/938] Loss: 0.10298800468444824\n",
      "Train[3/10][838/938] Loss: 0.11576366424560547\n",
      "Train[3/10][839/938] Loss: 0.1080472469329834\n",
      "Train[3/10][840/938] Loss: 0.10774087905883789\n",
      "Train[3/10][841/938] Loss: 0.10534787178039551\n",
      "Train[3/10][842/938] Loss: 0.10599946975708008\n",
      "Train[3/10][843/938] Loss: 0.11185050010681152\n",
      "Train[3/10][844/938] Loss: 0.10744071006774902\n",
      "Train[3/10][845/938] Loss: 0.10449624061584473\n",
      "Train[3/10][846/938] Loss: 0.10853767395019531\n",
      "Train[3/10][847/938] Loss: 0.11572074890136719\n",
      "Train[3/10][848/938] Loss: 0.10574221611022949\n",
      "Train[3/10][849/938] Loss: 0.1084890365600586\n",
      "Train[3/10][850/938] Loss: 0.11082243919372559\n",
      "Train[3/10][851/938] Loss: 0.11228108406066895\n",
      "Train[3/10][852/938] Loss: 0.10560297966003418\n",
      "Train[3/10][853/938] Loss: 0.10888862609863281\n",
      "Train[3/10][854/938] Loss: 0.11472868919372559\n",
      "Train[3/10][855/938] Loss: 0.11571192741394043\n",
      "Train[3/10][856/938] Loss: 0.10654115676879883\n",
      "Train[3/10][857/938] Loss: 0.10848879814147949\n",
      "Train[3/10][858/938] Loss: 0.10526251792907715\n",
      "Train[3/10][859/938] Loss: 0.10289955139160156\n",
      "Train[3/10][860/938] Loss: 0.10687923431396484\n",
      "Train[3/10][861/938] Loss: 0.10396194458007812\n",
      "Train[3/10][862/938] Loss: 0.10236835479736328\n",
      "Train[3/10][863/938] Loss: 0.10577154159545898\n",
      "Train[3/10][864/938] Loss: 0.11179852485656738\n",
      "Train[3/10][865/938] Loss: 0.10068821907043457\n",
      "Train[3/10][866/938] Loss: 0.10991930961608887\n",
      "Train[3/10][867/938] Loss: 0.10174107551574707\n",
      "Train[3/10][868/938] Loss: 0.10285377502441406\n",
      "Train[3/10][869/938] Loss: 0.11377429962158203\n",
      "Train[3/10][870/938] Loss: 0.10533618927001953\n",
      "Train[3/10][871/938] Loss: 0.10176610946655273\n",
      "Train[3/10][872/938] Loss: 0.10647130012512207\n",
      "Train[3/10][873/938] Loss: 0.10370659828186035\n",
      "Train[3/10][874/938] Loss: 0.10597681999206543\n",
      "Train[3/10][875/938] Loss: 0.11502242088317871\n",
      "Train[3/10][876/938] Loss: 0.10811281204223633\n",
      "Train[3/10][877/938] Loss: 0.11034536361694336\n",
      "Train[3/10][878/938] Loss: 0.11268854141235352\n",
      "Train[3/10][879/938] Loss: 0.10735225677490234\n",
      "Train[3/10][880/938] Loss: 0.10467362403869629\n",
      "Train[3/10][881/938] Loss: 0.11318778991699219\n",
      "Train[3/10][882/938] Loss: 0.10893630981445312\n",
      "Train[3/10][883/938] Loss: 0.10360360145568848\n",
      "Train[3/10][884/938] Loss: 0.10368156433105469\n",
      "Train[3/10][885/938] Loss: 0.10764360427856445\n",
      "Train[3/10][886/938] Loss: 0.11061334609985352\n",
      "Train[3/10][887/938] Loss: 0.11410951614379883\n",
      "Train[3/10][888/938] Loss: 0.10633468627929688\n",
      "Train[3/10][889/938] Loss: 0.10095453262329102\n",
      "Train[3/10][890/938] Loss: 0.09872770309448242\n",
      "Train[3/10][891/938] Loss: 0.10446023941040039\n",
      "Train[3/10][892/938] Loss: 0.10545969009399414\n",
      "Train[3/10][893/938] Loss: 0.1017906665802002\n",
      "Train[3/10][894/938] Loss: 0.10406303405761719\n",
      "Train[3/10][895/938] Loss: 0.1038975715637207\n",
      "Train[3/10][896/938] Loss: 0.10717964172363281\n",
      "Train[3/10][897/938] Loss: 0.11023235321044922\n",
      "Train[3/10][898/938] Loss: 0.10562777519226074\n",
      "Train[3/10][899/938] Loss: 0.10595321655273438\n",
      "Train[3/10][900/938] Loss: 0.10155749320983887\n",
      "Train[3/10][901/938] Loss: 0.1112067699432373\n",
      "Train[3/10][902/938] Loss: 0.10392284393310547\n",
      "Train[3/10][903/938] Loss: 0.12012910842895508\n",
      "Train[3/10][904/938] Loss: 0.10963821411132812\n",
      "Train[3/10][905/938] Loss: 0.10316610336303711\n",
      "Train[3/10][906/938] Loss: 0.10896778106689453\n",
      "Train[3/10][907/938] Loss: 0.11140561103820801\n",
      "Train[3/10][908/938] Loss: 0.11252307891845703\n",
      "Train[3/10][909/938] Loss: 0.1129612922668457\n",
      "Train[3/10][910/938] Loss: 0.09989070892333984\n",
      "Train[3/10][911/938] Loss: 0.11705160140991211\n",
      "Train[3/10][912/938] Loss: 0.11451387405395508\n",
      "Train[3/10][913/938] Loss: 0.10976481437683105\n",
      "Train[3/10][914/938] Loss: 0.10266709327697754\n",
      "Train[3/10][915/938] Loss: 0.10889029502868652\n",
      "Train[3/10][916/938] Loss: 0.10470032691955566\n",
      "Train[3/10][917/938] Loss: 0.10757589340209961\n",
      "Train[3/10][918/938] Loss: 0.10502266883850098\n",
      "Train[3/10][919/938] Loss: 0.1052548885345459\n",
      "Train[3/10][920/938] Loss: 0.10807609558105469\n",
      "Train[3/10][921/938] Loss: 0.10154080390930176\n",
      "Train[3/10][922/938] Loss: 0.10262012481689453\n",
      "Train[3/10][923/938] Loss: 0.11058759689331055\n",
      "Train[3/10][924/938] Loss: 0.10985064506530762\n",
      "Train[3/10][925/938] Loss: 0.10869574546813965\n",
      "Train[3/10][926/938] Loss: 0.10767555236816406\n",
      "Train[3/10][927/938] Loss: 0.1073904037475586\n",
      "Train[3/10][928/938] Loss: 0.10611581802368164\n",
      "Train[3/10][929/938] Loss: 0.10683584213256836\n",
      "Train[3/10][930/938] Loss: 0.10427331924438477\n",
      "Train[3/10][931/938] Loss: 0.09745597839355469\n",
      "Train[3/10][932/938] Loss: 0.10262465476989746\n",
      "Train[3/10][933/938] Loss: 0.10699772834777832\n",
      "Train[3/10][934/938] Loss: 0.10316157341003418\n",
      "Train[3/10][935/938] Loss: 0.10248208045959473\n",
      "Train[3/10][936/938] Loss: 0.10601019859313965\n",
      "Train[3/10][937/938] Loss: 0.11519432067871094\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. None expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#test_loss = net.test_net(train_loader, max_batch, start_epoch, max_epoch, save_output=True)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[18], line 158\u001b[0m, in \u001b[0;36mSAE_2DconvTT_small.train_net\u001b[1;34m(self, trainloader, optimizer, max_batch, start_epoch, max_epoch, save_output, save_model)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (batch_idx \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(trainloader) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m save_output:\n\u001b[0;32m    155\u001b[0m \u001b[38;5;66;03m#if (batch_idx == max_batch - 1) and save_output:\u001b[39;00m\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# Save output\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_output(real_img, x_recon, epoch, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 158\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_umap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatent_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;66;03m# Store model\u001b[39;00m\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m save_model:\n",
      "Cell \u001b[1;32mIn[10], line 153\u001b[0m, in \u001b[0;36mSAE.plot_umap\u001b[1;34m(self, data, labels, epoch, mode)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;66;03m# Apply UMAP to reduce dimensionality\u001b[39;00m\n\u001b[0;32m    152\u001b[0m reducer \u001b[38;5;241m=\u001b[39m umap\u001b[38;5;241m.\u001b[39mUMAP()\n\u001b[1;32m--> 153\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[43mreducer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(embedding[:, \u001b[38;5;241m0\u001b[39m], embedding[:, \u001b[38;5;241m1\u001b[39m], c\u001b[38;5;241m=\u001b[39mlabels, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSpectral\u001b[39m\u001b[38;5;124m'\u001b[39m, s\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m    156\u001b[0m plt\u001b[38;5;241m.\u001b[39mgca()\u001b[38;5;241m.\u001b[39mset_aspect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mequal\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatalim\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32me:\\Dev\\envs\\snn\\Lib\\site-packages\\umap\\umap_.py:2887\u001b[0m, in \u001b[0;36mUMAP.fit_transform\u001b[1;34m(self, X, y, force_all_finite)\u001b[0m\n\u001b[0;32m   2851\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   2852\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit X into an embedded space and return that transformed\u001b[39;00m\n\u001b[0;32m   2853\u001b[0m \u001b[38;5;124;03m    output.\u001b[39;00m\n\u001b[0;32m   2854\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2885\u001b[0m \u001b[38;5;124;03m        Local radii of data points in the embedding (log-transformed).\u001b[39;00m\n\u001b[0;32m   2886\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2887\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2888\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   2889\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dens:\n",
      "File \u001b[1;32me:\\Dev\\envs\\snn\\Lib\\site-packages\\umap\\umap_.py:2354\u001b[0m, in \u001b[0;36mUMAP.fit\u001b[1;34m(self, X, y, force_all_finite)\u001b[0m\n\u001b[0;32m   2328\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   2329\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit X into an embedded space.\u001b[39;00m\n\u001b[0;32m   2330\u001b[0m \n\u001b[0;32m   2331\u001b[0m \u001b[38;5;124;03m    Optionally use y for supervised dimension reduction.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2351\u001b[0m \u001b[38;5;124;03m                                 Values cannot be infinite.\u001b[39;00m\n\u001b[0;32m   2352\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2354\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2355\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raw_data \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m   2357\u001b[0m     \u001b[38;5;66;03m# Handle all the optional arguments, setting default\u001b[39;00m\n",
      "File \u001b[1;32me:\\Dev\\envs\\snn\\Lib\\site-packages\\sklearn\\utils\\validation.py:951\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    946\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    947\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    948\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    949\u001b[0m     )\n\u001b[0;32m    950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nd \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m--> 951\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    952\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    953\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    954\u001b[0m     )\n\u001b[0;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m    957\u001b[0m     _assert_all_finite(\n\u001b[0;32m    958\u001b[0m         array,\n\u001b[0;32m    959\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    960\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    961\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    962\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with dim 3. None expected <= 2."
     ]
    }
   ],
   "source": [
    "train_loss = net.train_net(train_loader, optimizer, max_batch, start_epoch, max_epoch, save_output=True, save_model=True)\n",
    "#test_loss = net.test_net(train_loader, max_batch, start_epoch, max_epoch, save_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e3edef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(704, 32, 32)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABugAAATSCAYAAABcsmLjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdd3xV9f3H8fe5K3tAIGHvvaeggIgMQVFB6x6/tlirta5Krdb2R2trbW2tWFFr1Vb92Qp1L5YMFZQhQ/aGABmQkL3vOr8/Qq4JJCE3JDkZr2cfPHrPued8z/ve3MTkfu7n+zVM0zQFAAAAAAAAAAAAoEHYrA4AAAAAAAAAAAAAtCQU6AAAAAAAAAAAAIAGRIEOAAAAAAAAAAAAaEAU6AAAAAAAAAAAAIAGRIEOAAAAAAAAAAAAaEAU6AAAAAAAAAAAAIAGRIEOAAAAAAAAAAAAaEAU6AAAAAAAAAAAAIAGRIEOAAAAaEI8Ho/VEYDz1lRfx001NwAAAIDGx2F1AAAAgMq89957evTRRyVJF1xwgf7v//4vqPNvu+02bdy4UZL05JNP6pprrqly/DI//vGP9bOf/Syo6xQWFuqiiy5SUVFRYN/vf/97XXfddTU6f/fu3Zo9e3Zg+3vf+56eeOKJGl9/w4YNuv322895nM1mU2hoqGJiYtS9e3eNHj1aV155pTp37lzjazU3zz33nBYsWCCp8tdIY1NcXKwFCxYoIiJCd99991n3P/LII3r//fclSW+88YbGjBnT0BGbhKKiIr3yyitavny5UlNTVVxcrKioKF188cX605/+VKsxPR6PJkyYoKysLElSt27dtHTpUhmGUeMx+vbtW6trl1fbr3vZtTt27KhVq1add47qnOt13JitXr1a//znP4P+71GZpKQkTZ48WVLt/rsGAAAAoHmhgw4AAOC0pUuXBn3O6tWrKxTngvXuu+9W2F68eLHy8/NrPV5V/H6/CgsLlZqaqq+//lrPPvusZsyYofnz59f5tVD39u3bpyuuuEIvv/yyvF6v1XGaLLfbrVtuuUULFizQ/v37lZeXJ4/Ho8zMzKCKaWdatWpVoDgnSYmJiVq3bl1dRG5WmvLr+L777tNdd92l5ORkq6MAAAAAaCbooAMAADjt6NGj2rNnj/r371/jcz799NNaX8/tduuTTz6RJMXExCgnJ0eFhYX64IMPdOuttwY9XkxMjH784x9Xep9pmiouLlZaWppWrlypU6dOyePx6MUXX5TX69XcuXNr/ThQ/3bt2qWkpCSrYzR5H3/8sXbt2iVJcjqdmjFjhnr06KHi4mKNHj261uOWFdrLvo8laeHChbroootqNd5dd92l6OjooM/r0qVLra7XUJry63jZsmVWRwAAAADQzFCgAwAALV5ISIhKSkoklXbR1bRAl5eXpzVr1tT6uitWrFB2drYk6Uc/+pGeeeYZ+Xw+LVy4sFYFusjISM2ZM+ecxz366KP65S9/qcWLF0uS/vnPf2rmzJnq169f0Ndsyu69917de++9VseoM3/84x/1xz/+0eoYjdqePXsCt++++27dc8895z3myZMntXbtWknSJZdcor1792rfvn1auXKl0tLSFB8fH/SY1113nTp16nTe2QAAAAAAjRdTXAIAgBZv7NixcjqdkoKb5vKzzz6T2+2WJA0aNCjo65af3nLatGm64IILJEkHDhzQpk2bgh6vpsLCwvTUU08F1p/z+XxatGhRvV0PaCwKCgoCt4cMGVInY37wwQfy+XySpNGjR2v69OmSJK/Xq7fffrtOrgEAAAAAaH4o0AEAgBYvOjpa48aNk1S6dlT5LpvqlE1v2adPH/Xu3Tuoa544cUJff/21JKlHjx7q2rWrrrjiisD9b731VlDjBcvpdOr6668PbJdlAZoz0zQDt10uV52M+d5770mSDMPQxIkTK3wfv/3224HiHQAAAAAA5THFJQAAgKQZM2bo888/l1SzaS4zMzO1fv16SdLMmTN15MiRoK733nvvye/3SyrtnpOk6dOn6/e//72Ki4u1bNkyPfbYY2rdunWQj6TmevbsGbh98uTJoM9/5JFH9P7770uS9u3bJ7fbrbfeeksffvihjh07JrfbrY4dO2rcuHG6/fbbq1wfKykpSZMnT5YkPfTQQ5ozZ45eeuklLVq0SNnZ2WrXrp3GjBmjuXPnnrUu11dffaUPPvhA3377rdLT0yVJbdq00YgRIzRz5kxdfPHFVeZ/7rnntGDBAknSk08+qWuuuabKY9euXatPPvlEmzZt0qlTp2QYhuLj4zVmzBhde+21Gjp0aI2es7S0NP33v//Vl19+qcOHD6uoqEhRUVHq27evLrvsMl177bUKCQmpNGOZBQsWBPb99Kc/DUzTWf7r8cYbb2jMmDGVZnC73froo4+0YsUK7dq1S1lZWQoLC1O7du00duxYXX/99dUWnMuu43K5tGPHDvn9fn300Uf6+OOPtX//fmVlZSk2NlZDhw7V7NmzNWXKlBo9NzWxbds2vfPOO9q0aZNOnDghn8+nNm3aaNCgQZo+fbqmT58um63iZxA3bNig22+//ayxyu+bPXt2raYH3bRpkxITEyVJw4cPD0xnOXz4cG3dulWpqan6/PPPA6/vpm7Hjh1avHixNm3apNTUVGVnZ8vpdComJkb9+vXTpEmTNHv27LOKn8G8jsvLysrSokWL9MUXX+jo0aPKzc1VTEyMevXqpUsvvVTXX3+9wsLCqszbt29fSdINN9ygxx9/XOnp6frPf/6jVatWKSUlRR6PR+3atdP48eN12223qWvXrhXOL/+zqUxycnJg3I4dO2rVqlU1fPaCs27dOq1YsUKbN29WWlqacnNzFRISotjYWA0aNEhTp07VjBkzZLfbK5z35z//Wa+88oqkmr2u3W63xo8fr5ycHMXExGjt2rVnff1M09SyZcu0ZMkSbd++XRkZGXK5XGrfvr3Gjh2rG2+8scJ/T8502223aePGjerevbuWLl2qDRs26K9//av27Nmj6OhoDRgwQHPmzKnyZxYAAADQXFGgAwAAkDRlyhS5XC653W4tXbpUDz74YLXHL1u2TF6vV5J0+eWX6/nnn6/xtUzTDBRSJOnKK6+UJEVFRWnKlCn65JNP5PF49O677+pHP/pRLR5NzZR/Y/fMN3mDlZ2drTvvvFPbtm2rsP/w4cM6fPiwFi5cqCeeeEJXX331Ocd68skn9X//93+B7cTEROXl5WnevHmBfSdOnNDDDz+sDRs2nHX+8ePHdfz4cX344YcaM2aM/vrXv6pNmza1flwPPfRQYI2x8hITE5WYmKhFixZp9uzZ+u1vf1uhuHam119/XU8//XRgvcMyWVlZWr9+vdavX6/XX39dL7zwQrVvdp+PTZs26eGHH1ZycnKF/R6PR7m5udq/f7/efPNN3XzzzXr00UflcFT/50JWVpbuvfdeffPNNxX2p6ena8WKFVqxYoUuvfRSPfvss+fVsZaTk6P//d//rXQK2uTkZCUnJ2vZsmV66aWX9Oyzz6pbt261vlYwyk9TO3PmzMDt2bNna+vWrZKkhQsXNvkCXX5+vh555BF99tlnZ93n8XhUWFio1NRUrV69Wi+//LJefvllde/e/byu+fHHH+vxxx9Xbm5uhf2nTp3SqVOntH79er388sv6y1/+orFjx55zvDVr1mju3LmBdT/LHDlyREeOHNHChQv1+9//XrNmzTqv3OcrPT1dDzzwQKXTHHs8HuXn5yspKUlLly7VP//5T/3jH/+o8PNt1qxZgQLdZ599ds6fS1988YVycnIklX5Q5czv0+TkZN1///3asWNHhf0lJSXKy8vT/v379e9//1s/+MEP9NBDD51VID/Tt99+qzlz5sjj8QQe7xdffKGbbrqp2vMAAACA5ogCHQAAgKTIyEhNmDBBK1euVGJiovbu3at+/fpVefzixYslSUOHDg2s5VZTGzdu1LFjxyRJgwcPVq9evQL3XXPNNfrkk08kSf/97391xx13yDCMYB9Ojezduzdwu6rutpq69957tW3bNtlsNk2cOFGDBg1SQUGBVqxYoWPHjsnj8egXv/iFfD5ftZ1qGzdu1Jo1a87aP3Xq1EARMT09XTfffHOgyORwODRhwgQNGDBAhmFo165dWrNmjbxerzZs2KDrr79e//3vf4Mu0uXk5OjGG28MdEeGhYXp0ksvVc+ePeXz+bRnzx6tWbNGHo9H77//vlJSUvTPf/6z0qLWggUL9NxzzwW2u3TpookTJ6p169Y6fvy4li1bpoKCAiUmJur222/Xhx9+qDZt2mjcuHEKDw/Xzp07A6+5cePGBaZkHT58eI0fz8aNGzVnzpzAuonR0dG69NJL1bVrVxUWFmr9+vWBjrg333xTx48f19///vcq33A3TVM/+clPtGXLFoWGhurSSy9Vr169VFxcrDVr1gSmil21apWee+45PfTQQzXOWl5BQYF++MMfaufOnZJKp5IcM2aMhg0bJqfTqQMHDujzzz9XcXGx9u7dq+uvv15vvfVWoMjZpUsXPfzww5JKv2/LxrnxxhsDr/tgp6gty1VWMHS5XBUKdJdffrn+8Ic/qLi4WGvXrlVSUpI6depUq8dvNb/frzvuuCNQcAwNDdXEiRPVq1cvhYaGKisrSxs3bgw8r8ePH9f999+vDz74IPDaCfZ1/O9//1uPP/54YLtv37666KKL1KpVq0BB59ixY0pPT9cdd9yhF198URMmTKjyMezdu1cfffSRioqK1KlTJ02aNElt2rRRSkqKli5dqpycHHk8Hv3yl7/UoEGDAj+TY2NjA6+dp556SpIUExOjH//4x5JKP1RRlwoLC3XzzTcH/vsQHR2tiRMnqlu3bnK5XEpLS9PXX3+tQ4cOSZJ27dqlxx57TC+99FJgjN69e2vgwIHatWuX8vPz9cUXXwS6tCvz0UcfBW6f+QGK48eP66abbgp0J8fGxmrSpEnq2rWriouLtX37dq1bt04+n0+vvPKK0tPTA89TZbxer37xi18EinNloqKiAq8FAAAAoCWhQAcAAHDa5ZdfrpUrV0qSlixZUmWBLi0tLdDdcPnllwd9nfJdN2cWqy688EK1b99eqampOnbsmNauXVvtG8+1VVxcrLfffjuwXd1UkDWxceNGxcbG6sUXX9SIESMC+3/2s5/pT3/6k/7v//5PpmnqySef1CWXXFLl1J1lxbk777xTt99+u1wul77++usKBcSf/exngeJct27d9Pzzz1cockqlU27ec889On78uJKTk/XQQw/p9ddfD+oxPfbYY4Hi3Lhx4/TnP/9ZcXFxFY5JTEzUvffeq/3792vDhg164YUXdN9991U4Zvv27RWm97vvvvt01113VehaLJvac+/evTp16pSefvppPfnkkxoxYoRGjBih9957L1DYGD58uObMmRPUY8nJydFPf/rTQHHu0ksv1ZNPPqnY2NgKxy1ZskSPPPKIiouL9cUXX+jFF1/UPffcU+mYHo9HW7Zs0fDhw/Xss88qISGhwuOZP3++XnzxRUnSm2++qXvvvbdWXXS/+93vAsWfNm3a6G9/+5tGjhxZ4Zjk5GTdd9992rlzZ+Cxfvjhh4Fp+MqerwMHDgTGuvzyy89rSr0lS5aosLBQkjR58mTFxMQE7ouKitLUqVP18ccfy+/3a9GiRbUuUFrt/fffDxTnOnbsqDfeeKPSYuOnn36quXPnyu/3a9++fdq8ebNGjx4tSUG9jnfu3Kknn3xSkhQSEqI//OEPFYqfkvToo4/q1Vdf1V//+ld5PB7NnTtXS5YsqfLnSllnb2Xfew888IDmzJmj3bt3y+fz6fXXX9fvfvc7SaUf3CjLWFZ4Kr+vrr3yyiuB4tzAgQP16quvqlWrVpUe9+c//1mS9Pnnnys5OVkdO3YM3D9r1izt2rVLkvTJJ59UWaDLy8sLTO3cpUuXCj+7fT6fHnzwwUBx7sorr9RvfvMbRUZGVhhj+/bt+ulPf6qTJ08GupavvfbaSq93/PhxSdKwYcP0q1/9Sr169dKhQ4d04MCBOlsTEgAAAGhKqp9/AgAAoAWZNGmSQkNDJanSqfTKLFmyRH6/XzabTTNmzAjqGvn5+Vq+fLmks7tuJMlms1WYYm3hwoVBjV8T6enpuueee5SUlCSptDPs1ltvPa8xbTabnn/++Qpv8EqS0+nUr371K02aNEmSlJubq5dffrnasW644QY99NBDatu2rWJiYjRjxgwNHDhQUulacBs3bpRU2l3y2muvnVWck0o7bv71r38F3kxev369vvrqqxo/nu3btwem8+vZs6deeOGFs4pzUmmB8KWXXgq8bl577bWzpuR75ZVXZJqmJOnWW2/VPffcc9aUom3atNGCBQsC3Xcff/yxCgoKapz3XF599dXANHZDhgzRc889d1ZxTiqd4q58B8wrr7wSOK8y0dHR+vvf/16hOFfmvvvuCxRWCwsLtX379qBzHzp0SB9++KGk0tfSP/7xj7OKc1Jp4ehf//qX2rdvL6l0atUPPvgg6OsFo3yhffbs2WfdX75I8e67757VNVSdyZMnq2/fvkH9e++9987vAVWh/HS8jz32WJWdgFdccUWFDxOUFYiC9eyzzwaeq9/+9rdn/YyUSqfkvfPOO3XzzTdLKp2K9o033qh23KuvvrrS773WrVvrl7/8ZWB73bp1tcpdF8q/Zv/whz9UWpyTpDvuuKPCz73du3dXuH/mzJlyOp2SSgt4+fn5lY6zdOnSQNH+qquuqnDfsmXLAtNajh07Vk899dRZxTmp9OfJggULAp3ezz//vHw+X5WPsXXr1nr11Vc1ePBghYWFadCgQZV+/wAAAAAtAQU6AACA0yIiIjRx4kRJCkxzWZmyDpBRo0ZVWpiozuLFi1VUVCSpdN276Ojos44p31X3+eef6+TJkzUaOz8/X6+++mql/1566SU99dRTmjNnjiZNmlRhTbV58+apbdu2QT2OM02bNk2jRo2q8v77778/cHvFihXVjlX2pntlyqb/lKTbb789UJCpTOfOnXXbbbcFtssXVM6lfHfh97///UABrjIdOnQITA1XUFAQ6MKUJLfbHegKdDgcuvvuu6vNO3PmTI0ePVqzZs2qtjAWrPLP29y5c6tdW+6yyy4LFMEKCwu1ZMmSKo+dMWNGpYU+qbRoW/41UdaJE4zFixfL7/dLKi06lBVqKxMdHV2h2y+Yr3ewEhMTtWXLFklSfHy8xo8ff9YxY8eODXQ1ZWRkVLp+W1Nw44036t5779UNN9ygSy65pNpj+/btG7hdVVGoOidPngx8v7Rr1+6c68GV/34qP1VjZar7uVI2XapUusadFdxut+655x795Cc/0Zw5c6qdYlmq+FyfWcxv3bp1oFhaUlJS5c/c8s/ZmQW6d955J3D7zjvvrHZtuSFDhgSmqExOTtbmzZurPPaqq66qtNAHAAAAtERMcQkAAFDOjBkztGzZMkmVT3OZnJysb7/9VpIq7ew4l3N13UilU42NHj1a33zzjbxer/773//q3nvvPefYOTk51a7/c6aoqCj95je/qdXjONMVV1xR7f39+/evMHXn0aNH1bVr17OOi4iIUJ8+faocZ/369YHb1a2rVGbGjBmBaRa/+eabcx5fpqxLT5IGDBhwzuOHDx+uRYsWSZI2b94c+Npu3bo1MA3i4MGDz7kO3p/+9KcaZ6ypsmk+pdI1pGoyreOMGTMCb7J/8803uvHGGys9bujQodWOU74DqKSkpKaRA4L9ek+fPl2//vWvZZqmdu7cqaKiIoWFhQV93XMp/3189dVXn9WVJZWulTdr1iw9//zzkqS33nqrxlPi3nXXXZUW76szePDgoI6vqZr+fMjJyanwYQKv1xv0tb755ptAt2n//v3Puf5m27Zt1bFjRyUnJys5OVknT56s9EMTDoej2u9jp9OpqKgoZWZm1up1WhdcLleVU0Oe6dSpU8rKygpsV9adOWvWLK1atUpSaYH+zGLniRMnAlM1Dx8+vMLPY6/XG5jWVKr5z8CyD35s3rxZF1xwQaXHDRs27JxjAQAAAC0FBToAANAoneuN2foa65JLLlF4eLgKCwu1dOlSPfjggxXu//TTTyWVvqF72WWXBZXj0KFDgeJefHx8oOOgMtdcc02goPT222/rJz/5SaVFgJpyOp2KiIhQXFyc+vfvrzFjxuiKK65QRERErccsr7rOpjK9evVSamqqJCklJaXSAl2HDh2q7NTwer2B851OZ6VTW56pd+/ecjqd8ng8SktLk9vtPudaR16vV0ePHg1s1/RN8zJlGc+8XZO89aFsKlNJ5+zKKdO/f/9Kzz/TuQqO5YtjZYWXYJS/dvlMVYmKilKnTp10/PjxwOulR48eQV+3Oj6fr8JUhNVNzzd79my98MILMk1TGzdu1KFDh9SzZ89zXuO6666rcipJq+Xk5CgxMVHHjh3TsWPHdPjwYe3du1eHDh2q8DWuzdf74MGDgdurV6+u0CVWEykpKZUW6KKjo8/5fV/2Wi3r2GwMMjIydOTIER0/flzHjh3ToUOHtGfPnsA6ddWZNGmSYmJilJOTo3Xr1ikzM7PCGn2ffPJJ4LGWdQCXSUlJCXywQCrtBg1G+Z97Z2qsr2sAAADAChToAABAo1R+Cr7q1rOpSvkuiLKpy2oiLCxMl1xyiRYvXhyY5rJ8UaNsesuLLrqoyqn9qlJ+yrC0tLQadSVIpdO+rV69WlOmTKn2uI4dOwY6JhpaZeuznSkmJiZwu6pp5KKioqo8v/yUj5GRkTUqWNpstkBnjFS6VlV8fHy15+Tm5taquFAmOzs7cLvsupKC7oiqK+U7bcp/DapT/rVd/vGcqbqpP89Um+e0/LWDyX78+HFJqtNpQsusWbNGaWlpge2adsVJpWtKPvbYY3Weqb653W4tXLhQb7/9tvbv31/lcXa7vVY/r8uc79erqvPro4uyvuTn5+v111/X+++/H3gdV+Zcz7XL5dLll1+ut956S16vV0uXLq0wzWfZ9JZOp/OstVSr+56vierOt+rnIAAAANAYUaADAACNUnh4eOB2cXFx0OeXrfN25lg1cfnllwcKcUuXLg0U6A4fPqw9e/ZIOveUjmfyer3nXCOpOm+99dY5C3RWqm5NszLl30yuqmha3Ti1LZqV74ipSTflmVPzzZ07t9r1l85UvlhZm2n+GoPyX6u67GYNVm2+5sF+vYN1PmvbffDBB3rooYeCKmxaLT09XXfcccdZa3LabDZ17NhRvXv31uDBgzVmzBitXbtWL7zwQq2vVf51d+GFFwbWUaup7t271/rajcGhQ4f0ox/9KDAlbRmHw6HOnTurT58+GjJkiC666CK98cYbev/996sdb9asWXrrrbcklXbMlRXo9u/fr3379kkq7Ro/88Mm5b8OUVFR1a6dWZnKuqPLnE8nOAAAANDcUKADAACNUvlpytLT04M+v/wUW+fqmDrTxRdfrIiICBUUFGjp0qV64IEHJH3XPRcaGqrJkycHNebnn38e6Bpr27atxo8ff85zCgsLA+vhffXVVzp+/Lg6d+4c1HUbSl5eXoX1xipTvrvlXFMjVqZ850V+fr58Pt853+z1eDzKy8sLbFfXoVfmzE6t66+/vsbdW2cqf73yORpS+eetpp0x5bvurOx4iY6ODnz/Z2dn16jYXj57Tb7ewcjMzNTq1asllRb/rr766hoVAZctW6bCwkLl5ubq008/DXraVCvNnTs3UJyLi4vT97//fV100UXq3bu3QkJCKhy7cuXK87pW+ddar169NGfOnPMarylxu9269957A8W5zp076/vf/75Gjx6tHj16nPWhhvIfQqnKsGHD1K1bNyUmJmrLli2BNfrKpmqWzp7eUqr4dTBNs0V9HQAAAICGRIEOAAA0St26dZNhGDJNU2lpacrNza1xoeDEiROBYohhGEF3VYSEhOjSSy/Vxx9/rCNHjmjfvn3q27evlixZIkmaOHGiIiMjgxrzvffeC9y+8cYb9dOf/vSc55imqSlTpigpKUmmaWrhwoX6+c9/HtR1G8qhQ4c0atSoao85cOBA4HZtCo0ul0sdOnRQSkqKPB6PDh48eM41qg4cOBDoBmnbtm2NOpdCQkLUtm3bQGHowIED53xsRUVFMgzjrPHLP87Dhw+f89pr1qzR4sWL1alTJ02YMEFDhgw55znnUr6bpaxr5lzKd0tZWRTu1q1b4Ouwd+9edejQodrjc3JylJKSIum7Dq+69NFHH8nj8UiSRo8erT/96U81Pres22nhwoVNpkC3bds2rV+/XlJpJ/KiRYuqfT2UL47WRvmxy69HV52srCzFxsZa2ulZF1asWKFDhw5Jktq1a6d33nmn2mmUy0+fW12n6axZszR//nyZpqmVK1fq5ptvDkyFHBsbq4kTJ551TocOHeRwOOT1epWfnx8o7FUnPz9fLpfrnGv9AQAAAPhOzefqAQAAaECRkZEVii8rVqyo8bnluzgGDBigiIiIoK9ffl2p5cuX68CBA4E3jGfOnBnUWBkZGfriiy8C21deeWWNzjMMQ7Nnzw5sv/fee3K73UFdu6GsWbOm2vu3bdsWKLQMHDjwnG/2VmXkyJGB22XdhdUpf8zw4cNrfJ3Ro0cHbtfktffnP/9ZQ4cO1bhx4/T8888H9g8bNiwwPeb27dvPucbW8uXL9d577+lvf/tbhYLm+RQfOnfuHHi+s7OzAwWX6ixdujRwe9iwYbW+9vk6n693//7963wqyfKF9quuuqrG511zzTWB29u3b9euXbvqNFd9+fbbbwO3x40bV21xzjRNbdy4MbBdfqrRMud6HZcvhG/evLlCEaoyaWlpmjBhgoYOHaoZM2ac8/jGrPxzPX369GqLc8XFxdq+fXtgu7Lnukz5Ls9Vq1YpJSUlsI7g9OnTKy2ohYWFaeDAgYHt5cuXnzP/Qw89pKFDh2rixIkV1lsFAAAAUDUKdAAAoNEqv87bM888c87ihiQVFBTo1VdfDWzXtBh2pvHjxwc69pYvXx4oWERGRlbacVCdDz74ILAW2ZAhQ6pdn+dMs2bNCry5mpmZWaMihRUWLlyojIyMKu//29/+Frg9Y8aMWl+nfMHyjTfeqDCV6ZmSk5P15ptvBrbLF13PZdasWYHbixYtUmJiYpXHJiYm6u2335YknTp1SoMGDQrcFxkZqUmTJkkqncLun//8Z5XjZGZmBro0nU6nLr744sB95dfAK78+VE2Vf96efvrpatfG++yzz7R161ZJpWtfXXbZZUFfr66Uf/1/+umn1Ra28vLyKqx/FszXuyZ27NgR6EB0uVxBPS+jR4+uUNxauHBhnWarL+U/EHCu7rg33nhDSUlJge3KXmPneh337Nkz0DXqdrv1zDPPVHvN+fPny+PxqKSkRBEREWrdunW1x5+Psul0a/P9VxPBPNd//etfK6zNWt33c4cOHXTBBRdIkjZs2HDO6S3LlP8Z+I9//KPa4uc333yjzz//XH6/XydPntTQoUOrzQ8AAACgFAU6AADQaN1yyy2Bzp+0tDRdf/312rlzZ5XHHzhwQP/zP/8TWMOnS5cuuuGGG2p1bZfLFVhnbv/+/Vq0aJEkacqUKWetu3Qu5btugi0YdurUKfDmqtR439jPzs7WnXfeqZMnT1bYX1JSol//+tdau3atpNKvyW233Vbr64wbNy7Q3ZaXl6fvf//7lU6Fd+DAAf3gBz9Qfn6+JOmCCy4IqqAyceLEQMddYWGhfvjDH1ZaHDp06JDuuuuuwJvrQ4YMOauAe9dddwXe3P/HP/6hf//732eNk52drfvvvz8wNeusWbPUtm3bwP3lp1Qte30H4/bbbw+sEbh9+3bde++9la5H99lnn+nhhx8ObN95551Br+FYl7p37x7oVPN4PLrzzju1efPms45LTU3VnDlzAgXbHj166Oabb67TLO+++27g9sSJE4Nam88wjAoFj08++STw2mzM+vXrF7i9efNmffbZZ2cd43a79fe///2s6T4rWyOtJq/j++67L1CU/e9//6s//elPZ3UOe71evfDCCxW+Jvfee28NHlHtlWXPzMxUYWFhnY9f/rleunRphY66MoWFhfr973+v119/vcL+c61HV/baK/taSaVT344YMaLKc6655hp16dJFUul/f3/4wx/q2LFjZx23devWwDqtknTZZZepd+/e1eYBAAAAUIo16AAAQKMVERGhv/3tb5ozZ47y8/OVmJioa6+9VgMHDtSQIUMUHx8vv9+vjIwMbd++vULxrnXr1nr++ecVHh5e6+vPmDEjsG5U2fSMwXblfPvtt4ECkt1ur1VXzzXXXKMNGzZIkjZt2qQDBw40ujdAnU6ndu7cqenTp+uyyy5Tt27dlJGRoc8++yxQNAkPD9cf/vCH85528Omnn9Z1112nkydPKjExUVdffbUmTJiggQMHyjAM7dy5U2vWrAl0lcTHx+svf/lLhe6dmnjmmWd03XXXKT09XcnJyfre976niy66SEOGDJFpmjpw4IBWr14d6KiJiYnRn//857PGGTJkiB588EH95S9/kd/v1+OPP66FCxdqwoQJiomJUVJSkpYtWxboEO3WrdtZaw126tQpcPvjjz9WVFSUEhIS1Lt3b1166aXnfCxxcXH6y1/+orvuuksej0erVq3S1KlTNXnyZHXt2lVFRUVav369tm3bFjhn7NixNVorsb7NmzdPe/bs0f79+3Xq1CndcsstGjt2rIYNGyan06mDBw9q1apVgY6iyMhIPfPMM+f1vX+mkpKSCp1HtenMnT17thYsWCDTNFVYWKgPP/xQt9xyS6XHvv3220EVAMvExcVVKASer4suuki9e/fWgQMHZJqmfvrTn2r8+PEaMGCAQkJClJycrNWrVwc6vpxOZ2CNvsoKwDV5HU+YMEF33XWXXnzxRUnSP//5Ty1evFiTJk1SQkKC0tLStGbNGh0/fjww1q233hp0Z3OwOnXqpJycHLndbs2ZM0eTJk2S1+vVT37ykzoZ/4orrtDf/vY3ZWRkqKSkRDfffLMuvfRS9erVS4Zh6NixY1q9erUKCgoknfu5Lu+yyy7T448/rqKiokBh+FxTtIaGhurZZ5/VrbfeqoKCAu3Zs0eXX365LrnkEvXr108lJSXatWuXvvrqq8A5HTt21Lx5887jWQAAAABaFgp0AACgURs2bJgWLlyoRx99VDt27JAk7dq1q9qp7i688EI98cQT6tix43ld+6KLLlJsbGzgzc9WrVpp3LhxQY1RvsPjwgsvVJs2bYLOUfbmatkbswsXLtSvf/3roMepT7/+9a/10ksvKTk5OVDULC8hIUEvvvhihXWNaishIUFvv/22HnjgAW3ZskVer1erV6/W6tWrzzp2/PjxeuqppxQXFxf0ddq3b6933nlHDzzwgLZu3Sq/36+1a9cGugHL69mzp+bPn69u3bpVOtaPfvQjhYeH66mnnlJxcbH2798fWAeqvGHDhunZZ59VTExMhf19+vTR8OHDtXXrVpmmGejCu/TSS2tUoJNKn4vXXntNc+fOVWpqqnJzcyv9WhmGoR/84Af62c9+Fuj8s1JERIT+85//6Be/+IVWrlwp0zS1bt06rVu37qxjBw4cqPnz5wc6f+rK8uXLlZubK0mKiooKTFsajI4dO2rMmDGBNQAXLlxYZYGurMspWP369avTAp3dbtdzzz2nH/7wh0pJSZGkKr8HRo0apQcffDDwmCr7GV3T1/EDDzyguLg4Pf300yoqKtKJEyf01ltvVZrvjjvu0IMPPlgnj7c6N9xwg/73f/9XkrRlyxZt2bJFUmmn95nfr7URFRWlBQsW6O6771Z2drZ8Pp8+++yzSrsWp06dqlmzZumee+6RVPlzXV5ERISmTp2qjz76KLCvJmsoDhgwQAsXLtQDDzygQ4cOyePxVJlp+PDhmj9/fr1OMwoAAAA0NxToAABAo9e7d2+98847WrdunT777DPt2LFDx44dCxSsIiIi1KVLFw0dOlSXX355tdN2BcPpdGrq1KmB9cWmTZsmh6Pmvz4VFxdr8eLFge3arocXFhamGTNm6J133pEkffjhh5o7d67CwsJqNV596Natmz766CO99tprWrp0qY4fPy6bzaY+ffpo+vTpuv766xUREVFn10tISNBbb72l1atXa/Hixdq6datOnTolr9erhIQEjRgxQldddZUmTJhwXtdp166dFi5cqNWrV2vJkiWB63g8HrVq1UoDBgzQZZddppkzZ8rlclU71i233KIpU6boP//5j9auXaukpCTl5+crJiZGgwcP1pVXXqkZM2ZUWhQzDEMvv/yy5s+fr1WrVik9Pb1CB01NjRo1SsuXL9d7772nVatWac+ePcrKypLD4VDnzp01duxYXX/99Y2uQzMqKkovvPCCNm3apA8++EDffPON0tPT5Xa7FRcXp6FDh2rGjBmaNm1avRQVy09TO23atHN+ratyzTXXBAp0+/fv1+bNmzVy5Mg6yVhfunfvrg8//FBvvvmmVq1apSNHjqioqEhhYWFq3769+vfvH+isMgxDPXr00OHDh3Xs2DFt2bKlws/jYF7Ht912m2bMmKFFixbpq6++UmJionJychQSEqLOnTtrzJgxuuGGG9SzZ88GeR5uuOEGOZ1Ovfnmmzpy5Ig8Ho/atGmj1NTUOinQSdKIESP08ccf64033tCXX36p48ePy+12KyIiQh06dNCgQYN09dVXa/To0SopKVF0dLRyc3P1zTffKCUlRR06dKhy7KuvvjpQoBs+fHiNi9h9+vTRxx9/rCVLlmj58uXauXOnMjIy5Pf71aZNGw0ePFgzZ87UlClTgu5SBgAAAFo6wzRN0+oQAAAAaHoeeeSRQAfWG2+8oTFjxlicKDjPPfecFixYIEn64x//qNmzZ1ucCADqx/vvv69HHnlEkvTb3/5WN954o8WJAAAAAPARNwAAALRIZWvUSap1RxQANAUffvihJCkkJKRWa6ECAAAAqHsU6AAAANAiZWVlBW5HRkZamAQA6s/hw4cDU6tedtllio6OtjgRAAAAAIkCHQAAAFogr9erLVu2BLY7depkYRoAqDsFBQUqW8niyJEjevDBBwPbt912m5XRAAAAAJTjsDoAAAAA0FB++9vfKi8vT/v379eBAwckSfHx8erRo4fFyQCgbrz33nv661//KpfLpezs7MD+adOmaciQIdYFAwAAAFABBToAAAC0CH6/Xx999JHy8/Mr7L///vtlGIZFqQCgbrVv316FhYUqLCwM7OvSpYvmzZtnYSoAAAAAZ6JABwAAgBYhPT1dCQkJ8nq9kqTevXvrBz/4ga644gqLkwFA3enTp4/69OmjxMRExcTEaNKkSbrvvvvUpk0bq6MBAAAAKMcwyyajt8CoUaPkdrvVtm1bqyIAAAAAAAAAAIBGIj09XS6XS5s2bbI6Sot16623KjU11eoY9a59+/Z68803Lbu+pR10JSUl8vl8VkYAAAAAAAAAAACNhNfrlYV9RZCUmpqqpKRkhThjrI5Sb0o8OVZHsLZAFx8fL0lauXKllTEAAAAAAAAAAEAjMHnyZKsjQFKIM0bDe/3U6hj1ZuvBBVZHkM3qAAAAAAAAAAAAAEBLQoEOAAAAAAAAAAAAaEAU6AAAAAAAAAAAAIAGRIEOAAAAAAAAAAAAaEAU6AAAAAAAAAAAAIAGRIEOAAAAAAAAAAAAaEAU6AAAAAAAAAAAAIAGFHSBLj8/X/PmzdP48eN1wQUXaO7cucrIyKiPbAAAAAAAAAAAAECzE3SB7v7779cXX3yhJ554Qv/+979VVFSk22+/XW63uz7yAQAAAAAAAAAAAM1KUAW6PXv2aO3atXr88cc1ceJE9e7dW0899ZTS0tL06aef1ldGAAAAAAAAAAAAoNkIqkCXmJgoSRo1alRgX0REhLp27aqNGzfWaTAAAAAAAAAAAACgOQqqQBcfHy9JSk1NDezz+Xw6ceKEMjMz6zYZAAAAAAAAAAAA0AwFVaAbPHiwevTooXnz5unkyZMqLi7W008/raysLHk8nvrKCAAAAAAAAAAAADQbQRXoXC6XFixYoKKiIl188cUaNWqUsrKyNGnSJEVGRtZXRgAAAAAAAAAAAKDZcAR7Qs+ePfXuu+8qOztbDodDkZGR+t73vqexY8fWRz4AAAAAAAAAAACgWQmqgy4/P1+33nqr9u7dq9jYWEVGRiopKUm7d+/WuHHj6isjAAAAAAAAAAAA0GwEVaCLjIyUaZp64okndODAAe3YsUN33323xo4dqwsvvLC+MgIAAAAAAAAAAADNRlAFOkn661//qpiYGN1000368Y9/rJEjR+q5556rj2wAAAAAAAAAAABAsxP0GnQJCQlasGBBfWQBAAAAAAAAAAAAmr2gO+gAAAAAAAAAAAAA1B4FOgAAAAAAAAAAAKABUaADAAAAAAAAAAAAGhAFOgAAAAAAAAAAAKABUaADAAAAAAAAAAAAGpDD6gAAAAAArLU5/Yi+PXVUbUIjdVmXoQq1O62OBAAAAABAs0aBDgAAAGjBdmQc18JD60o3cqSUwmzdPXCKtaEAAAAAAGjmmOISAAAAaME2ph2qsH0kL82iJAAAAAAAtBwU6AAAAIAWLNzpsjoCAAAAAAAtDgU6AAAAoAWb1nGwHMZ3fxZcEN/TwjQAAAAAALQMrEEHAAAAtGBxYVH6+dCZ2p2VrGhXmAa37mx1JAAAAAAAmj066AAAAIAWrnVopMa16yO336sPEzdrR+ZxqyMBAAAAANCs0UEHAAAANGNun1enivPUOiRSoQ5nlcd9kbpHnx77VjYZ+urkft3Y80KNbNu9AZMCAAAAANByUKADAAAAmqn0oly9sHuF8j3FCrU7dWf/S9U5Mq7SY8u65vwyJUm7s5Io0AEAAAAAUE+Y4hIAAABoplan7FaBp0SSVOLzaOnxbVUeGx8WI0OGJMmQ1DYsOnCfaZpKzEvXrswklfg8VY7h9fv030Pr9bvN7+ufez9Xgae4bh4IAAAAAADNDB10AAAAQDPlM/1nbJtVHntl1xEq9rp1LD9DfWLbaXLHgYH7lh7fplUpuyVJcSGRun/wdIU5XGeNsTpltzalH5YpKT+7WB8kbtYtvcfVzYMBmiCv3ye7YZNhGFZHAQAAANDIUKADAAAAmqmJ7ftrV1aySnwe2Q2bpnYcVOWx4Q6X/qfvxWft9/n9Wn26OCdJGSX52pF5XBfE9zzr2PTivMBtv0ydLMo5z0cANE0+v19vHfxa2zKPKcIRov/pM0Hdo+OtjgUAAACgEaFABwAAADRTHSJa6dFhVyqlMFvxYdGKcYUHPYZhSA6bXR6/L7DPZav8z4hBrTpp66lE2WTIL1NDWnepdXagKdt06rC2ZR6TJBV6S/TWwXX65YirLU4FAAAAoDGhQAcAAAA0YxHOUPWOaVfr822GTd/rcYEWHVovv2lqQGxHDW7dudJjh8R10Q9sF+tAzkl1CI/VqLY9an1doCkr8JTIkGSe/lfgLbE4EQAAAIDGhgIdAAAA0EJ4/F4dzctQlCtUCWExNT5vRJvuGhDbSSV+j6KdYdWupzWgVScNaNWpLuICTdbQuK5albJbJT6PJGlcuz4WJwIAAADQ2FCgAwAAAFqAIq9bz+1cFlgn7qquIzShfb8anx/qcCpUzvqKBzQrcaGRemjI5dqbnaJYV7j6xXawOhIAAACARoYCHQAAANACbD11NFCck6TFx7dpfLu+1XbDNRSP36c1qXuVVVKgYW26qmd0gtWRgPPWKiRCFyb0tjoGAAAAgEaKAh0AAADQAtjPKMTZZH1hrsyig+u0PfOYDBnakHZQPx04TV2i2lgdCwAAAACAemOzOgAAAACA+je8TTd1iYyTJBmSZncf1Si65yRpT3ayTEl+mZIM7ctJtToSAAAAAAD1ig46AAAAoAVw2R26Z+BUpRXlKsIRoihXmNWRAtqGxSilIEvm6f8lhMVYHQlNlN9vymZrHIVnAAAAAKgOBToAAACghbAZNrULj7U6xllu7z1e7xzeqMySfI2O76nBrTtbHQlNjNfj09+f+Uqb1h1TXNtw3ffIJerao7XVsYJimj7JXyDZImQYdqvjAAAAAKhnFOgAAAAAWKp1aKTuHHCp1THQhK1edkDffH1UkpRxqlAvP/uVfv/slRanqjnTlyvlLpPMIskIkxk9TYadTlIAAACgOWMNOgAAAABAk5aTXRSY2tL0m8rOKrI4UZAKv5XM4tLbZnHpNgAAAIBmjQIdAAAAAKBJGzO+m+x2m3R6+blLp/exNlDQfJLM07dNSV4LswAAAABoCExxCQAAAABo0jp3a6Xfzb9C2zYnKz4hSsMv6HTOcwryS/SP+V/p4L5T6jcoQXfcd5HCwpx1msvr9+uDHclKyirUxb3iNaJTq8oPDB0geZIl+SXZpNBBdZoDAAAAQONDgQ4AAAAA0OS17xij9h1rvm7bote3aPuWFPn9pjZvOK64t7bp5h+OqtNMz36xX29/myS7YWjR1uN6/rqRlRbpDGeCzJhZki9LsreSYY+s0xwAAAAAGh8KdAAAAACCku8p1rLj21XgLdGY+J7qG9vB6khA0E6k5MrvL51W0vSbSkvNq/NrrNyfJknymabshqE1h9Kr7KIz7JEShTkAAACgxWANOgAAAABBeXXv59qQdkg7Mo/r1b2fK7kgy+pIQNDGjO8mSbLZSheuG31R1zq/RtdW4bIZpeP7TFNdWoXX+TUAAAAANLz8/HzNmzdP48eP1wUXXKC5c+cqIyMjqDHooAMAAABQY16/T0kFmYFtU1JiXro6RlSxthbQSE2e0VfRMaE6vP+U+gyI1/ALOtf5NeZNH6THl+3S0awCTe2ToKsGdazzawAAAABoePfff78OHTqkJ554Qh06dND8+fN1++236/3335fL5arRGBToAAAAANSYw2ZXQli00oryZKp0esDOEa0tTgXUzuiLutZL51yZdtGheuG6kfU2PgAAAICGt2fPHq1du1Yvv/yyLr74YknSU089pUsuuUSffvqpZs+eXaNxmOISAAAAQFDm9Jukwa07q0dUvG7tPU5dotpYHQkAAAAAgAaRmJgoSRo1alRgX0REhLp27aqNGzfWeBw66AAAAAAEpVVIhG7rM97qGAAAAAAA1FpqaqomT55c5f0rV66sdH98fHzg/J49e0qSfD6fTpw4obi4uBpfnw46AAAAAACqsGfHCa1cvE8pSTlWRwEAAADQCAwePFg9evTQvHnzdPLkSRUXF+vpp59WVlaWPB5Pjcehgw4AAAAAgEp89ulevfnyN5Ikh8Omx568TD16M6UrAAAA0By0b9++yi656rhcLi1YsEAPP/ywLr74YjmdTl155ZWaNGmSbLaa98VRoAMAAAAAoBIrPt0XuO33m1q76lCFAp3X45PdYZNhGFbEAwAAAGCRnj176t1331V2drYcDociIyP1ve99T2PHjq3xGExxCQAAAABo0TJPFehfL6zXi0+v0cF96YH90bGhstlKi2+mKUXFhEqSvF6/XvjLl5pz3X907/ff1v49aZbkBgAAANDw8vPzdeutt2rv3r2KjY1VZGSkkpKStHv3bo0bN67G41CgAwAAANDkrD2xT/M2vasntnygfdkpVsdBE+b3+fXkr5bryxUHteGro/rjr5Yr/WS+JOn7d49R6zbhkqT+gxM0/eoBkqS1qw9pw9qjkqT83BK99Mxaa8IDAAAAaHCRkZEyTVNPPPGEDhw4oB07dujuu+/W2LFjdeGFF9Z4HKa4BAAAANCkJBdk6sPEzZKkQkmv71+j34y8Vi47f94geNlZRUo7kR/Y9vhNHT5wSm0TItWxc6z+8tJs+bx+OZz2wDF5OcUyDEOmaco0pbzcEiuiAwAAALDIX//6V/3ud7/TTTfdJJfLpWnTpunnP/95UGPwFywAAACAJiWrpKDCtsfvU6G3hAIdaiU6NkwxrUKVl1Miv9+UzWaoc7dWgfsNw6hQnJOkMeO76dN3d6moyCNJmnJF3wbNDAAAAMBaCQkJWrBgwXmNwV+wAAAAAJqU7lHxinSEqMDrlmSqS2QbxbjCrY6FJsrhsOnh307Votc3q7jIqytmD1SHTjHVnhPfLkpP/O1KfbspSXFtIzR0ZMcGSgsAAACguaBABwAAALQwbp9XCw+t077sVHUIj9WtfcY3qQJXhDNE9w+eoU3ph+WyOzQmvqcMw7A6FpqwTl1i9dCvJwd1TlzbCE2eQeccAAAAgNqxWR0AAAAAQMNanbJbOzOPy+336lh+hj44ssnqSEGLDQnXlE6DdHH7fgqxO62OAwAAAABAUCjQAQAAAC1M6RpupR1nfpnKKMm3NhAAAAAAAC0MBToAAACghRkW11WmTBmni3Sj2vao8li/aWpbxjF9dWK/ctyFDRURAAAAAIBmjTXoAAAAgBamX6sOunvAFB3MOaH2Ea00qFWnKo9978g32pB2UJK0PGm7fjbk8ia1Xh2aD7fbp2Uf7VbmqUKNndBNfQcmWB0JAAAAAGqNAh0AAADQAvWIjleP6Phqj/GZfm08XZyTpEKvWzszkzSuXZ/6jgcEmKap7ZtT9M6/t+rYkSzZbIY+X35Av/7TdPXo3cbqeAAAAABQKxToAAAAAAScKMzW9oxjigkJ18g23RXmCFGhtyRwf5QztNZjH807pc9T9shhs2lqp8GKD4uui8ho5j56e4fe+8+2wLbfb8qwGdqxNYUCHQAAAIAmiwIdAAAAAEnSyaIcPbtjqXymKVOmEvPSdVvvcfq/A1+pyFuiC+J7aVDrzrUaO8ddqJf2rJTX75Nk6GDuSf1y+FVy2viTBNVb8em+s/aZflMdO8c2fBgAAAAAqCP8NQwAAABAkrQ7M1k+0y/z9PbWU0d1Q88L9ZuR18gvU3bDVuuxUwuz5fH7Tm+ZyvcUK7OkQAlhMeedG81bTGyo8nJLZJqlr8zIKJemXzVAI8fWrlgMAAAAAI1B7f/CBgAAANCstAoJDxTnDBmKdYWX3jaM8yrOSVK7sFg5DJuM02NHOELUyhVxfoHRIvzo/nFqFRcmSRoxprPm//N7uvK6wTIM46xjc3OKtfGrozq0/1RDxwQAAACAoNBBBwAAAECSNCSuq47lZ2hj+mHFOMN0c+9xdTZ2bEi4ftT/Uq1O2S2HYdNlnYfIZefPEZxb1x6t9cwr18rn88tur7pQnJFeoP/92afKzytdM/GmH47U9KsGNFRMAAAAAAgKfxEDAAAAkCTZDENXdRupq7qNrJfxe0THq0d0fL2MjeavuuKcJK1ddUiFBe7A9sdv76RABwAAAKDRYopLAAAAAECTFxrmDKxTZxhSaBifRwUAAADQeFGgAwAAAAA0eZdM66Xe/Us7NF0hDv3wngsD95mmKdN9VGbRDpneLKsiAgAAAEAAHykEAAAAADRJmacKtHrZAdnshibP6KtfPjFNOdnFCo9wyeWyf3dg0TapeHvgthk9XYajjTWhAQAAAEAU6AAAAAAATVBRoVu//fkS5eYUy5S0/stEPfHsTMW2Cjv74JID5TZMyZ2o40l2fftNkuLbR+mCcV1lGEZDRQcAAAAACnQAAAAAgKbnyMEMZWcVBbZPpOQqJTlXXbq1OvtgW7jkK5ZkSjKVlSXNm7tYfp9fpikdPZKp628b0WDZAQAAAIA16AAAAAAATU7bhEgFmt4MyeG0qXXr8MoPjhwn2aIl2SRnN61cLZl+U6ZZeveXnx1siMgAAAAAEEAHHQAAAACgyWmbEKUfPzhe77y5VXa7TbfMGa3I6JBKjzXssVLs1YHt1q33ye8vrc7ZbIZat4loiMgAAAAAEECBDgAAAADQJF14cXddeHH3oM+bOK23Du0/pY1fJapNQqR+/OC4ekgHAAAAAFWjQAcAAAAAaFEcDpvufGCc7nxgnDLSC3TsSKZCQ52Ka0snHQAAAICGQYEOAAAAANAi7d+Tpqf+9zN5PH45nDb9/DdT1G9ggtWxAAAAALQANqsDAAAAAABghSXv75bX65ck+bx+LX5vl8WJAAAAALQUFOgAAAAAAC2S02WTYRiSJMMw5HTZLU4EAAAAoKWgQAcAAAAAaJGuuWmYomJCJEmR0SG69pZh1gYCAAAA0GKwBh0AAAAAoEVq1zFaT//jGmWkF6h1mwg5nTbl55UoPMIlm82wOh4AAACAZowCHQAAAACgxXI67WrXIVrZWUX687wVSjqWrbi2EXr4N1PUrmO01fEAAAAANFNMcQkAAAAAjZTb55VpmlbHaBE++u92pSTlSJKyMgr11mubLU4EAAAAoDmjgw4AAAAAGplCb4le2fO5jhdkqFVIhH7Ub5LahtHNVZ8K8t0qK4X6/aYK8koszQMAAACgeaODDgAAAAAamZXJu5RUkClJyi4p1AeJmyxO1PxdOr2PbEbpunOGIV12VX+LEwEAAABozuigAwAAAIBGpsDzXfeWKVP5Hrq56lvfgQn6w9+u1IG96erSvZW69mhtdSQAAAAAzRgFOgAAAKAW/KZfB3PT5Df96h3dTnYbk1Og7oxJ6KVvM47Kd3r9uQnt+1qcqGVo1zFa7ToylSgAAACA+keBDgAAAAiSaZp6Y/8a7cpKliT1jE7Qj/pPkt2gSIe60T2qrR4cMkNHctPVPjxWXaPaWB0JAAAAAFCHKNABAAAAQUoryg0U5yTpUO5JHc/PULeothamQnOTEBajhLAYq2MAAAAAAOoBBToAAAAgSE6b/ax9LlvVv1q7fV6tObFPBZ5ijWzbQx0jWtVnPABNRHZmoVKTc9W5aytFRodYHQcAAABAA6JABwAAAASpdWikpnUarOVJOyRJE9r1Vfvw2CqP/9e+L3Qo96QMGVp38oAeGnqF2oRGNVBaAI3R3p0n9ZffrpDH41d4hFO/fOIyde5G8R4AAABoKSjQAQAAALUwtdNgXZTQR6ZMRTpDqzzO4/fqYO5JSZIpU37T1IGcExTogBbu/YXb5PX6JUnFRV4t+XC37rx/3FnHFXndWnfygEp8Xl0Q31NxoZENHRUAAABAPaBABwAAANRShPPcU9I5DLtinGHK9RTLlClJahsaXd/RADRydrtRcdtmnHWM3zT1jz2rlFyQGejAfXjYzGo/FAAAAACgabBZHQAAAABozgzD0A/7XaJOEa3UyhWhq7qOUK+YBKtjAbDYtbcMV0ho6WdmI6NCdMW1g846Js9TpKSCTJmS/DJV5HPrcG5aAycFAAAAUB/ooAMAAADqWYeIVrpv8HSrYwBoRHr2aaNnXrlW6Sfz1a5DlEJCnWcdE+4IUYjNIbffe7r/VopjelwAAACgWaCDDgAAAGggaUU52pZxVJnF+VZHAdAIhEe41LVH60qLc5LktNn1g34T1TY0WjGucF3TfbQ6RrRq4JQtk+nLl+nNkGn6rY4CAACAZooOOgAAAKAB7M5K0mv71siUKYdh090DpqhLVBurYwFo5HpGJ+jnw2ZaHaNFMYv3SYUbSjfsrWVGXybDqLyICgAAANQWHXQAAABAA1idslvm6UnqfKaptSf3W5wIAHAm0zSlwk3f7fBlSiWJluUBAABA80WBDgAAAGgAITanDBmSJENSiI3JLADgTKYv5/TUkua5D24wjSkLAAAAmgsKdAAAAEADmNl1uCKdIZKkViERmtJpkMWJAKBxMQu3SDkfSrmfSvkrLVn/zTAMKXzkdzvsraSQ7g2eAwAAAM0fH9sFAAAAGkC78Fg9NnyW8r3FinKGymbwWTkAKGP6i6Xind/t8KRI3hOSs0ODZzFC+8l0dpTMYsneWoZhb/AMAAAAaP4o0AEAAAANxG6zKcYVbnUMAGga8r+SaY+WIi6UYY9u0Esb9ihJUQ16TQAAALQsfGwXAAAAAABYyrCFSqFnTP1rFkneNCn/c0syAQAAAPWJDjoAAAAAAGohq9Ctl74+pFMFJZo5sIMu6RVvdaQmzQgfITOkp1S8TyrZe3qvKflyLM0FAAAA1AcKdAAAAAAA1MLDH23TrhM5Mk1p7eFT+scNozSkQ6zVsZo0wx5TWqQr2Xd6jyk5O1maCQAAoCXyhNq1b2J7q2PUG0+S9esMM8UlAAAAAABBMk1TO1Nz5DclU5IhaUcKnV51wXDESVGXSSF9pLDhUuSEermOaZoy3UdlFu+W6cutl2sAAAAAVaGDDgAAAADQ7Pl8ftntdfcZVcMw1D8hWnvTcgNFuoHtY+ps/JbOcMZLznqeMrRoi1S86/TGVpkxV8iwx9bvNQEAAIDTKNABAAAAAJqtk6l5eub3q5SanKu+A+N1/6OTFBHpqpOx/3z1UD2/5qDSC0p01aAOGtYxtk7GbapM05RK9kglRyR7tBQ+WoYt1OpYVSvZX27DL5UkSuHDLAoDAACAloYCHQAAANBMZJcUamtGosLsLo1q210Om/Vz6rckpumXsg9Jfo/Uqo8MG39uNQb/fuUbnUzNkyTt35OuT97ZoRu+P7JOxo6LCNH/Th9YJ2M1C+5EqXBT6W1fpmSWSFFTLI1ULSNMMj2nN0zJFm5pHAAAALQs/MUIAAAANAP5nmI9s2OJirwlMiXtykrSJR3668PEzfL6/ZrWabCGtelqdcxmzdzzbyltc+lGVFdp+L0U6YL0zddHdfhAhvoNTNDQUR3rZMyszEL5/aak0nXisrOL62RcVMKXqdJn2Sz9582wONA5RE6Q8j+X/IWSq5sU0svqRAAAAGhB+GsRAAAAaAb2Zaeq0FsS2N6bnaJDuSfl9ftkSvrPwa/UMaKV2oZFWxeyGTOLs74rzklS3lEp+6DUup91oZqYlYv36Y1/bJTNZmjx+7t014PjdeHE7uc97pTL++qfz68PbF88ued5j4kqONpJ2vXdtrO9ZVFqwnDESbHXyjRNGYZhdRwAAAC0MBToAAAAgGYgNqTi1GxOwy6P3xfYNiVlFOdToKsvNufZ++x1s85ZS7F+zRFJCnS7bfz6aJ0U6CZO7a2E9tE6lpipfgMT1KV76/MeE5UzXB1lRk6U3EclW5QUNtjqSDVCcQ4AAABWsFkdAAAAAMD56xmdoKmdBstlcyjaGabb+4xX29AoGTJkk6Fwh0udI+OsjtlsGa5IGT2v/m5H+7FS9PkXl1qShA7RstlKCyWGzVB8QmSdjd1vUIKmzexPca4BGK6uMiIvlhE+XIZh7WeC/aeS5D+5R2bhNpnFe2SavnOfBAAAADQQOugAAACAZmJap8Ga1um7jpVOkXFak7pXXtOvCxN6K8IZYmG65s/oPElqd4Hk98kIoVMxWDf+z0jlZBXp0P5T6j+4nWbdNNTqSGjC3J/+Q77tyxTyPzNkFjlLu+Q8yVLUFKujAQAAAJIo0AEAAADNVqQzVDO6DLM6RotiOCOsjtBkRUaH6KH/nWx1DDQD/qyT8n39gewDu8sILTfVrCdFpumWYTD9LAAAAKzHFJcAAABAM+Pz+5VckKkcd6HVUQCg4Zml6xiaOQUVdxku8TllAAAANBb8ZgoAAAA0I8U+j17ctUIphVkyJF3XY6xGx/ewOhYANBhb63ayX3CFfBs/lWfNdjnGDJQRGiNFjJNh8DllAAAANA4U6AAAAIB6UOgt0fH8TLUJjVJcaGSDXXdLeqJSCrMkSaakD49upkAHoMVxXvUTOcZcLvm8MuJ7yrBRmAMAAEDjQoEOAAAAqGOnivO0YOdyFXhLZMjQrb3HaUhclwa5timz4rZpVnEk0HglHcvW8o/3yGa36YrZA9U2oeGK3GgeDMOQ0a77OY8zTY9UvFvyF0quHjKcCQ2QDgAAAKBABwAAANS5dScPqMjrllRaMFt2fHuDFehGtOmmr0/uV1pRriRpZtfhDXJdoK7k5RbriUeXqrjIK0n69pvjeurF2XK57BYnQ3PwXUGuSArpKRXtkDxJkgyp5KDM6MtlOOKsjgkAAIAWgAIdAAAAUMfshi3Qx2ZIsjfg1GphDpceGDxDSQWZinKGqk1oVINdG6gLRw9nqrDAE9jOyihSWmquOnVtZWEqNBt5X0jeFJUW5A6Uu+P0T21PqkSBDgAAAA2ASdgBAACAOja+XV+1DomQJDlsdl3VdWSNz3X7vNqQdlDrTx5Usddz7hMq4bTZ1T2qbaMvzrl9Xh3OTVNGcb7VUdCItO8YI7vDJsOQDEMKDXMorm1Ejc/3enzy+5naFWczTf/p4pxUWpAzJSNUpR+lOM0e2/DBAAAA0CLRQQcAAADUsWhXmOYOvUIZxfmKdoUpzOGq0Xk+068Xd69QUkGmJGntiX16YPB0OWy1n9ovx12otan75JepcQl91Dq0cazlVeAp1t92LldmSb4MSdf1GKvR8T2sjoVGIK5thB58bJI+WLhddruh6/9nhMLCz/095Pebeu3F9fris4MKC3fq7ocmaOjIjg2QGE2FYdhk2qIkf74CHXPhw6WSI5K/QArpI8PVydKMAAAAaDko0AEAAAD1wGGzKyE8JqhzThbmBIpzknSyKEfH8zPUPTq+Vhk8fp+e3/mZst2FMiRtOZWoXwy9UqEOZ63Gq0sb0w8rq6S0c86U9OmxrRToEDB4eAcNHt4hqHO2bjyuLz47KEkqKvLoxafX6IU3b5DNZpzjTLQoUZdKBeslf6EU2k9GSC8ppJfVqQAAANACUaADAAAAauBUcZ6WHtumYr9HE9v3V++YdnV+jQhniAwF+jokSZHO0FqPl1aUoyx3gXR6zHxPsZILM9UzOuG8ctYFmyoWTQyDIgrOT15uyXcbplRU6JHf55ftPDpQ0fwY9hgp+jKrYwAAAACsQQcAAACci8/v1993r9T2zOPan52qV/au1qnivDq/TowrXNf2uEBOm10Ow6aru45U27DoWo8X64qQw/juV36bYSgupHFMcXlBfE/Fh5V2GNpk6Oog1ukDKjP8gk6Kjv2uoD1xai85nBTnAAAAADROdNABAAAA55DnKVaOuzCwbZqmkgsy1SY0qs6vNSa+ly5o21PS+XeVRThD9IO+E/XJ0a3yya8ZnYcpNiSiLmKetzCHSw8OnqETRdmKcoYp2hVmdSQ0cTGxYfr9/JnasuG4omJCNeKCzlZHAgAAAIAqUaADAAAAziHKFapYV7hy3EWSTNkMmzpGtK6369XldI99YtvrZ7Ht62y8umS31e/ziMZr3RdHtG7NEbWNj9Q1Nw9TRKSrTsaNiQ3TpMv61MlYqFter1+JBzMUHuFSh87Brc8JAAAANEcU6AAAAIBzsBs23TVgipYlbVeJz6MJ7frVS/cc0BLs2Jqivz+zVpJksxlKT8vXz351qcWpUJ/cbp/+9OvlOrjvlCRp9k1DNeuGIRanAgAAAKxFgQ4AAACogbjQSN3c6yKrY6AZKyxw6+N3diors1DjLumhwcM7WB2pXuzfnSabzZDfb8rvN7Vv10mrIzU4n88vu73lLAm/bVNSoDgnSR8s3KYZV/dXSKjTwlQAAACAtSjQAQAAAEAj8Pyfv9Tu7SdkmtL6L4/o13+arp592lodq8717NtGfr8pqbSDrle/5vcYq1JS7NFzf/pSO7amqG18pB741SR16hJrdax6d/a0vYZUh1P5AgAAAE1Ry/nIHgAAAAA0Yru3n5Dfb8o0S4tXe3emWZyofgwb1Ulzfnqh+g9upwmTe+ruBydYHanBLP1oj3Z+myJJyjhVoNdeWG9xooYxbFRH9R+cENi+/vbhCgnh88IAAABo2fiNGAAAAAAagS7dW+nYkazTRTqpa49WVkeqNxdP6aWLp/SyOkaDy80ulmEYMs3S6T2zs4qsjtQgHE67Hv7tVCUdy1Z4uFNt4iOtjgQAAABYjg46AAAAAGgE7nvkEg0f3Unde8bp+3eP0aBhzXMNupZs/KU9ZbN9N7XjlCv6WpimYdlshrp0a0VxDgAAADiNDjoAAAAAOA/7s1P11qF1Kva6NaF9P83oPLSSNbfOLa5thO579JK6D4hGo3uvOP3umZnatS1VHTrHaODQ9lZHahZMf7FkOGQYvMUBAACApoPfXgEAAACglnymX28cWKsSn0eStDplt3pFJ6hPLIUXVK5D5xh16BxjdYxmwTT9UsFayZ0oySYzYpyMkO5WxwIAAABqhCkuAQAAAKCWvH5foDhXJsfdMtYVAyznSTpdnJMkv1TwdWnRDgAAAGgCKNABAAAAQC2F2J0a3LqzJMmQFO4IUT+654CGYXrO2OGTZFqRBAAAAAgaU1wCAAAADSTXXaRj+RlKCItW27Boq+OgjtzSa5y2ZiSq0OvW0LguinKFWR0JaBmcnSRbpOTPL90O6SfDsFubCQAAAKihoAt0Xq9Xzz//vD744ANlZ2drwIAB+vnPf65hw4bVQzwAAACgeUgpyNLzuz6T2++VIUO395mgQa07WR0LdcBus2lU2x5WxwBaHMMWIjN6puRJkWwhkqOd1ZEAAACAGgt6issXX3xRb7/9tn73u9/pgw8+UPfu3XXHHXcoLS2tPvIBAAAAzcJXJ/fL4/dJkkyZWpm80+JEQNORmVGoBU99od/9Yom+XHHQ6jhoRAybS0ZINxnO9jIMw+o4AAAAQI0F3UG3YsUKzZw5U+PHj5ckPfLII3r77bf17bffatq0aXUeEAAAAGgOnDa7DJWujmSc3m6MTNPU5lNHlFyQpd4x7TSgVcdqj9+fc0LLjm+TTTZd3nWYuke1baCkaEn+9uTnOno4U36/qYP7TimubYQGDm2aa/3t3XlS+3adVPfecRoyovrvLwAAAADNV9AddHFxcVq9erWSkpLk8/m0aNEiuVwu9evXrz7yAQAAAM3CpA4D1CokQpIUanfpyq4jLE5UuVUpu7Xo0Hp9fWK//rXvC23POFblsTnuQv1r7+c6lp+ho/npemXPahV63Q2YFi1FWXFOkgxDSjyUYXGi2tm0/pie/NVyvb9ou55+fJU+/+yA1ZEAAAAAWCToDrrHHntM999/vyZPniy73S6bzabnnntOXbp0qY98AAAAQLMQ4wrXz4fNVE5JoaJcoXLagv5VvEFszzgqSfLLlCFpZ1aShsRV/rv+qaI8eU2/pNLOQLffq6ySfIU7WjdQWrQU/QYlaO/OkzLN0iJd34EJFieqnXWfH5FhSObpYuPalYd0ydTeFqcCAAAAYIWgO+gOHjyoqKgoPf/881q0aJGuueYazZ07V3v27KmPfAAAAECzYTdsah0a2WiLc5IUHxYjm75bx6ltaFSVx7aPaKUwu0s2GbLJUJQzVG1DoxsiJlqYnz48UaNn9JZjfEcN+J8h6tijaRaBW7cND6yTZrMZapMQaXEiAAAAAFYJ6p2B1NRUPfTQQ3rttdc0atQoSdLgwYN18OBBPffcc3rhhRfqJSQAAACAhjGr20iV+DxKKshU39j2uqTDgCqPDXe49NNBU/Vl6l4ZMnRJhwFy2Rtv8RFNV6FMvecuUqHdr11H0pX4wbd6/nsjAsWupmL2jUOVkpRbugZdrzjd+P2RVkeqwPSkSyW7JTmksCEy7FUX6AEAAACcn6D+et62bZs8Ho8GDx5cYf/QoUP15Zdf1mkwAAAAAA0vwhmqH/a7pMbHx4fF6Hs9xtRfIEDSpmOZynd7A9tbkrKUV+JVdKjTwlTBC49w6efzJlsdo1KmL1/KWy6pdNpaeU/IjJktwwh64h0AAAAANRDUb9rt2rWTJO3bt6/C/v3796tbt251FgoAAAAAgDIdY8MCtw1JUSEOhbvs1gVqjnyZknwqXVHSlPwFpf8AAAAA1IugCnRDhgzRyJEj9Ytf/ELr169XYmKi5s+fr3Xr1unOO++sr4wAAAAAgBZsSIdY3T+xt1qFu9S5Vbj+fPUwOWx0dtUpeyspsP6kIRmhki3cykQAAABAsxbUFJc2m00vvvii5s+fr0cffVQ5OTnq06ePXnvtNQ0dOrS+MgIAAAAA6ojXn6Ei7waZKpbL1ksh9sFNYi23m0Z01U0julodo9ky7FEyoyZLRTslwymFD5dh0KUIAAAA1JegV3CPiYnRvHnzNG/evPrIAwAAAACoJ6Zpqsj7lUwVS5Lc/r2y2+LkNDpanAyNgeHsIDk7WB0DAAAAaBGYEwQAAAAAWgwzUJwr4zdZZwwAAAAAGhoFOgAAAABoIQzDJofRpWxLkl1OGx1TAAAAANDQgp7iEgAAAEDdKvZ6dDjvpKJd4eoU0drqOGjmwhwXyONvK1PFcti6yGZEWh0JzYDpKZFv82cy3UVyDJ0kI6aN1ZEAAACARo0CHQAAAGChfE+xnt2xVNnuQknSFV2G6ZIOAyxOhebMMGxy2XtaHQPNiGmacr/xG/kPb5MMQ9617yv0/hdlRMRYHQ0AAABotJjiEgAAAJCUVpSjpPxM+U1/g15366lE5ZwuzknSZ0k7G/T6AHDeCrJLi3OSZJpSQbZ8ZdsAAAAAKkUHHQAAAFq8Jce2aVXKLklS7+h2mtPvEtltDfNZNofNLvOMbQBoUkIiJGeI5HFLp3+iGTFtrc0EAAAANHJ00AEAAKBFK/CUBIpzknQg94QO5JxosOuPattd3aNK38i2GzZ9r8cFDXZtAKgLhtMl182PSVGtJFeYHNO+L3uX/lbHAgAAAOqN1+vVs88+q0mTJmn48OG65ZZb9O233wY1Bh10AAAAgIWcNofuHjBF2e5ChdldCnU4rY4EAEGz9xmlsEfetDoGAAAA0CBefPFFvf322/rjH/+ozp076+WXX9Ydd9yhxYsXKz4+vkZj0EEHAACAFi3CGaIpHQcFtvvEtFPv2HYNmsEwDLUKiaA4BwAAAABAE7BixQrNnDlT48ePV9euXfXII48oLy8vqC46OugAAADQ4l3WeYhGtOkmt9+n9uGxshmG1ZEAAAAAAEAjFRcXp9WrV+vWW29V+/bttWjRIrlcLvXr16/GY1CgAwAAACS1DYu2OgIAAAAAAGggqampmjx5cpX3r1y5ssr7HnvsMd1///2aPHmy7Ha7bDabnnvuOXXp0qXG12eKSwAAAAAAAAAAAKCGDh48qKioKD3//PNatGiRrrnmGs2dO1d79uyp8Rh00AEAAAAAAAAAAKBFad++fbVdclVJTU3VQw89pNdee02jRo2SJA0ePFgHDx7Uc889pxdeeKFG49BBBwAAAABNjM/Mldt3VD4z1+ooAAAAANCibNu2TR6PR4MHD66wf+jQoTp69GiNx6FABwAAAABNiNefqgLPMhX7NqjAs0xe/0mrIwEAAABAi9GuXTtJ0r59+yrs379/v7p161bjcSjQAQAAAEATUuLbL8k8vWXK7TtgZRwgaKZpnvsgAAAAoJEaMmSIRo4cqV/84hdav369EhMTNX/+fK1bt0533nlnjcdhDToAAAAAaEIMuSQZKi3SGTIMl8WJgJoxfblS3irJnyvT2UGKnCjDcFodCwAAAAiKzWbTiy++qPnz5+vRRx9VTk6O+vTpo9dee01Dhw6t8TgU6AAAAACgCQl1DFaBJ0OmCmUoQiH2gVZHAmqmYJ3kzyu97UmRindLYTV/AwMAAABoLGJiYjRv3jzNmzev1mNQoAMAAACqUeLz6P0jm5SYl66eMQma1W2knDZ+jYZ1bEakIp2Xy5RbhkJkGIbVkYCa8Rfpu+lZjdPbAAAAQMvEOwsAAABANZYc26YtpxJlylRmWr4iHSGa0WWY1bHQwhmGTYZCrY4BBCe0r1T4zXfbrh7WZQEAAAAsRoEOAAAAqEZqYbbM0x0fpqTUwhxrAwFAE2WE9pdpj5F82ZKjvQxHK6sjAQAAAJaxWR0AAAAAaMz6t+ooSbLJOL3dwco4ANCkGc4OMkIHUJwDAABAi0cHHQAAAFCNie37Kczh1LH8DHWPaquRbbpbHQkNxCzJkU5skGxOqf2FMhxMKQkAAAAAqBsU6AAAAIBqGIahMfG9NCa+l9VR0IBMT6HMzU9L7rzSHSc3SyN/JsNgEhIAAAAAwPnjr0sAAAAAOFNuouTOVenKg6aUnyQVZVgcCgAAAADQXFCgAwAAAIAzhZ6xPpbhkFyR1mQBUCnTNK2OAAAAANQaU1wCAAAAwBmMiPZS7+tkJi6WbA4Zva+X4QizOlaT5ff5tWv7Cfl8fg0a2l4Op93qSGjCTF++lL9a8mXJdLSTIi+RYXNZHQsAAAAICgU6AAAAAKiE0XGcjI7jrI7R5JmmqWef/ELfbkqSJPUdGK9fPD5VdjsTujRVpi9b8hdJjrYyDAveVij8RvJll972npSKt0vhoxo+BwAAAHAeKNABAAAAKi0i7MlOUZ6nSANiOyrKRbcUUBdSknICxTlJ2rcrTYcPnFLvfvEWpkJtmcV7SgtkkmSLkhl9uQxbSMOG8BeqdH3Isu2ihr0+AAAAUAco0AEAAACSPkzcrK9O7pckRThC9LMhlyuaIh1w3kJCzv6zMyTUaUESnC/TNKXCLd/t8OdJ7iNSaL/6vaZ8FTv1QvpIhevKjpBCetbb9QEAAID6wpwiAAAAaJE8fp92ZSZpX3aqvH6fvj55IHBfgbdEOzKPW5gOaFq2b0nWh//drr27Tp51X5v4SF1z89DA9oxZA9SlW6uGjFfvTH+hzIINMvO/kunNsDpO/TLOfBuh/t5WMH3ZUva7UtZ/ZOYukel3l0YI7S1FTZXCRkrRl8twdqi3DAAAAEB9oYMOAAAALY7X79MLuz5TUkGmJGlo6y4KsTlU7PcEjolwNPCUbUAT9flnB/Sv59fLMAyZpqn7H71EI8Z0rnDM1dcP0ZTL+8r0S5HRzet7yzT9Uu4yyZ9fusOdKDNmlgx7hLXB6oFhGDLDx0gFX0kyJXsbKaR7/V2wYINknp6+0ntKKt4phY8ozeJsLznb19+1AQAAgHpGgQ4AAAAtzqHctEBxTpK2ZR7TjT3H6v3EzSrxeTSyTTcNietczQgAyqxdeUhS6VSEhiF99fnhswp0khQR+V1hrsjr1q6sJDltdg1q1Vl2WxOe3MVfVDrVY4BP8p2SmmGBTpKMkB4ynR0ks1iyRcs4q6OudszifVLRdslwSBEXynC2k/zFqrDWnFlSJ9cCAAAAGgMKdAAAAGhxQuxn/xrcN7aDHh/VXT7TJ6eNX5OBmoqLj9Ch/afk95syDEOt24RXe7zb59Xfdi7TqeLSola/2A76Yd+JMgyjIeLWPVuoZIRULB7ZYy2L0xAMW6ik0Dobz/RmSIUbTm9Iylsls9X1UuiAcmvNGVJIrzq7JgAAAGA13nkAAABAi9M1so0ujO+tdWkHZEi6susIRTpL32y2GfyKDATjph+MUkZ6gRIPZqjvoHaadcPQao8/lHsyUJyTpL3ZKcp2F6pVSNPsODMMu8yoqVLhJsn0SGGDZdhjrI7VtJRNDxrglUy3jNDeMu0xki9bcraTYY+2Ih0AAABQL3j3AQAAAC2OYRi6psdoTes8WHbDpjCHy+pIQJMV2ypMv3pyeo2PDz9jfUebDIXanXUdq0EZjtZS9DSrY1jONE3JlykZjuCKlI4EyXCVFjhlSvY4yQiTJBnOeMkZXz+BAQAAAAtRoAMAAECLVdY1B6DhdI1qo0s7DNDqlN2yGzZd2+MCiuTNgGn6pfzPJU9S6XbIABkRo2p0rmELlRl9hVRyUDKcUmif85ry1PRmSPlrJLNICukthY1sulOoAgAAoNmiQAcAAAAAaFAzugzT1E6DZRiG7IbN6jioC96TgeKcJKlkt8ywATJs1a9JWMawR0nhw+smS/4Xkr9AkikV75YcbSRXt7oZGwAAAKgjFOgAAAAAAA3OYbNbdu3MjEJ98s4OlRR7NeWKfureK86yLKgHZcW5Mr4z17gDAAAArEeBDgAAAABQZwo8JVqWtF257iKNattdg1p3tjpSBT6fX0/+arlOnSwt2mz86qj++PzVimsbYXGyJs6RIDk7fddFF1Lz7rk65+ouuQ9LMiTZJFfjeg0CAAAAEgU6AAAAAEAden3/l0rMOyVTpnZlJeknA6eqe1Rbq2MFZGcWKS01L7Dtdvt05GAGBbrzZBg2mZGTJF+WZNhl2GOsCxNxUWnB0CyUXF2tzQIAAABUgcn+AQAAAAB1pqw49912uoVpzhYdG6qo6BCVLX1nsxnq2IUCTl0wDEOGo7XlBTHDsMkI7S0jbKgMe6ylWQAAAICq0EEHAAAAVGFz+hF9mbpH4Y4Qzeo2SgnhvIkPnEuniNZKKsgMFOm6RDTs+m6mp0T+g1slV6hsPYbKMIwK9zuddj382yl661+bVVLs1cxrB6l9R763AQAAADQsCnQAAABAJY7nZ2jhoXWSJEOGXt67Wr8cfrVsZ7zZD6Ci7/e9WJ8e26ocd6EuiO+pnjEJDXZt01Oikr8/JPPEYUmSfcRUua598KzjunRvrV88PrXBcgEAAADAmSjQAQAAAJVILcwO3DZlKsddKLfPq1CH07pQQBMQ7QrTTb0usuTa/oNbA8U5SfJt+UzmZT+QERlrSR4AAAAAqAoFOgAAAKAS3aPaymHY5DNLp+nrGNFKIXZ+fQbq09HDmdq786S6dG+l/oPbBT+AK7TitmGTKKoDAAAAaIR4hwEAAACoRNuwaN09YIrWpx1UuCNEkzoMOGstKwB1Z8+OE3pq3gr5/aVF8R/cM1aXTO0d1Bi2HkNlHzFVvi2fSYZNzpl3yQiNqI+4AAAAAHBeKNABAAAAVegS1UZdotpYHQNoEb5ceUhmue1VS/YHXaAzDEOuax+UedkPJIdLRmh43YYEAAAAgDpCgQ4AAAAAYLnY2FAZkkxJNpuhVq3Daj0Wa84BAAAAaOxsVgcAAAAAAGDm9warz4B4SVL7jtG69UejLU6EumaaHpklR2S6k2Sa5rlPAAAAAJoxOugAAAAAAJaLiHTp0d9Pk9/nl83OZ0mbG9P0SDmfSv7c0h2u7lLkBGtDVcI0fVLJfslfJLm6y3C0sjoSAAAAmin+6gEAAAAANBoU55opT8p3xTlJch+R6S+2Lk9V8tdIhd9Ixbuk3MUyfTlWJwIAAEAzxV8+AAAAAACgfhmuM3dIht2SKFUxTVPyHCvbkuSTPMlWRgIAAEAzRoEOAAAAAADUL0c7KaTP6Q2bFHGRDMNpaaQzGYYh2SIkGd/ttEVZlgcAAADNG2vQAQAAAACAemUYhhQxVmb4CEl2GY2ge870pEreNMnRVoazQ+nOyElSwVela9CF9pWcnawNCQAAgGaLAh0AAAAAAGgQxllTXVrDLDkiFaxRabecKTNinIyQnjIcraWYK62OBwAAgBaAKS4BAAAAAEDL4j58+oZZ+n8lhyyLAgAAgJaJAh0AAAAAAGhZbJH6bq054/Q2AAAA0HAo0AEAAAAAgJYlbJjkaCfJLjnipfARVicCAABAC8MadAAAAEA9y/cUy2bYFO5oHGsvAUBLZ9hCpOipVscAAABAC0aBDgAAAKgnpmnqw8TN+urkfknSFV2G6ZIOAyxOBQAAAAAArMYUlwAAAEA9OV6QESjOSdKnx75VrrvIwkQAAAAAAKAxoIMOAAAAqCN+09Sm9MNKK8pV/1YdZJpnH+P2exs+GAAAAAAAaFTooAMAAADqyJJj3+rtwxu0JnWv/r57pXymT10j2wTuH9y6s+JCIi1MCAAAAAAAGgM66AAAAIA6sjXjqCTJL1M2GdqTnaK7BkzW/pwTshs29Y5JkGEYFqcEAAAAAABWo0AHAAAABKnE55HNMOS0Vfx1Oj40SrnuIpky5ZepNiFRctjsGtCqo0VJAQAAAABAY0SBDgAAAKgh0zT16bGt+iJ1r2wydHW3kbqoXZ/A/df3HKu3Dq1TWmGOBrfuogvb9bYwLQAAAAAAaKwo0AEAAAA1lFSQqS9S90oqncbyg8RNGhLXRZHOUElSbEiE7h4wxcqIAAAAAACgCbBZHQAAAABoKgq97grbpqQSn9eaMAAAAAAAoMmigw4AAACooR7R8WofHqvUwmxJ0oBWHdU6JMLaUAAAAAAA1LHQUJ8mXJhmdYx6s+Jdn9URKNABAAAANeW02fXTgdO0JztZdsOu/q06yDAMq2MBACSZpl8q3iP5ciRXJxmuLlZHAgAAAKpEgQ4AAAAIgsvu0NC4rlbHAIAWwTT9kueY5HdLri4ybKFVH1z4jVSyT5IhuQ/KjJwkw9W5wbICAAAAwWANOgAAAABoxLIyC7V310kVFrjPfTDQ3BR8JeV/KRWul3I+lukvrvpYT9LpG6YkQ/KkNERCAAAAoFbooAMAAACARmrH1hTNf2K1vF6/oqJD9Ks/Tle7DtFWxwIahGl6JPeRcjuKJE+yFNKz8hPsrSV/oUoLdKZkj22AlAAAAEDt0EEHAAAAADWUm1OsP/9mhX5y6yK98OcvVVLsqdfrvfvmt/L5/JKkgny3ln+8p16vBzQudp31uWKjmikuIy6UnJ0lW7QUOlgK6V2v6QAAAIDzQQcdAAAAANTQf179Rru3n5Dfb2rj18fUtl2UrrtteL1dzzjjI5U2m1Fv1wIaG8OwyYycIOWvleSRQvpKzg5VH28LlaIuabB8AAAAwPmggw4AAAAAauhEap78fvP0lqn0k3n1er3rbx8hp9MuSYqODdX0qwfU6/VgDdP0yTS9VsdoVExfjszivZLhlFrdKLW6VUbEGBkGRWoAAAA0D3TQAQAAAC3csbxTWnx8m/ymX9M6DVavmHZWR2q0LpzQXUcOZMhmM+T3mxp9Udd6vV7/we30zKvX6lRavtp3ilFICH/CNTdmySGpYJ0kv8yQ/lL4qBZfhDK9p6TcpZJKp3dV+GgZof0tzQQAAADUNf66AwAAAFqwIq9b/9izSm5/affOq3s/1yPDr1KMK9ziZI3TtCv7KbZ1mI4ezlT/we00eHjV0+3VlcioEEVGhdT7ddDwTNMjFXwt6XRXZskeydVFciZYmstyJYcUeE4kqXivRIEOAAAAzQwFOgAAAKAFyyopUIn/u6n1vKZf6UV5FOiqYBiGxozvpjHju1kdBc2B6VWFQpQkmSWWRGlUbKH67nkxJFuYlWkAAACAesEadAAAAEAL1iY0SlHOUBmn/xdqd6p9eKzVsYAWwbCFSc4u3+2wRUvO9tYFaixCB0iO01Pt2iKkiLHW5gEAAADqAR10AAAAQAvmsjv0k4FTtTplt/ymqYnt+ynCyXSKQG2ZpikV75RK9klGmBQxToYjtuoTIi+WPEml3XSuTjIMZ4NlbawMwylFT5Np+mUYfK4YAAAAzRMFOgAAAKCFaxMapet6jLE6BtA8eJKloq2nN4qk/NVS7OwqDzcMW+m6czgLxTkAAAA0ZxToAAAAAACoK/7cchum5M+TaZoyDMOySI2V6S+W3Eclwym5utW6IGd60iT3odKOxbCBdCECAACgSaBABwAAAABAXXF2UOly72bpP2dninOVMP0lUs4nkllYusN9TIq6JPhxvFlS3rKyLcl7SoqeUmc5AQAAgPpCgQ4AAAAAgDpi2GNlRs+QSg5LtjAptL/VkRonT8p3xTlJ8hyT6S+RYQtyDUxPqkqLoad5U+hYBAAAQJNAgQ4AAAAAgDpkOOIkR5zVMRo3W+gZO+yScfZbFKa/WCrcXDp1qKubFNKvYvHNEVvuaEOyRVGcAwAAQJNAgQ4AAAAAANQp05MqFe2QZJPCR8hwtK54gKOdFDpQKt4tySFFjpNh2M8eqOCr0m47mZI3vbQr0dUtcLfh7CAzfLRUvE+yhUsRY+vxUQEAAAB1hwIdAAAAAACoM6YvX8pbKclfuiPvlMzYa2UYzsAxhmFI4SNlhg2XZFTd9eY9pe+msDQkb0aFAp0kGaH9mUoUAAAATY7N6gAAAAAAgMbFLDgpM3G5zNQNMv0+q+OgqfHlKFCckyTTLfkLKj3UMGzVT0npaCep7H5TciTUVUoAAADAUnTQAQAAAAACzMI0mZv/Ivm9kkwp57CMfjdZHQtNiaO1St9uOF3cNUIlW1Ttxoq8SCqKlHx5kqurDFenukoJAAAAWIoCHQAAAADgO6d2fleck6STmyQKdAiCYQuTGX3Z6fXlbFLYkMrXl6vJWIZTCh9ZtwEBAACARoACHQAAAADgO6GxqrDmV0isdVnQZBmOOClygtUxAAAAgEaLAh0AAADQTBV63Vpy7FudKs7TsDZdNSa+l9WRECTT9MvrT5KpEjlsnWQzwur/om2HSR2PSifWS64YGQNuq/9rAgAAAEALQ4EOAAAAaKYWHvxae7NTZcrUwdyTinCEalBr1m9qSoq838hrHpUkGb7dinBeJpsRWq/XNAybjN6zpd6z6/U6AAAAANCS2awOAAAAAKB+JOalyzw9VaFNho7ln7I4EYJhmt5AcU6STJXI60+xMBEAAAAAoK5QoAMAAACaqe7R8TJkSJL8MtUtqq3FiRAcm86c9MSo5+45AAAAAEDDYIpLAAAAoJm6seeFWpa0XRnF+Roa10UDWnW0OhKCYBg2hTsuVKF3gySPnLaechjtrY4FAAAAAKgDFOgAAACAZirM4dKsbqOsjoEguN0+FeSXKLZVmAzDkMPWXlHOqyWZMgwmQEHLZJo+yV8k2cL5PgAAAECzQYEOAAAAABqBvbtOav7vV6uoyKMeveP08G+nKCzcJcMwpNNTlQItjenLkXKXS2aRZIuQGTVNhj3K6lgAAADAeeOjZwAAAADQCLz24noVF3skSUcOZmjF4n0WJwIagcItkllcettfKBVta/AIpjdDZvEBmb7sBr82AAAAmi866AAAAACgESgu8so0S28bhqHiIq+1gYDGwPRKMss2Tm834OXdR6X8L05vGTKjpspwtmvQDAAAAGie6KADAAAAgEbgqusGB26Hhjl18ZReFqYBGomwgfpuilebFDqgYa9fvKfchimV0NkKAACAukEHHQAAAAA0ApdO76MeveOUdiJffQfGKyY2zOpIgOUMZweZMbMkX6Zkj5Nhj2zgAKEqLRCapf9vhDTs9QEAANBsUaADAAAAgEaiW884desZZ3UMoFEx7FGSPcqai4ePlPKyJH+eZI+RwoZakwMAAADNDgU6AECzYp5evMcwjHMcCQCoDyU+j04W5qh1aKQinaFWxwGA82LYo0o7+OSR5OR3TAAAANQZCnQAgGbBNE2ZiUukYyslu0vqd4uMNoOsjgUALUpGcb4W7FqufE+xHIZdc/pdol4xCVbHQjNwIiVXr/99g7IyCnXpjD6aNrO/1ZHQgpQW5VxWxwAAAEAzY7M6AAAAdSLnsHR0uWT6JG+RzN2vy/R5rE4FAC3KF6l7VOgpkST5TJ+WHP/W2kAIMEtyZB5bITNpjUyf24LrH5GZ85HMnCUyvaeCPn/+Hz7X3p0nlZqcq3+/skk7tqbUQ0pUxzR9MvO/kpm1UGbuUpm+AqsjAQAAAE0aBToAQPPgzq247fdIvhJrsgBAC+M3/Tqen6FC73c/d00L86Ai01Mgc9NfZB7+VObBd2VufykwJXSDXN+bLRWskXzZki9dylsh0/TV+Hy/39SJ5Bz5/aczG1Lysez6iIrqFO+R3Ick0y1506XCdVYnAgAAAJo0prgEADQPrfpIrujvCnVxA2W4Iq3NBAAtgM/06197v9C+nFRJksOwyW+achg2Te881OJ0kCRlH5Q8ed9t5xySSnKk0NiGub4/p+K26ZbMYsmIqNHpNpuhgcM6aNe3qSpb/mvAkHZ1HBLn5M+XZKi0/G5KvrxznAAAAACgOhToAABNlmma8prJ8psFcjg6yDbq51LaVskRKsWPsDoeALQIh3PTAsU5SfKafn2/z8XqEhmnKFeYhckQENKq4rbNKTnDG+76jrYq/dPzdNecLVoygntt3PvwxVr8wW5lZxZq/KSe6tK9dZ3HxDm4ukgl+xUo0rm6W50IAAAAaNIo0AEAmqwS3w65/XtP396pCOdU2TtdbHEqAGhZDBln7escZHHONE2ZMmUzmIG/PhjRXaSeV8tMXCbZXTL63ijD7mq469vCZUbP0MGd32rtmnzFxLXXjNk+hYXV/OsdGubUNTfRkWklw9lBZtRlkidZssdSoAMAAADOEwU6AECT5fYfLLfll9d/XHb7QMvyAEBL1CO6rQa26qRdWUmSpEkdBig6iOLcjszjWnRovTw+ryZ26K8ZnYfKMM4u+uH8GJ0nyeg8ybLrJydLT/4uWaYpmWa2Du7P1sO/mWJZHtSO4UyQnAlWxwAAAACaBQp0AIAmy6Yw+VW2/okpQ6GW5gGAlshm2PQ/fSboZFGOHDa72oRG1fhcj9+r/xz4Sl7TL0lanbJbfWPbq2c0BYDmZveOE/L5zMD2rm9T5ff5ZbPTNYnGy/RmSN4MydFGhoNpVQEAAFC3KNABAJqsMMcYFXq/lqlCOYwuctqYagkArGAYhtqFxwZ9XonPGyjOlcn3FNdRKjQmHTvHBm7bbIbi20VSnEOjZrqPS/mrv9uOnCzD1dHCRAAAAGhuKNABAJosu621olwzZZom06EBQBMU6QzVwFYdtSsrWZIU5QxV75j2FqdCfRg4tL1u/dForVi8T61ahel/7h5jdSSgesV7K26X7JUo0AEAAKAOUaADADR5FOcAoOm6udc4Ldi1TKmFOcrzFGtz+mFNaN/P6lioB1Ov6KepV/C1RRNhC5FkSDJL/99gKnUAAADULeYUAQDUK9Pvk5mTKLMw3eooANAoFHs9WpO6V5+n7GE6R0n7c04otTAnsP3x0a1y+7wWJgrOidxi/XvTUX2yK0Ven//cJwBoGsJGSLbTa2raYqTw4dbmAQAAQLNDBx0AoN6YPrfMbxdIecdKd/S4UkaXydaGAgAL+Uy//r57hZILs2RIWndyvx4acoVc9ub3a7lpmvLLlN2o/jOB/jPWoDNVel5TkJ5fotvfXK88t1emKX195JT+MHOI1bEA1AHDHikz5mpJXkkOZmwAAABAnaODDgBQf05t/644J8k8/KlMf9PpigCAupZelKvkwixJpZOmZZYU6Gj+KWtD1YMjeel6fMv7enTDQv3nwFfymVV3lvVv1VGdI1oHti/tMFChdmdDxDxvXx85pdyS0uKcJK06kKZiz/+zd99xcl2F3f8/507Z2areq9Vl2ZJ7xRjcKLYBYxMSigmhPGBKQkkIIQm/NEzyQAjhcUIggElCJ8QQbJptbHDvVZYlS7Iky+p1+87MPb8/RlZxVdndu+Xzzkthzt25935t2V7tfO85p5ptKEm9JoRACAXLOUmSJPWJofeoriRpAAkvOpSk4aa5UCIhHDBDbESxIcNEfePbK26lvdxFBO7ftoa5IyZy8vjZz/veQpLjikXns7ZtG6VcgcmNo/o37BEY31y393UAGuvyFPM+AylJkiRJemn+9ChJ6jtjF0PLUXuHYdbrCInPhkgavhoLJd4y9wwa83XU5wq88aiTGV/fknWsXtde6d5bQQag9SX22ssnOWa1jB9U5RzAaTPGcPnJMynmEsY0FvnsRYtJ+nmmzdbNbfzsmqXcetMqUvfAkyRJkqRBw09JJUl9JuQKcPyHoO1pKDQQSqNf+iRJGuKWjJnBkjEzso7Rp86YMI+bNzwGQDHJD9m/3hACV7xsDle8bE4m99+2pZ2/+MhP6ewoEyMsfWgD7/nwmZlkkSRJkqTh4s477+Tyyy9/3q9NnTqVG2644aCuY0EnSepTISTQPDXrGJKkfnTh9OOY2TyOXT3tHD1qKqPqGrOONCTdf/dTdLSX945v/fUq/uADp5PLDY2FUmKM/PoXK3j4/qeZftQoLr70GPKFXNaxJEmSJA1zxx9/PLfccssBxx544AE+9KEPccUVVxz0dSzoJEmSpGFqd08nq1s3M7bUzJTG3pvlHELgmNE+nNHXRo6u3/s6BGhqqSNJhs6Gr7+5/gm++eU7Abj/rnV0tPfw1nednHEqSZIkScNdsVhk3Lhxe8cdHR1ceeWVXHLJJVx66aUHfR0LOkmSJGkY2ty5m39+5Bd0V2szsN4061ROGT8741Q6FCeeOo3zL5zPjb9YQXNLHe//2FmEft4Dry8te2QTSRJI00iM8OgDG7KOJPWq2LMWupZDUg8NJxCS+pc+SZIkSQPOl7/8ZTo7O/nEJz5xSOdZ0EmSJEnD0J2bn6Bcrewd37D+kQFX0FUqKd1dFRqbillHGZBCCLztPafw1nef3CfFXDWm3LlpJTt72jl29DSmNY3p9Xu8mKPmjuG2m1cDEJLAnPnjXuIMafCIlS3QdtOeUYDqDhhxUZaRJEmShp0NGzZw7rnnvuDXD2Yvue3bt3P11VfzsY99jJEjRx7S/S3oJEl9Lu5aBTtWQNNUwthFWceRpCFh+c4NbO1qY/7ISYwpNR3y+XW5ApEIQNgzHkgefXAD//zZm+jqrLDkxCl86E/PpuD+Y8+rr2bN/WjV3dy1ZSUJgZuffowPHfsqpvbiUqgv5bzXLqCzo8xD9z3NjFmjefPlx/fbvaU+V9m63yBCdTsxprX9myVJkjRofPvb36a5uZk3v/nNh3yuBZ0kqU/FbUuJD3+F2se/EeZeSphyVtaxJGlQu3H9o/xs3YMAFJIcHz7mVUxsGHlI1zhr4nyW7niK9e07qMsVeONRA2tvr69+8Va6u2oz/B68dz233LiSV75qXsaphpcHt60BICUSCCzdsb5fC7okCbz+dxbz+t9Z3G/3lPpNfux+gwC5UZZzkiRJ/WzSpEkHNUvuxVxzzTW84Q1voFQqHfK5FnSSpD4VN93L3nIOiBvutKCTpCN0y8bH976upin3bX2S104/7pCuUZ8v8uFjXk1buYuGfJF8MrBmp3W0l4m1bx2EAB3tPdkGGoZGl5rY2LGLuOf/xtQd+kxNSc8v5McRm86GrhV79qBzhqgkSdJgs2zZMtatW8fFF198WOcfUkF35513cvnllz/v16ZOnXrETaMkaQgqjdxvkECp/568l6ShqqlQoq3cRaQ2u6kxX3dY10lCoKVY37vheslrLjmaa777EACNTXWcdtZRGScaft4292V894nb2N7dzknjZnH82JlZR5KGlFCcAcUZWceQJEnSYbrnnnsYM2YMCxYsOKzzD6mgO/7447nlllsOOPbAAw/woQ99iCuuuOKwAkiShrYw/Xxi+0bY8Tg0TiHMfWPWkSRp0Pud2afxjWU3s7vcyYKRkzlj4tw+vV8sdxCXfx9a18KoBYS5byQkfbsYxyW/u4QFiyawfWsHxxw/iREjB2aROJSNr2/hw8e+OusY/SJ2PQ49qyFphoYTCcmhL08jSZIkaXhZunQp8+fPP+zzD+mn6mKxyLhx4/aOOzo6uPLKK7nkkku49NJLDzuEJGnoCvkS4dj3ZB1DkoaUqY2j+fMT3kA1pv2yNGVceQ1seRCIsOF2qGuBmX1f3Cw8dmKf30P9L8YI5XWQtkFhKiHXkm2enrXQceee0RZIO6HlvEwzSZIkSRr4tmzZwsiRIw/7/CN67PXLX/4ynZ2dfOITnziSy0iSJEk6RCEE8qGf9o1r38Aze4kCxPaNhP65s4aizvug69E9g/uJIy4i5EZkl6eylX375UaobskuiyRJkqRB46tf/eoRnZ8c7onbt2/n6quv5n3ve98RNYSSJEmSBrYw9tg9LxIgEsYsyjSPBrmu5fsNUuh5MqskNfkJ7CugA+SduSlJkiSp7x32DLpvf/vbNDc38+Y3v7k380iSJEkaaKafRyg0EVufIoyaSxh/fNaJNJgl9ZCW9wwihGz3FwzFKcTGs2pFYdIEDUsyzSNJkiRpeDjsgu6aa67hDW94A6WSm2dLkiRJQ1kICUw+w2UtRVpN+d8fPsLD9z/NzDljeNPbj6ejvYf/9w+/Ye2q7Ry9ZBLv++jLqK8vvPBFml4GrTdB7ITiTKib00/pX1ioOwrqjso6hiRJkqRh5LAKumXLlrFu3Touvvji3s4jSZIkSRqgfnXt4/zoOw8C8MTjW6mUU1p3d7Fq+VbSNPLgPev53x88zO9cfsILXiPkx8Koy4gxEoK1ryRJkqTh6bAKunvuuYcxY8awYMGC3s4jSepn8clfENf9GvL1hAVvIYyam3UkSZI0QK1asZUQAjFGYow88fgWcrlAmj6zh1tk25b2g7qW5ZwkSZKk4Sw5nJOWLl3K/PnzezuLJKmfxR0riE/+DKpd0L2T+MjXiGk161iSJGmAWnDMBGKslXEhwNGLJ3LWubUlKkMSiBFOP9ulIiVJkiTppRzWDLotW7YwcuTIXo4iSep33Tv2G8RaUZf2QFKfWSRJkjRwveKCuVSrkUcf3MD0o0Zx8aXHkC/kGDuukTWrtrPgmAnMXzQh65iSJEmSNOAdVkH31a9+tbdzSJKyMGo+5Ouh0gVEGL2QkLeckyRJzy+EwHmvnc95rz1wRZXjTp7KcSdPzSiVJEmSJA0+h1XQSZKGhlA3Ak78OGy+r1bUTTot60iSJElDUowpdD0Kle1QmAh189yHT5IkSRrGLOgkaZgL9WNgxvlZx5AkSYNEGjsop+sIFCkkMwjhsLY2H346H4Suh2uvy2tq/1tyb3dJkiRpuLKgkyRJkiQdlDR20lb+JdADQCV9mobCmdmGGizKTz9rvNGCTpIkSRrGfNRRkiRJknRQKukGninnACpxPTFWsgs0mOTHAvstaZkfk1kUSZIkSdlzBp0kSZIk6aAkoeFZRwrE8iaInVCYTEie/XXt1XBi7X8rW6EwGUpHZ5tHkiRJUqYs6CQpQzFG6N4JuTpCwQ+0JEnSwJYLEygmC+hJlxMoUqqOIXTeUPtiKBJbLiLkmrINOUCFkIfGU7OOMeTFrsehZzUkzdBwIiEpZR1JkiRJel4WdJKUkZhWiUuvhq0PAwHmvYkw+YysY0mSJL2gEAKl/GJKLAYgbv/Wvi/GHuh5EuqPySachr3YsxY67twz2gJpJ7Scl2kmSZIk6YW4B50kZWX70j3lHEAkrvghsVrONJIkSdIhCXUvPtawFMubiN2riGln/964spV9+/xFqG7p3/tLkiRJh8AZdJKUlWeXcTGt/Rok4o7lxE33QN1IwrRzCXk/kJMkadhpOhPaboJYhsI0qJuVdSJlLHY+BJ0P1Aahbs+yp439c/P8BOCRPYMA+Yn9c19JkiTpMFjQSVJWxiyCxknQvqE2nvqKPim5ymk3y3feQWt5G2PqpjJ7xEkk4cgmUMfda4kP/uu+ces6wuL/c6RRJUnSIBMKk4gj3wxUCaGQdRwNBJ2P7Hsdu2v7wfXTsqehOIXYeFZtqdWkCRqW9Mt9JUmSpMNhQSdJGQn5OjjhI7DzCcjXQ8vMPrnPil13saVrDRBZ3/EYdbl6pjcfe2QX3bl8z4tY+58djx/Z9SRJ0qAVQoK7J2ivUIRY2W/cv8VtqDsK6o7q13tKkiRJh8OfoiQpQyFXJIw5mjDiKEIIL33CYWgvb2dvkUagvbLzyC/aOHm/aybQMOnIrylJkqTBr+kM9j4LnJ8MdXMyjSNJkiQNVM6gk6Q+EHvaiKt/Cp3bCRNPIkw8JbMsY0vTaW/bCQQgMrpuyhFfM4w5Gua8kbjh9toedHMvO+JrSpIkafALhcnEUW+u7UsY6vrsITRJkiRpsLOgk6Q+EJd+s7Z0JZG4czkUmgljFh78+bFMZ+UOKnEzuTCa+vzpJKF0WFlmNi+hkCvRXt7BqLrJjK+feVjXebYw9eWEqS/vlWtJkjRUtbd188A962lsKrLkxCmWFRoWQshByGUdQ5IkSRrQLOgkqS/sru35VhOIu588pIKuu/oolbgRiJSrW3hg/a+Z2HQWs8c2HXKUEBKmNh78vSVJUu9ob+vmLz5yLdu2tANw9vlz+IMPnJ5xKkmSJEnSQOAedJLUi256YjO//607ebRzDJFnnpCPhBGzDuk6aewgxlrBlySQSzr4wA/vpatS7eXEkqSB6oldG/n2ilv5yZP30lHpPqRzOys9PNW+nZ5qpY/S6WDcf/dTe8s5gJt/9QTdXeWXPC+mVeLmB4gb7yZWuvoyoiRJkiQpI86gk6ResnZHO3/204dII3x8+7G8f0qJi2aXyE08iTB6/iFdq5CbTiU+RTWFXAK/WlbHzs4yG3d3MXN0Yx/9FUiSBoqn23fwlcd+vXe8tm0bHzzmgoM6d03rVr7y2I30pBWa8nVcseh8xtW39FVUvYjGxuIB40IxRy7/4sv+xRiJj3wNti+tHWgYDyd+nJArvuh5kiRJkqTBxRl0ktRLVm9rJ92zquWuSpHPrlnE5pmXEyaceMjXKiRT6Smfwffuq+cvr23iZ0tLjGkoMqnl8PahkyQNLqtaNxP3+781bVupxvSgzv3Zugcpp7WZcx2VHm56+rG+jKoXseSkqZx1zmwACoUc7/3DM8nnX+JHsO4d+8o5gI7Ne/a1lSRJkiQNJc6gk6ResmjiCOoLObr3LEM5eUQ945vrDutaXZUqoxum8LKjmlm7fQ0XzE/4g9OOou4lnrqXJA0NUxpG7X0dCIyvbyYXDu7ZunS/Ii8C6d49UdVftne1sb5jB1MaRvHuD5/BW99zMoV8Qr5wEN/HcyVqz1HuV8gWGvoqqiRJkiQpIxZ0ktRLxjbV8ZU3n8QPH3iKunzC20+eST45tInKPZWUT137ML9dtYWR9QX+4XVL+MxFi/sosSRpoDqqZTxvnn0at21cQXOxxOtnHPxs7FdNXcy/L/s1lZhSyuU5e9KCPkyqZ1u1ezNffexGKjElFxLeveCVzBkx4aDPD4UGmP9m4vLvQ0xh+rmElpl9F1iSJEmSlAkLOknqRXPHNfPJ8xce9vk/eWQ9v121BYBdXWX++ueP8sM/OLO34kmSBpGTxs3ipHGzDvm82SMm8MnjX8+Wrt1MahhJQ/7wZnPr8Pxmw7K9y5FWY8pNTy89pIIOIEw6FSacBDEl5Ap9EfOwxRhp3d1NfUOBwsHMCJQkSZIkPS8LOkkaQHZ2lkkCpBFihJ1d5awjSZIGkeU7N7ClazdzR0xidsuhlULqHcUkBwQgEggUc4f3I1dIcsDBF2A9PVXadncxcnQDSRIO654veY/uCv/4tzfy2MObKJXyfPiTr2DRkkl9ci9JkiRJGuoObe01SVKfetXCiZT222fud4+fnmEaSdJgcvPTj/HVZb/mmifv5QsPXcdT7duzjjQsXTBtMS2FEgBNhTpePW1Jn99z+dLNfPgdP+Aj7/4Rf/XH19He1tMn97n5V0/w2MObAOjurvC1L93eJ/eRJEmSpOHAGXSSNIBMG9nAty8/nTue3MqkEfWcMn101pEkSYPErRuX732dxsh9W1YztdHvI/1tbKmZPz3+dezu6aSlWE8+6ftlIK/+8p107Zl1v2b1Dq6/dhmvf3Pv72Hb2VkmhECMkRhrY2m4iGkXtN8J6S4oTIf6JYTQN7NVJUmSNDw4g06SBpiJLSXesHgqp84Y4w/9kqSD1lQoEah934hEmvbM4lL/yyc5Rpea+qWcA+juKhNj7XUAuroqfXKfM18xi8am4t7xRZce0yf3kQak9tugvBaqO6HrIehekXUiSZIkDXLOoJMkSZKGgDfNPpVvLLuZHT3tzBsxiZdNnJ91JPWT173pWL5+1R0AlOrznH3+nD65z5hxjVz5pYt59KGNjB3fyNwF4/vkPtKAVNkO7GnCCVDdcViXiXvadB/EkyRJkgWdJEmSNARMahjJJ49/HWmM5BIXyhhOzj5/LkfNGcOmDa3MO3o8I0bW99m9WkbWc/rLj+qz60sDVnEqdC+nNk81QmHyIV8i9qyF9lshVomlYwgNx/V2SkmSJA0iFnSSJEnSEBFCIOesjGFp+lGjmX6Uew5mbe8+ZdUdUJwO9ccRgoX5kNBwMiSNUN0NxamE4rRDOj3GCrT9BkhrB7oeIhYmEwrORJUkSRquLOgkSZIk6TDFGKF7GZQ3Q34slBZayAxn7XdAeR0QoesRSBqgtCDrVOoFIeSg/tjDv0Ass7ec23us84gySZIkaXCzoJMkSZKkw9X1GHTeU3tdXgNUoX5xppGUoWrv7FOmISiUoDAFyuv3jBsgPynbTJIkScqUBZ0kSZIkHa7KhgPH5Q0WdMNZYWptRuXefcqmZJ1IA0QIgdj0Cuh5sjabrjiTkBSzjiVJkqQMWdBJkiRJ0uHKjdk3IwZqy1xq+Go4ac8+ZbugOIVQnJ51Ig0gIeSgbnbWMSRJkjRAWNBJkiRJ0uGqPxaoQnkj5MdD/XFZJ1KGQkigflHWMSRJkiQNAhZ0kiRJknSYQshBw4lZx5AkSZIkDTIWdJIkSZIkqVfEnqeg+3EIRag/npBryjqSJEmSNCBZ0EmSJEmSpCMWKzug7cY9owCVbcQRryeEkGkuSZIkaSBKsg4gSZIkSZKGgOrW/QYR0t0Qy5nFkSRJkgYyCzpJkiRJknTkcmP3GwRIWiAUev02sdpGLG8kpj29fm1JkiSpv7jEpSRJkiRJg1istkLaBvkxhFDMLEfIjyI2nQvdyyDU1fag6+XlLWPPWmi7GYgQSsSW1xByzb16D0mSJKk/WNBJGtZitUL5p/9GdemtJOOmU3zTxwkjxr70iZIkSdIAELtXQ/tva4NQT2x5LSHXmFmeUJwCxSl9d4OO+4FYex27oWsZNJ7cd/eTJEmS+ogFnaRhrXrnT6nedS0Aaftuen70T9S9828zTnXk4u61xMe/C+U2wrRXEqa9MutIkiT1i6fatnPj04+ShMB5U45hYsPIrCNJfavz/n2vYxd0L4eG42vDnnXQvQKSeqg/jpDU92u0WH4auh7bM5vuOEKu6cgvGpIXH0uSJEmDhAWdpGEt3fo0JAmkKcSUdMu6rCMdsRgj8eGvQrkNiMSVP4amqYRRc7OOJklSn2ord/GvS6+nnFaAwIpdG/nk8a+nlOv9PbCkgePZS0jWxrGyFdp+ve9YZTuMuLDfUsXKTmi9gdpstwCVrcQRrz/yJS8bToTWXwNVSBqgtPDIw0qSJEkZsKCTNKzljj6d6p0/3VvS5ReffVjXae0q85NHn6aaRi5eNJlRDdnt/UFahnLrgcc6t4IFnSRpiNvUsYuetLJnFOmo9LCtq5UpjaMzzSX1qYaToe0mIIWkCUoLascrm/d7U4TqNmJMCf0146y6lb1LURIh3Q2xpzab7giEwmTiyMsgbYfcCELIHXFUSZIkPVdDHi6cXs46Rp+5bQC0YwMggiRlJzfneIrvupJ02V2EcdPInXjBIV+jUk153/fvYdX2dgJwzUNP8a3LT6e+kM2HBSFXJI6aDzuWAwGSPIyal0kWSZL604SGERSSHJW0CgRKuTxj6pqzjiX1qVCcuqew6oRcy77CKrf/vsoBcqP6r5wDyI2p3feZGXRJE4TeeYgtJHWQHFnRJ0mSJGXNgk7SsJebtYTcrCWHff7q7e2s3NYO1D5+eHp3F49t2s0JU0e96HkxRra0ddNSKlDq5TIvHPMuWP9bYrmdMPFkQv2YXr2+JEmHY/UT27jq//6Gnds7OOvcObz9vaeQJEe43N1+mgol/s/Cc7lh/SMkIeH8qcdSyru8pYa+kJQgKR14rDCe2PRy6FpeWwqy4YT+zZQfRWw6p7YHXVIH9ccf+fKWkiRJ0hBiQSdJR2hMYx25EKjG2hI+ARjf9OJP9Hb0VPjwj+7nkQ27qMsn/MPrlnDqjN4r0UKuCNPPfc6OJJIkZemq//sbtm5uI0a48efLmbdwPKeffVSv3mNG81j+YMErevWa0mAVijOhODPD+0+B4pTM7i9JkiQNZP24voUkDU2jG4r89WuPYUxjkZH1Bf7s/IVMHdnwoudc8/B6Ht2wC4CeSsqVv3qsP6IOKLF1O9XVDxM7Wl/6zZKkIWHH9g72PM9CCLB9zwx0abCJsUrsWVv7FatZx5EkSZI0CDmDTpJ6wbnzJnDuvAkH/f6ucpUQIMbaspidleH1wU519cP0XP0XUOmBUiN17/2/JBNmZh1LktTHzjpnNr/+xQpCgEIhx4mnTu/V669r28atG5dTzOU5d8oiRhRf/IEZ6XDEmELrr6CyuXYgP4HYfH7/7u8mSZIkadCzoJOkDFy4aDI/eGAdOzrLALzr1N5d3mugq9z4LajW/trp7qTy2/+meNnHsg0lSepzl7/3FOYuHM/2re2cfPoMJk5p6bVr7+xu51+XXk8lTQFYsWsjH19yITlLE/W26vZ95RxAZRNUd0DePX8lSZIkHTwLOknKwITmEt99x+ncv34nE5tLLJjQex9QDgrP/rA0uFueJA0HSS7hzFfM6pNrr23bRjndNyN9a1crrT2djKxr7JP7aRgLxYM7JkmSJEkvwsdJJSkjI+qLvGLO+Oct5yrpNjoqd9BZuYc0dmSQrm8Vzr8ciqXaoKGZ/Nm/k20gSdKgN7FhBIHaAx+BQGO+jqZCKeNUOhRtrd2sfmIb3V3lrKO8qJBrgfrj9h2oP56Qa84sjyRJkqTByRl0kjTApLGdjspNQBUIVNJNNBVeM6T2NUmmLaD0x98kbt9AGDuVUFefdSRJ0iA3vn4El887i18//Sh1uQIXTT+efJLLOpYO0uOPbuJzf30DPd1VRowq8edXvprxEwdu6RXqFxNLC2uvQyHjNJIkSZIGIws6SRpgqnE7tXIOIBJpJ9JJYGgt0RXqmwhT5h7Ueze3dvHNu5+ku1LlTcdNY/74YbYkqCTpoBwzeirHjJ6adQwdhh/85/2Ue2p//mnd1c111yzl9993asapXpzFnCRJkqQjYUEnSS8g3bSG8s/+ndjVTuGsy8gtOqNf7puEkUAAIrVFuooEhu8SXZVqyvt/cC8bdncCcMPyzXz/989gXFNdxskkSVJvSWM8YBzT+ALvlCRJkqShYeisl6ZBIX1qOV3/+kd0feG9VO77VdZxNEyt/9U9PHTlt9l06yMv+J5YrdD99T8jfeJ+4rpl9Hzn70g3remXfLnQTH3+THJhLLkwgYb8Kwhh+C7Rtam1i/W7OkkjpBE6y1Ue27Q761iSJKkXXfqW48jlaz+e1jcWePXrF2acSJIkSZL6ljPo1G9itUL3N/8SOtsgppT/+wskE2eRTJ6ddTQNI8u//jNufffnIAkQI+de8zdMv/h5Zsa174a2HfvGMZJuepJkwox+yVlIJlNIJvfLvQa6sU11tJQKtHWXSSPkQuCoMUNruU9Jkoa7RUsm8fl/u4RNG1qZOmMUjU3FrCNJkiRJUp9yBp36T2cbdOyGmO49lG5Zl2EgDUfLv3Zd7UUaIQSe+I9fPv8bm0YSxk6FkNR+5QskU+f3X1DtVZfP8aVLj+f4qaNYNLGFz168mGkjG7KOJUmSetnI0Q3MXzTBck6SJEnSsOAMOvWfxhGESbOJG1fXttfKF0lmLMo6lYaZphkT2HrXMmI1JYRA45Rxz/u+kCTUveuzlG/6DnR3kj/tIpLRE/s5rZ4xf3wLV112YtYxJGnYe2T7Uzy8fS1jS828YvLRFJLhuwSzpKEnph1Q3gBJI6Hgn/0lSZLUtyzo1G9CCNT9wWeo3PIjYncH+ZNfTTLy+csRqa+c8rn30bZ6I9vuW8GEsxdz3P/3jhd8b2gZTfF1H+jHdJIkDVyP79zAN5f/hkAAIlu7Wvm9Oc+zTPQwcu8da7n5+icYOaqey956HC0j67OOJOkwxWob7P4pxJ7auP44Qv3ijFNJkiRpKLOgU78KDc0ULnjhQkTqaw2Tx3LR7f8v6xiSJA06K3ZtJCGQEoFaYTecPfH4Fv75szcDkCSBdU/u4NP/97UZp5J02HpWQSzvG3c9ChZ0kiRJ6kPuQSdJGhAq1ZTHN+9mS1t31lEkSc9jUsPIveVcIDClcVTGibL1xONb9r5O08iqFdtIq+mLnCFpQAtF2PPfuH1jSZIkqe84g06SlLn27grv+8E9rNjSRhLgzy84mtcePTnrWJKk/Zwwdia7ejq4f+saxtc384aZJ2UdqU/c+PPl/O8PHqZUX+D3338q8xdNeN73zZ43du/rJAlMP2oUSc7nH6VBq24ulJ+C8tMQCtB4ZtaJJEmSNMRZ0EkatqpP3E/lpu9BvkDhgt8nmTw760jD1nWPbWDFljYA0gj/eNNyC7oB6LbVW/m321aSSwIfPGsuJ0wd3rNnpOEmhMA5UxZxzpRFWUfpM0+u3MY3v3wnACHAF/7u13zpm2+iUMg9571zF4znA3/8cm765XJGjmrgdy4/vr/jSoNW7FkDXY9DKEHDCYRcU9aRCCEHzecR0x4IeUKwcJckSVLfsqCTNCylOzfT8x+fhmoVQqB73eOUPvEfhGIp62j9bsWWVn74wFPUFxLedtJMxjbV9XuGNEYC+xYVijG+2NuVgc2tXfzJTx6kmtZ+bz76P/fzk/ecRUupkHEySeo9mza07n0dI3R2lGlv7Wbk6Ibnff8pZ87glDNn9Fc8aVCJMYW0HZJ6Qtj30UOsbIW2m/eMArTugJGv76MMEcproLIDCpMIhYkveU5IXNpSkiRJ/cOCTv0ipinV239MddVDJFPmkj/7dwg5//FTduKmNVCt7BlE6Goj7txMGD8922D9bEtbN+/93j10V6oA3PbkNr59+Wnkk/59Yvg1CyfxowefYs2ODgLwwbPm9uv99dLW7eygku4rTrsqKZtauwZ1QXfd0qe5ccVmpo5s4D2nz6Kx6Pclabibv2gCDY0FujorxBg5as4YRoyqzzqWNOjEtBN2/wLS3UCB2HwuoTC+9sXK1v3fCekuYs86QnFa7wfpehQ67wMCdD1MbDqHUJza+/eRJEmSDoOfRKlfVO/4CeXrvgpAuuwuqJQpXPCOjFNpOEsmz4ZiCco9tQPNowijXvqJ2qHm0Y276CxX947X7uhgS1s3k1r698PIllKB/3jbqTy2qZWxjUWmjnz+mQrKzrxxzYwoFWjrrhXbYxqLTBs1eH+ffrNyC3/9i6UAJAE27e7iyosXZ5xKUtZGjqrn//vca7n5+ieoLxU478L5hBCyjiUNCjHthJ6nIKmD8mZIn5mRWoaOu2DERbVhfvxzT267iTjidYTciN4N1bPqmXRAgJ410AsFXYwRKpsg9tRm5oXB+8CSJEmSsmNBp35RffKR/UaR6qoH8UcYZSk0j6bu3f9A5bb/gVyB/CveTCgMv+VsZo5uJAm1fd+SAE3FPKMbsvn7UJfPcdyUkZncWy+tuVTgq797Mt+/fy25JPB7J8yglH/unkyDxYPrd5ILgWqMpBHuX78j60iSBogJk1r4nbefkHUMqU/FWAbotWIppp2w638hdtUOJM8q2uK+B8JCfjSx8Sxo/+3+b4DKNujtgi5phuqu2vWJkDT2znU77obuZXvu0UIc8VpCGH4/S0iSJOnIWNCpXyRT55M+elttEAK56QuzDSQByZQ5FN/0x1nHyNTM0Y387YXHcvWdT1JfzPGRs+dRN4hLF/Wt6aMa+Pg5C7KO0SsWTWyhumevwyTAMZN6+QNBSZIGqNj5EHQ+UHtdfxyhvhdmkPes21fOAaS7qH3csGdJ+WffozgDOu+v7VH3zOy2/Ngjz/FsjadCWzdUd0B+MtQfc8SXjLG8r5yD2jKePU9B3awjvrYkSZKGFws60V7u5ltP3Mqa1q0c1TyOt8w9k4Z87z79l3/ZG6HcTXXlg+SmLSB/3tt79fqSDt85cydwztwJWccY8NIYqaaRQq5/9+fTkdvZ2cNfXPcISzfu4sRpo/n0qxfxyrnj+fg587lx+Samj2rkipfNyTqmJEl9LlZ37y3nAOh8gFicSci1HNmFk7pnHSjAiNdDeS10PQbttxHL66HxDEJICCEhNl9QyxJ7oLTwyDM8j5A0QMure/mqyZ5f6X43cn0YSZIkHToLOvGzdQ/wxK5NRCLLd23kF+se5JKjTu7Ve4QkR+Hct1E49229el1JOhwxrUD7RqgbSSg2veT7b1m1hU//7BE6eqpcsngKf3zOAvckGkT++eYV3LtuO2ms/V5+7Y5VfPjl87hsyTQuWzIt63iSJPWfPUtbvuSxQ1WYDsU50PMEUICmswi5BmLbSkjbgFjbDy4/Fkq12fgh1wRNLzswSkyh/DRQhcLkAbm3Wwg5YuPp0H4bEKEwAwpTso4lSZKkQciCTmzvaidSW+YrEtne3Z5xIknqO7GnlXj/F6FzK4QcLPoDwthFL/j+ahr5y+seoaNc2zvlRw+t54yjxvKyWeP6K7KO0FO7Okhr3+aIEZ7e1ZltIEmSspIbBfkJUNlUG+cn1I4doRACNJ1BjKcCyb4HmfYuYQkQ9oxfRNstUH5yT9aRxJbXEsLA+9gi1M0mFqdDrBCS+qzjSJIkaZBynS5xwriZAARqP0SdMHZmdmEkqY/F9bdA57Y9gypx5f+86PvLabq3nHvGzs5eeNJc/eZVCyYBtb3mInDevInZBpIkKSMhJNB8HjS9ovar+bzasV67fu7AVQbqnllCes+x4owXPDemHfvKOYDqTihv7LVsvS2EguWcJEmSjsjAexRN/e6kcbNoKpRY07qVmc3jmD9yUtaRJB2C7ds6uPHnj5MkCee+Zh4jRvpBwYuK6YuPn6WUz3Hh0ZO4dukGAMY0FDnzqLGHd+sYuW7pBlZta+f0mWM4afrow7qODs2lS6YytrHI0k27OWHqKE6dMSbrSJIkZSaEHBSn98/N6o+vzdBLW6EwlZB/sT/75KkVeXHfoQG4xKUkSZLUWyzoBMCCkZNZMHJy1jEkHaKuzjJ//SfXsWtHFwC337yKz3zpdRQKuYyTDVxhypnEjXdBzy4gEGZd/JLnfOqCozlz1lh2d5Z5+ZzxjGooHta9//2OVXztjtXkAnzr3jV84ZLjOH3m4ZV9OjRnzxnP2XPGZx1D0iGolKvs2N7JqDEN5PMu/CENRDFWofMBqGyB/ESoX3zAjLwQAtQddVDXCkmR2HAqdNwJRKibD3m/d0uSJGnosqBTv6uuepDy9f9JCAn5899BbuYL7/0k6cU9uWo7O7bt209r88Y21q/dyczZzhB6IaFuJJzySWhdB6XRhPqX/nuVhMA5cycc8b1/uay2TFM1Qi4Ebn5iiwWdJD2Pp5/axWf/4pfs2tHF6LENfPJvL2D8xOasYx2yGCN3/OZJVq/cxsJjJnD8KdOyjiT1rs4HoOvR2uvKZggJ1C9+ydNiLEPaBUnTAUtihtI8Yt0siCkhObwHoiRJkqTBwkdR1a9i2w56vvmXxLWPka55lJ6r/5zY0Zp1LGnQGje+iSTZ86FGgHw+YfTYxmxDPUtP9Unaen5Oe/kGqumOrOMAEPIlwqi5B1XO9abpoxrJ7fkQKo2RKSNcjlSSns9//9f9tO7qBmDn9k6u+d5DGSc6PL/4yWN8+Qu38Ktrl/FPn7mJ23+zOutIUu+qbHnWeOtLnhJ71sOO78Ou/4Hd1xLTngO+HkLeck6SJEnDggWd+lW6dT1UyhBj7Ve5m7h9Q9axpEFrzLhG3v+xsxg3oYkJE5v50CfOpmVEKetYe1XTHXRV7yJlN9W4jY7Kb4gvsefbUPan5y3kuKkjGVlf4MJFk/ndE/pp/5eDVE0jDzy1g4ef3kka40ufIEl9pKurQtzz36EYI91dlYwTHZ47b3kSgLQaCQHuvWNttoGk3paf+KzxQaw40HEnUK29rm6H7uW9HkuSJEkaDFziUv0qmTAT6puhq712oKGFMG4a1Yd/S/WxOwjjppI/6zJC3s3ApYN1ypkzOOXMGVnHeF5pPHCGbKSbSA+BgVMi9qdxTXVcddmJWcd4XtU08vEfP8DtT24D4IL5E/ir1xxzwLJTktRfXnvJIh57eBPVakoun/Cq1y3MOtJhmTR1BE+u3E6a1srGiZNbeuW6MVaBxP9GK3v1i2vLWla21sq50tEvfU6s7jcIEAdnAS9JkiQdKQs69atQ30Td//kcld/+N4SE/MsvI135AD3fvbL2gx2RuGsLxTd8OOuoknpBLhkD1RxQmzWXhBEE6rINpef12Kbde8s5gF8+vol3nTaLGaMH1pKpkoaHRUsm8dmrXsfaJ3cwc9Zoxo5vyjrSYXnLH5xEe1sPq1ZsZdHiSVz8pmOP6HoxVuis3E4lbiBQoiH/MnLJ6F5KKx26cJB7zgHEtL1W5NXNg64HnzkKXUuJIU+oP6bvgkqSJEkDkAWd+l0ybhrFN/7R3nHPrddAkkBa+wC/uvyebIJJ6nVJaKQxfy496UoCBYq5+T7tP0Dlk+f+vhRyroQtqXdt39bBow9sYOz4RhYeO/FF3zt+YjPjJzb3U7K+0dRcx0c+9cpeu15PupJKrC0PH+mis3I3TcVX9dr1pb4SK9tg98/Zu7Rl6QToeoDaQ1wV6LyPWJhAyI/LLqQkSZLUzyzolLlk0iyqe8o5QkIyeU62gST1qlwykvpkYC7rqH3mj2/m9cdM4cePrAfg7SfNYPKI+oxTSRpKNm9s5dMfu5aO9jIAl731uCOeUTbcxNgNBGDP/nx0Z5pHOmhdj/PMigoA9Kw+cAxQbQcLOkmSJA0jFnTKXO7EC4it26k+eith/AyKF78v60iSNOyEEPjk+Qt5xykzySWBCc3Dc59ASX3ntptX09m5b6+p66551ILuEBWSGfSkK3hmFlIxNzfbQNLBCvt/9BAgFGp71lU27TlUgsKLz6p9tph2QdfS2p52pXmE3IjeyytJkiT1Aws6ZS4kCYVz3kLhnLdkHUWShj1nzUnqK42NRWIa9467u6u07e6mqcW9SQ9WLhlBU+FVVNKNJKGJfHJohYaUmfpjoPw0pLshFKHxFMi1QPcTEMtQN4uQHPzDQTGmsPsXtesB9DxBHPEGQuKfYyRJkjR4uLmMJEmSpD539gVzKTUU9o7TasrP/3dphokGpyQ0UczNsZzToBKSBhjxOhhxKYy8jJAfTQh5QmkBof5YQtJ4aBdMOyDdRW2511gr+Spb+iK6JEmS1Gcs6CRJkiT1uWIxx6hR+2a3hBDo3m/JSw1taWynXF1HNe7OOooyEkJCyDUSQu7IL5aUastk7i/XcuTXlSRJkvqRBZ0GvdjTRWzbmXUMSRq2lm3azeduXMZXbltJW7cftkt6YfvvOVdXl+eVr5qXYZrDF2MkxvjSbxQAlXQbbeWf0Vm9nfbyLyin67OOpEEuhDw0nQu50ZC0QOPLCLmRWceSJEmSDol70GlQqzx0M+Uffh6qFZKjT6f4u39GyPXCE5mSpIOybmcH7/3ePVTTSCRy77rt/NubT846lqQB6sxXzGLGUaPYsH43cxeMY+TohqwjHbKf/2QpP/yvB0iSwOXvPYWXnTM760hHJFa2Q+fDtUH9YkJ+VK/fo5yuoLYUIUCkp7qMQjKl1++j4SUUxsOIi7KOIUmSJB02Z9Bp0IpplfKP/gmqtdka6dLbqT56S7ahJGmYuW/dDnqqKdUYSSM8+PQuOnqcRSfphU2dMYqTz5gxKMu5p9ft4jtfv5dyT5Xurgr//qXb2bWzM+tYhy2m3dD6Cyivrf1q/QUx7emDO+2/FGF41liSJEmShicLOg066Y5NVB64kXT9E1ApH/jF7sH7AYmkwSHGlDS2E2M16yi1JdbaNhBb1xFjmkmGmaMb975OAoxtLFJfcCazpKHp2WVcjJHW3d0ZpekF1Z0Qy9Rmt0WIPZD2/h5xdbmFBGrfLwJ1lHJLev0ekiRJkjTYuMSlBpV0/RN0f+XjUKk92ZvMP5n08bsBCKMmkDvmzCzjSRri0thGe/nXRDoJlGgovIJcaMksT1zxQ3j61tpg7LGw6J2E0L/P3iyZMpJPnLuA79y3lhGlAn9y7gJCCP2aQZL6y+x5Y5k0tYUNT+3eO548JbvvA0csN4Laj4QVajPb8rX9vHpZEhpoKryaSDeBun7/XiVJkiRJA5EFnQaVyt0/27ukJUDcuYXiu/8e2neRzDmBUBp8SyVJGjy6q48S6QIg0k135WEaCtk8GBA7t+0r5wC2Pgy718CIo4742l3lKhtbu5jcUs+aHe3csmorU0fWc968Cc9bvl2yeCqXLJ56xPeVpIGuWJfnLz77Gu685UmSXOD0lx9Fkhu8ZVNISsSW86HzISBA/RJCUuybe4WEQH2fXFuSJEmSBiMLOg0qoW6/Ai4khPomckcdm10gScNKjBVqy4ABRCJDb6+1xzfv5kM/vI/d3RVG1RfY3VUmAmmE5Ztb+cBZc7OOKEmZamwqcs6r52Udo9eE/DhoPjfrGJIkSZI07Azexz01LOVffhlhwszaoLGFwkXvyzSPpOGlmJvPvm+dgbrcgsyyhPoxMOWsfQfGHQctM474uv9yy0raemrF487OMtVYK+cA/vfRp4/4+pIkSZIkSZKcQadBJjSOoO6DX4KO3VBqIuRyWUeSNIzkk7E0FV5DNe4gF0aShKZM8yRzLyVOfhnEKjRO6pW933qqVWJ87vEkwITm0hFfX5IkSZIkSZIz6DQIhRAIjSMs5yRlIgmNFJKpmZdzzwiNEwhNk3ulnAN45ylHkU9q1yoVcpw5cyx1uYQZoxr5/169qFfuIUnqG91dZf7lc7/hQ+/4AV/4u1/T3taddSRJkiRJ0gtwBp36VbrpSco/+Rdi+y7yZ15C/uRXZx1JkoaNGCNsvIu4cwWheRpMOYsQDnxW55QZY/jBO89k1bY25o9vZkxjXUZpJUmH6prvPsRdt60lppGH7l3Pd6++l3d98IysY0mSJEnSkHTNNdfwla98hXXr1jF9+nQ++MEP8prXvOagz7egU7+JMdJ99V9C63aIKeVr/pkwYQa56QuzjiZJw8OGO4jLvwcE4qZ7CJVOmPncByUmtpSY2OJylpI02Gza2Ercs3FomkY2PLU740SSJEmSNDT9+Mc/5lOf+hR/9md/xllnncW1117LRz/6USZOnMjxxx9/UNdwicshIFbK9PzkKrq+8F56fvQFYndn1pGeX08X7N4KMd17KG5ak2EgSRpe4vZlz7yq/f9tj2UXRpIGqWWPbOLKT/2Cz/7FL3ni8S1ZxznAiadNByDJ1ZYqPuVlM7KMI0mSJElDUoyRL37xi1x++eW89a1vZfr06bz//e/njDPO4K677jro6ziDbgio/Po7VO+6DmKkuu1pKJQoXvz+rGM9R6irJ0xfSFz3OAQg5EiOOjbrWJI0bISmycStD1Er6AI0T806kiQNKjt3dPK5v7qeSqX2wNk/fPp6vvDvl9LYVMw4Wc2Zr5hFfUOBxx/ZxKx5YznlTAs6SZIkSeptq1evZv369Vx88cUHHP/a1752SNexoBsC0o1PQqzNhiCmpBtWZZrnxdRd/ldUfvvfxM5W8ideQDJ2StaRJGn4mH4ulDtgx+PQMoMw63VZJ5KkQWXj+t2Uy/tWg+juqrBlUyuNTWMyTHWg409o4Pj5myE+BT1lqJubdSRJkiRJGpA2bNjAueee+4Jfv+GGG573+OrVqwHo6OjgXe96F0uXLmXq1Km8//3v55xzzjno+1vQDQG5eSeSLrsDkgTSlNz8k7OO9IJCfROFC96RdQxJ/SiNHVTSjSShkXwyIes4w1pI8oS5l2QdQ5IGrakzRtLQWKSrswxAU3MdEye3ZJxqnxhTaL0BYjcQof12Ym4UIT8262iSJEmSNGS0tbUB8IlPfIIPfvCDfPzjH+cXv/gFV1xxBd/4xjc4/fTTD+o6FnRDQO6U10KhSLr6YZKp88md/JqsIw0YsVKGJEdI3G5RykI1ttJe/hVQAaAudyx1uYXZhpIk6TA1NdfxqStfxc+uWUoS4MJLj6FUX8g61j6xDLHrwGPVXWBBJ0mSJEnPMWnSpBecJfdiCoXaz4Hvete7uOSS2sPwCxcuZOnSpRZ0w00IgfwJ58MJ52cdZcCIMVL+yVW1vfmKJYpv+mNyRx/cvxSSek+5ugao7h33VB+3oJMkDWpTp4/kPR8+I+sYzy8UITcWqtv2HEgg7+x1SZIkSepNEybUfs6aN2/eAcfnzJnDTTfddNDXcVqR+kyMkXTtMqrL7iL2dL30Cb0offzuWjkH0NNFz/f/gVitvvhJknpdCEUg7htTl10YSZKGuBACNJ8HpWOgbh60vIaQa8o6VibSNJKm8aXfKEmSJEmHaNGiRTQ2NvLggw8ecHz58uVMnz79oK/jDDr1mcovr6bymx8AEMZNpe59/0QoNfTLvWPH7gMPlLuhWoZcrl/uL6mmmMymkm6kGjcSKFLKD9w9MiVJGgpCUoSG47OOkalfXbuM7159L4HA773zRM597fysI0mSJEkaQkqlEu9+97u56qqrmDBhAosXL+baa6/l1ltv5eqrrz7o61jQqU/Ecg+V3/5w33jLU1Qfu5388ef2y/1zC06h3DwGWmvL++SOP5dQLPXLvSXtE0KOxsLLibEC5GpP9kuSJPWRzRtb+a+v3r13/B9fuYslJ01h7PjhOZNQkiRJUt+44oorqK+v5wtf+AKbNm1i9uzZfOlLX+LUU0896GtY0KlvJAkkOahW9h4Khf5b2i40tFD60P+j+tgdhPpmkoWn9du9JT1XCH67kSRJfa9193OX1m/d3W1BJ0mSJKnXvfOd7+Sd73znYZ/vHnTqEyGXp/D6D0Ko/SOWLDiVZOHph3SNWCnTc+1X6Pri++j57y8QuzsOLUPjCPInvYrcojMIif+oS5IkDScxuv/YcDRj1himHzVq73jm7NFMmznqRc6QJEmSpGw4pUF9Jn/iBeSOPp3Y3UkYMe6Ql7ar/PaHVG/7MRCpbnkKcjmKb/hw34SVJEnSkLBrZydf/MxNrFqxjdnzxvKHf/YKWka41Plwkc8nfOozr+LOW54E4LSzZpLP+7CeJEmSpIHHgk59KtQ3E+qbD+q96c7NlK/7KrF1B/lTLyTduBoCEIGYkj69qk+zSpIkafD7/n/cz+onthFjZNWKrfzwv+7nDz5waCs5aHAr1Rc4+/y5WceQJEmSpBdlQacBo+c/Pk3cvA5iSnntUnIvfxPEWFsmM6bk5p+cdURJkiQNcDu3dZCmteUt0zSyc3tnxokkSZIkSXouCzoNCLFaJW5ac8Cx0DSKwqUfJV31EMnk2eROuyijdJIkSRosXn7+HB55cAMh1J71evl5c7KOJEmSJEnSc1jQaUAIuRxh2gLiU8uprWkJuZnHkEyZAyecl204SZIkDQoxVjjl5MjUzy/moUcSZs+bwLyF47OOJUmSJEnSc1jQacCoe/unKd/4bWjfSe7EC2rlnCRJknQQYqzC7l9AdRuTR8HkV06E5mOyjiVJkiRJ0vOyoNOAERpHULz4/VnHkCRJ0mBU2QrVbfuNN0J1F+RHZhZJkiRJkqQXkmQdQJIkSZKOWKh77rGk0P85JEmSJEk6CBZ0kiRJkga9kB8J9UueGUHDSYSkMctI2iOtpmze2Ep3VznrKJIkSZI0YLjEpSRJkqQhIdQvIZYWAYEQclnHGTLWr9vJV//pNrZta+eVF8zlkt9bQgjhoM5t3d3FlZ/6JevX7aKulOejf3EOCxZN6OPEkiRJkjTwOYNukIrlbioP3Uz1kVuIFZ9ElSQNbF2VKv9ww2P83n/czv+9cRndlWrWkSQNUSHkLed62Zf+/mbWrN7O7p1d/Pj7D3PP7WsP+txf/u8ynl6/G4Ce7gr/9ZW7+iqmJEmSJA0qzqAbhGKlTPdX/5i4/gkAktnHUfz9vyUk9q2ShobYtZO45hdQ6SJMOYswclbWkXSEvnrbKq55eD1phCe3t9NQyPGBs+ZmHUuSdBC2bGwjTSMAIcDmja0HfW53d4UARCBG6OnxAQ1JkiRJAgu6ASfduZnyj/8fcccmcieeT/5llz5n+Zh03bK95RxAuvIB4tanCOOn93dcSep1MabEB6+Czm1AJG59CE7+U0LDuKyj6Qis2NLKns92iRGWbzn4D3clSdk66Yzp3PGbJ0mSQEgCi0+Y8pLnpNWUr191B7+9cSXP/DgTArzhdxf3cVpJz4hpN7TfCdXtUJwG9ccTgg/2SpIkDRQWdANMz3c+UyvfYkrl518nGT2Z3KIzDnhPqG96znmh1NhfEftM7GwjXfsYYdQEEstGafgqt0Pnln3jWIXWNWBBN6idOnMMd63dThIgjXDazDEv+v5KmnLtoxvY3NrFK+dNYM7Y537vkyT1j/d86AxmzxvLjq0dnPKymUybOeolz7n9t0/y2xtXArUHMxqbi/z5la9m8tQRfR1X0jPa74DyWiBC16OQ1EPp6KxTSZIkaQ8LugEmbnoSYlobhIR005PPKeiSiUeRf+VbqNz0HSBQeO17CC0v/kHnQBd3baXrX/4Q2nYAUHjDh8mf/OqMU0nKRL4B6kZC9y5qC2IFaHrpJ/U1sL3lhOmU8jkefnoniyeP5JLFL/57+g83LOMnjzxNEuA/7nmSq99yKrMt6SQpE/lCjgsuWnhI5+za2UkItXIOoKuzYjkn9bfqDmp/ngYIUNmZYRhJkiQ9mwXdAJPMO5l06W2wZ6eGZM7xz/u+wnlvI//yyyAkhEKxXzP2hco9v4D2XXvH5Rv+c0gXdLGnCzrboGXMc5YwlYa7kORgyfuJK/8XKp2Eaa8kNE7KOpaOUAiBS5dM5dIlUw/q/b9YthGozbYjjfx21RYLOkkaRE4+fTo/+d7DdHaWAXjlq9x3VOp3hanQvZRnPl+gODnrRJIkSdqPBd0AU7zsY1RuOYq4czO5xWeTm/7CT6qGYqkfk/WxQpH9n+wL+cFfOr6Q6mN30vPdz0ClTHLUYorv+CtCoS7rWNKAEhomEI59d9YxlKGJzSXW7ewgjbWSblJLfdaRJEmHYNyEZv72ixdx313rGDW6gRNPcwl7qd81nABJQ20mXXEKoTgz60SSJEnajwXdABOKJQrnvCXrGP0uf8prqT50M3HDKsjnKVx8RdaR+kzP//wTVGpPEqerH6J63/XkT70w21CSNMD83UWL+cvrHmZTaxcXLZrM+fMnZB1JknSIxo5vOuSlMSX1nhASqHfPOUmSpIHKgk4DQig1UnfFF4k7NhEaRxJKDVlH6jvl7n2vQyDuP5YkATBnbBPfvvz0rGNIkiRJkiRJfSLJOoD0jJDkSMZMHtrlHJB/5e/tGzSNIr/kFZllkSRJ0uDVXu7mmifv4T+X/5bHdqzPOo4kSZIk6RA4g07qZ4WXv4ncrCXEXVtJZh1LqG/OOpIkSZIGoW8u/w1Ptm4lEnl4+zo+eMwFTG8am3UsSZIkSdJBOKwZdNdccw2vfe1rOfbYY7nwwgv52c9+1tu5pCEtmTqP3KIzLOckSZJ0WNIYWd26hUgEIAKrd2/JNpSkASHGKrFrGbHjAWJ1V9ZxJEmS9AIOuaD78Y9/zKc+9Sne+ta3cu2113LRRRfx0Y9+lPvvv78v8kl7xV1bqa58gNjRmnUUSZIkKVNJCExuGEVC2HtsatPoDBNJGjDafgsdd0HXw7DrWmLVn6ElSZIGokNa4jLGyBe/+EUuv/xy3vrWtwLw/ve/n3vuuYe77rqL448/vk9CStXl99DzX38N1QqUmqj7P58jGT8961iSJElSZt45/2x+uvY+dvV0ctr4OcxumZB1JEkZizGF8tpnRkAFyushtyDLWJIkSXoeh1TQrV69mvXr13PxxRcfcPxrX/tar4aSnq18w39BtVob9HRQue3HFN/woWxDSRp0YrUHNt4NaQ9MOIlQdJlZSdLgNbKugbfNfVnWMSQNKAFCPcTOfYeSpuziSJIk6QUd0hKXq1evBqCjo4N3vetdnH766bzpTW/ixhtv7JNw0l5Jnr2r90QgyWWZRlIfi7vXEDfeQ+za2XvXjJH40L8RV/yAuPInxHs/T6x0vvSJkiRJ0iARQoDmV0LSAqEIpcVQmJJ1LEmSJD2PQyro2traAPjEJz7BRRddxNe//nXOPPNMrrjiCm6//fY+CSgBFF79TijU1QbNo8mfdWm2gST1mbj+VuJ9XyAu+y/i3VcS2zf2zoW7d8Culc/cBbp3ws4neufakiRJ0gAR8mMJI99AGPW7hIbjaqWdJEmSBpxDWuKyUCgA8K53vYtLLrkEgIULF7J06VK+8Y1vcPrpp/d+QgnIzVhE6RP/Sdy5mTBmCqFQzDqSpD4S192wb1AtEzfcSZjz+iO/cL4BQh5iZd+xupFHfl1JkiRJkiRJOkSHNINuwoTapuPz5s074PicOXN46qmnei+V9DxCqZFk4lGWc9JQl6tn/zVtQ77UK5cN+RLh6Muh0AhJkTDrdYTmab1ybUmSJEmSJEk6FIc0g27RokU0Njby4IMPctJJJ+09vnz5cqZPn97r4SRJw0+Y/ybiQ1+BSge0zICpZ/fetcctJoxb3GvXkyRJkiRJkqTDcUgFXalU4t3vfjdXXXUVEyZMYPHixVx77bXceuutXH311X0UUZI0lMSYwralUO2BMYsI+boDvh5aZsIZfwOVTig0umeGJEmSJEmSpCHnkAo6gCuuuIL6+nq+8IUvsGnTJmbPns2XvvQlTj311L7IJ0kaQmKMxEevhq0P1Q40TIQTP0rIHbh0bUhyUGzq/4ADSBq7SONOktBCEhqyjiNJkiRJkiSpFx1yQQfwzne+k3e+8529nUWSNNR179pXzgF0bISdK2DMouwyDUDVdCftlRuBCpDQkD+LfDIh61iSJEmSJEmSeslhFXSSJB2WXBFIgHTfsbyzw56tJ30cqO4ZpXRXHx2UBV1PdQXd1WUEipTyJ5FPxmQdSZIkSZIkSRoQkqwDSJKGj1BoIMx7E4Q9336mnA0tMzPNNDA9+9vz4Pt2XUm30lW9n0gnKbvorPy2tv+gJEmSJEmSJGfQSZL6V5h8Okw4CWJKyNdlHWdAqsstpJJuINIFFCjlFmcd6ZClse2AcaSH2pKdxed9vyRJkiRJkjScWNBJkvpdyBWyjjCgJaGJpsKFpLGNJDQQwuD7+5VPxkM1T22pzkgujAUG31+HJEmSJEmS1Bcs6Aa4mKZUH/w1cdsGckefTjJ5dtaRDkuMkcpvf0j17p8TWsZQuOQPScZOyTqWJA1YIeTIhRFZxzhsSWigsXAe5epqQihSTOYQQsg6liRJkiRJkjQgDL5NbYaZ8s/+nfIPP0/lpu/S/a9/RLp+RdaRDku67C4qv/gGcfsG0jVL6fnW32QdSZLUx3KhhVJ+CXW5hYNyFqAkSZIkSZLUVyzoBrjq/TfUXsQUYqT66G3ZBjpM6Za18MzMiZgSt67PNpAkSZIkSZIkSVJGLOgGuDBqPIQ9v00xJYyakG2gw5Sbc0LtryMkEALJ/FOyjiRJg9KWu5dxx4e+xAN/+1+U2zuzjiNJkiRJkiTpMLgH3QBX/J0/oed7f0/cvpHc4rPJnXh+1pEOSzJ5NsV3/z3VB39NaBlL/sw3ZB1JkgadnY+t4bqz/pCYRmKasvm2R7jgus9mHatXxRi5ccVm1u/s5GWzxjJrbFPWkSRJ/SjGKnQ9BmkHFGcSCuOzjiRJkiRJfcKCboBLxk2j9MH/l3WMXpGbcTS5GUdnHUOSekXc8iDxif8BIMx+HWH8CX1+z6evv4+0p7J3vP7nd5NWqiT5XJ/fu798+daVfPPuJ0kCfPX2lXz9Lacwd1xz1rHUC2K1B3auhGIToXla1nEkDVTtt0LPk0CA7seJLa8l5MdknUqSJEmSep0FnSQdoRgjbH8MenbDmEWEomXCUBe7dxGXfrO2PygQl/4ntMwilEb26X1HLNhXaoRcQtOMCUOqnAO45uHaHqVphEDk+sc3WdANAbHSSbz3C9C5uTae8SqSo16TcSpJA1LPuj0vIhCgvB4s6CRJkiQNQe5BJ0lHKD7xP8SHv0J8/LvEu/+e2L0760jqa9279pZzNRG6d/T5baecfxInf+59NM+axLhTF3Luj/+2z+/Z38Y315GE2utqhHHNddkGUu/Y8uDecg6ANb8iptXs8kgauHItwJ5vBETIjcgyjSRJkiT1GQs6HbHYup3qinuJu7ZmHUXqdzGmsP6WfQfKbbD1oewCqX80ToL6sdQ+QAxQGg1NU/rl1sd89E1c9sR/ceEt/8yoRTP75Z796f979TFMGdFAIQm8euFE3nBM//x9VR9LCs8aJxDC879X0vDWdDbkx0HSCPXHQWF61okkSZIkqU+4xKWOSLp+Bd3//gno6YJcgeLv/w25WYuzjiX1owD5Oqh07jtUaMgujvpFyBXg+D+Cp28FIkw+k5ArZh1rSJg9tokfvPOMrGOot41bAhvvgh2PAwlh3u8Qgs+JSXqukGuBlldnHUOSJEmS+pwFnY5I5ZYfQbmnNkgrVG76rgWdhpUQAiy8nLj0aqh2w/gTYdxxWcdSPwjFJpj5qqxjSINCSPKw+H3QtR3yJUKhMetIkiRJkiRJmbKg05HJ7f+PUIBc4QXfKg1VYcxCeNmVkFacRSXpiHRVqjy5rZ0JzSVGNQyt/56EEKB+TNYxJEmSJEmSBgQLOh2R/Ct+l+qK+6BtB5QaKJx/edaRpEyEkMAQKedijFDtgVyx9oG6pH6xta2b93zvbjbs7qKQBP7+dUs446ixWceSJEmSJElSH7Cg0xFJxk6h9PGvE7dvJIyaQCiWso4k6QjEnlbiQ1+GtvVQGg2L309oGJd1LGlY+MED69jU2gVAJY38829WWNANMw8/vZO/+vmj7Owq8+bjpvHu02f5oIQkSZIkKRPFJHDC2PqsY/SZYpL9z9tJ1gE0+IVCHcmEGZZz0hAQ1/wS2jbUBl07iCuvyTSPNJykMe59Hdkzm1XDRoyRP/nJg6zf3Ulbd4Wv3bmaO9dszzqWJEmSJEnqIxZ0kqR9yu3UqgFq/1tuzzKNNKxcdtw0Ru/Zdy6XBK542ZyME6k/lauRHZ1l9u9lN+zuzC6QJEmSJEnqUy5xKUnaK0w+g7jlAZ75hDhMefkhXyNufoC45X4ojSXMvICQq+vllNLQNKG5xPd+/wxWbG5l8oh6xjc7M304KeYTzp49jptXbiEJUMrnOH2mS5xKkiRJkjRUWdBJkvYKI+fASX8Cu1ZD0xRCy/RDOj9uf4y49GqgtoZz7NpGWPT7vZ5TGqoai3mOmzoq6xjKyN9eeCw/eeRpdnb2cMGCiUxssaSVJEmSJGmosqCTJB0gNE6ExomHdW7c8QS11ZPT2oEdj/daLkka6gq5hEuXTM06hiRJkiRJ6gcWdJI0jMW0CtsegWoPjD2WkD+y2RqheRrxmXKOBJoPbQaeJEmSJEmSJA0HFnTqM+nmtcRdW0imLSSUGrKOI+lZYozER79RK+gA6sfDSR87sj3jxi0hzLmEuOk+aBhHmP2GXskqSZIkSZIkSUOJBZ36ROXOayn/5KraoGUspSv+idA8OttQkg7UvWtfOQfQuRl2PAFjFx32JUMIMPVswtSzeyGgJEmSJEmSJA1NSdYBNDSVr/+PfYPWbVTuuz67MJKeX67Ic74NFJztqqFr9bY2frtyCzs7e7KOIkmSJEmSpGHOGXTDQLplHeUbvgWVMvmzLiU34+i+v2musO91hJAvvPB7JWUiFBpg/puJy78PsQrTzoGWmVnH0jC2u6vMNQ+tp5ymXHzMZMY3HdmeiPu7bunT/M0vlhKBllKBb/zeyUwZaSEtSZIkSZKkbFjQDXGx3EP3v38C2ncDkZ4V91L66L8TRozt0/sWX/cBer57JVQrhMmzyZ30qj69n6TDEyadChNOglgl5IpZx9EwVklT3v/9e1i1vZ0A/M9DT/Hdd5xBU13v/FHl329fRdzzuq27wv88vJ4PnjW3V64tSZIkSZIkHSoLuiEu7twMbTv3Haj0kG5cTa6PC7rc0adT+uS3ie07CaMnEZJcn95P0uGr/fvpv6PK1rodnazc1g5ABLa29/Doxl2cOmNMr1y/Lp8j7Lk2ROryrvItSZIkSZKk7Pjp1BAXRo6DxpEQEggB8gWSiUf1z73rm0jGTrWckyS9pDGNRQq5QNgzDsCklt5b4vLj58ynVKh9PzpqdCO/c/z0Xru2JEmSJEmSdKicQTfEhUIdde/+LOXr/wuqZfJnXdbny1tKknSoWkoFPnvREj7362WUqynvO3MO00c19tr1T5w2muv+z8vZ3t7NxJZ6ckl46ZMkSZIkSZKkPmJBNwwk46dT95Y/yzqGJEkv6sxZYzlz1sv67Pr1hRxTRjb02fUlSZIkSZKkg+USl5IkSZIkSZIkSVI/sqCTJEmSJEmSJEmS+pEFnYjVCunTK4mt27OOIkmSBqA0tlGNu4kxZh1FkiRJkiRpSHAPumEudrXT/ZU/Jm56EkJC4U0fI7/klVnHkiQNcw+u38k967Yzb1wzZ80el3WcYa2zcj/ldAUA+TCD+vwphBAyTvVcrV1lntjaxrSRDYxtqss6jiRJkiRJ0ouyoBvmqvf+irhpTW0QU8o//TcLOmkYizGFzm1QbCbkS1nH0TB12+qtfOyaBwgB0ggfecU83nz89KxjDUtpbNtbzgFU4hrSOJdcGJ1hqudau6Od93z3HnZ1lSnkAp9//XGcMmNM1rEkSZIkSZJekEtcDnMxphAOOJBZFknZiuUO4j2fI971d8Tb/py47bGsI2mY+uWyjXvLOYCfPvp0toGGschz/1zwfMey9p1719LWXQagUo185baVGSeSJEmSJEl6cRZ0w1z+hPMIoybtHRde9c4M00jK1NO3QfuG2uu0QlzxA2JPK3HXamKlK9tsGlYmtOybvZkEmNxSn2Ga4S2hiXyYsXecD5MH3Ow5YM+Sm3ueOAqQJANvCU5JkiRJkqT9ucTlMBcaWqj78FWk61cQWsaQjJ700idJGpJiWj7wQKWLeMdfQVqBQhOc8EeE+rHZhNOw8o6TZ7Jyaxt3r93OnLFNfOyV87OONGyFEKjPn0Ia5xKJ5MLoAbn/3FtPnM7NT2xmW0cPdbmEK86ck3UkSZIkSZKkF2VBJ0KhjtzMY7KOISljYdLpxKdvg3Jr7UCuBJXO2utyB3HdTYR5l2WWT8NHQzHP515/XNYxtEcIYUDOmtvflJEN/PAPzmTN9nYmjahnRKmQdSRJkiRJkqQXZUEnSQIglEbCKZ+E3U9CaTRx2Xege0fWsSTpoNQXciyY0JJ1DEmSJEmSpIPiHnSSpL1CoYEw5mhC40TCrAshydW+UGggTHtFptkkSepNlXQj3dVHqaSbso4iSZIkSRqGnEEnSXpeYdQ8OO3T0LkNGicS8qWsI0mS1Ct6qk/SVb1r77g+dxqF3PQME0mSJEmShhsLOknSCwrFZig2Zx1DkqReVU6fPGDckz5pQSdJkiRJ6lcWdJIkHaSndnbwo4eeophLePPx0xnVUMw6kiTpMCShkWoMQAQCSWjMOpIkSZIkaZixoJMk6SDs6uzhD75zN23dZQB+/cRmvvX208gnbucqSc8WYzeQI4SB+eNGXe5Y0thGNW4jF8ZSyh2TdSRJkiRJ0jAzMH9iliRpgHl04252d5X3jtds7+DpXV1MH9WQYSpJGlhijHRW7qIS1wAJpdxJFHMzs471HEko0Vh4ZdYxJEmSJEnDmI/9S5J0EKaOrCfseR2A+kKOsY0ucSlJ+6vEDXvKOYCUruo9xFjNNJMkSZIkSQORBZ0kSQdh+qhG/uo1xzB1ZD2zxjbxudcvoaHoRHRJOkCsPOtAuueXJEmSJEnan58sDiHp9o1U77+BUGokd/KrCcVS1pEkaUi5YMFELlgwMesYkjRg5ZNJhGoTkTYACsksQihknEqSJEmSpIHHgm6IiK3b6b7qw9DdATFSXXYHxT+4khDCS58sSZIk9YIQCjQVzqeSbiSEArkwIetIkiRJkiQNSBZ0Q0R11YPQ1bZ3nK56CDpboaElw1SSJEkabkIoUMhNyzqGJEmSJEkDmgXdEBFG7v90coBSA9Q1ZJZHkqThrLv6GN3VZQSK1OdPJp+MzzqSjkD7+i1sf2AloxbPommav5eSJEmSJOnIWdANEbkZR5N/9buo/OYHhFIDhTd+hJDzt1eSpP5WSbfQXX0YgEiZjsqtNBdeTwhJxsl0ODbf/ig/P+/jVDt7SOoKvOrnf8/Es5dkHWvQiTHSky6lp/oEgTrq86eQS0ZnHUuSJEmSpMzY4AwhhbMupXDWpVnHkCRpWEtjx7OOlPf8qssgjY7UI5//AWl3GYC0XOHhf/iuBd1hqMaNdFcfBSDSTUflFpoKF7tfsiRJkiRp2PJRbkmSpF5UW86yCNSKh1x4ZqzBKFdfhD0lUgiBpOTv5eFIY9sB40gXELMJI0mSJEnSAGBBJ0mS+s2uzh42t3VlHaNPJaGepsL51OWOppQ7nob8y4bkLKH1Ozv41eMbWb2tPesofeq4v3g7pXEjAagb3cIJf/3ObAMNUvlkEpDjmeI6Hya77KskSZIkaVhziUtJktQvvn3vGr70mxVE4LULJ/IXr1o0JIsrgCQ0UpdblHWMPvPg+p188L/vpVyNJAH+4XVLeNmscVnH6hMj5k3jslXfon3NJhqnjydf71KlhyMJTTQWzqdcXUMIdRST2VlHkiRJkiQpUz62KkmS+tyurvLecg7gusc2ct9TOzLNpMP3gwfWUU1rv5sx1srXoSxfKjJi/jTLuSOUCy2U8sdSl5tHCLms40iSJEmSlCkLOkmS1OfKlfQ5u011V9JMsujINRT3lSshQGPRRRkkSZIkSZIOhQWdDkp12Z10/dvH6P7Gp0g3rMo6jiRpkBnbVMfFiybvHR89oYWTpo3OMJGOxLtOm8XkEfUAjG4o8oGz5macSJIkSZIkaXDxcWe9pHTrenq+9TeQpsSQ0P31P6P0if8k5AtZR5MkDSJ/dv5CLjx6Ep2VKidOHU0x73NCg9WE5hLfe8cZ7OjoYWRDgXzi7+X+OjZuZ+2Pb6U0biQz3nAmwb8/kiRJkiTpWSzo9JLipjWQ7lmGLKbQsZvYup0wakK2wSRJg0oIgeOmjso6hnpJLgmMbXJPtmfr2LidHy95D11bdgIw7z0Xcua/fTTbUJIkSZIkacDxcV69pGTqPCjUQUggJIRREwktY/d+Pd25mXTDKmJazTClJElS9tb++Na95RzA8q9dR1quZBdIkiRJkiQNSM6g00sKI8ZS955/oHLbj6FYovCK3yXkcgBUbv8J5Z9+GYBkxiKK7/w7QqGYZVxJkqTMlMaN3DcIgWJLIyGfyyyPJEmSJEkamJxBp4OSTJlL8U0fp/j6DxJG1GbPxWqF8nVf3fuedM2jVJfellVESZKkzM14w5nMe8+FkASKIxp5xXf+nBBC1rEkSZIkSdIA4ww6Hb4Ya7+efUySJGmYCknCmf/2UU7/fx8m5HOWc5IkSZIk6Xk5g06HLeQL5M+/fN94yhxyR5/e5/dNd2yi57//kZ7vfIbqmkf7/H7SoYo9baQrf0K6/PvEtvXZ5WhdR9x0L7FrZ2YZJGm4Sgp5yzlJkiRJkvSCnEGnI1I4+3fIHX06sWM3yZR5hHyhT+8Xq1W6//0TsGsrANXH7qTuI18hGTWhT+8rHawYU+KDV0H7RiAQN94Dp3ySUBrVvzk23EF8/Lu1Qa4OTvgjQuOkfs0gSZIkSZIkSUPRpk2bePnLX/6c41deeSVvfOMbD+oaFnQ6Ysm4af12r9i6DXZu3negmhLXrwALOg0UPa3QvmHPIELaA7tXQ38XdGuv3zeololP306Ye3DfGAaL2L2TuPLH0L2bMPkMwoQTs47U62KsUk7XAVUKyTRCKGYdacCrxt10lm8jpZV8mEx9/jRCyGUdS5IkSZIkSUPIsmXLqKur4/rrrz9gBZ3m5uaDvoYFnQaV0DQKmkZB+67afndJQpg0K+tY0j6FRsg3QqUD2LMnY8PE/s+RqwfCngwR8qX+z9DH4sNfhbYNQErctRLqRhJGzs46Vq+JMdJR+S3VWHsoobu6jKbCBYTQtzOVB6JNrV1U08jkEfUv+d6uyt2ktAKRSlxPT7qCutyCvg8pSZIkSZKkYWP58uXMnDmT8ePHH/Y1LOj0gtLNa+n54T8Sd20hf/KryZ/7tsz3Ugn5AnXvupLyL6+G7k7yL7+MZMzkTDNJ+wtJHpa8j7jiR1DtIkw/j9DU//+MhnlvIj705VpR2DSVMPUV/Z6hL8WYwrP392tdB0OpoKN9bzn3zLgSt1IIw2up0n+5ZQX/cfcaAC5aNJlPnb/wRb8XpbGTveU4gRg7+z6kJEmSJEmShpXHH3+c2bOP7LNICzq9oJ5vf4a49SmIKZVff4dk4lHkjnlZ1rFIxk+n7m1/2WvXi+Ueqvf8nNi+m9xxryAZO7XXrq3hKTRPI5zwh9lmaJkOZ/xNraArNGVerve2EBJiy1Gw+8l9B0cclVmevhAosm8WZE3C0JsJ+WI27u7aW84B/PTRp7lk8RQWTRzxnPc+vauTxzbtZsbo6YxvWbb3eD6Z3i9ZJUmSJEmSNLhs2LCBc8899wW/fsMNN7zg15YvX86oUaN461vfyurVq5kxYwbvf//7n3dfuhdiQacXFLdvgJjWBiGQblvPUNzFp+c7nyF9/C4ICZVb/4e6D/8LiXvaaQgISQ6KB655HDu2EDfeScjXw+SXEfJ1mWRLYzeVdCNJqCMXJhxWgRiOeRfxyZ9Dzy7CxNMILTP6IGl2QihSnzuFzuq9QJW63CJySf/uZZi1cpo+51ilGp9z7OGnd/KBH95HTzUlFwJXXryEU2dG8mEiuWRkPySVJEmSJEnScFGpVFi1ahVz5szhT//0T2lqauLaa6/lve99L9/4xjc4/fTTD+o6FnR6QckxZ5I+eDMkAUJCbv4pWUfqdbHcXSvnoFZG9nSSrriP5JTXZBtM6gOxexfx3s9DtYdIhG2PwnEf6vfZdWnsor38KyK1pQcLyRzq8ycc8nVCsYkw77LejjegFHIz9s4AG2qzIA/G1BH1vGbhRH722EYATpsxmmMmPXf23PcfWEdlT5mXxsh37mvl5bNP6teskiRJkiRJGlwmTZr0orPkXkg+n+fOO+8kl8tRKtVWvDrmmGNYsWIFX/va1yzodOSKb/wI1anzibu2klv8cpKJQ2v5OADyRWgcAR27IdZmZYTRzp7TELVjBVS79o13rdqzBGZjv8aopOv3lnMA5fQJSvE4Qkj6NcdgMRyLuWeEEPjLVy3ijYunUk0jx04eSS557t+PUiG33znQWPCPN5IkSZIkSeo7jY3P/Ux17ty53HLLLQd9DT8N1QsK+QL5M15P4TXvIpkyN+s4fSKEQN3bPk0YMxnqm8mf93Zycw59Jo80KNSP3W8QIF8Puf7f0yyE4rOO5Gt5pOcRQuDYySM5buqo5y3nAN516iwmtdQDMKq+yAfOmtOfEV9SjJEYn7s0pyRJkiRJkgafFStWcMIJJ3DnnXcecPyRRx5hzpyD/1zKR8w1oFXuu57Kzd+DYonixR8gmb6g1++RTF9A6SNf7fXrSgNNGDET5lxCXHsD5OsJ899c26euD8SYUk5XkcZOCsm0A/YBy4cp5MN0KnEtkKM+f+qwniWmIzexpcT3fv90trf3MLqhSD43MJ4/ijHSVb2PcrqKQJH6/GnkE2dpS5IkSZIkDWazZ89m1qxZ/PVf/zV/9Vd/xahRo/j+97/PAw88wH//938f9HUs6HRY4q6tpE+vJEycSTKqbz5sTDeupvzf/1gbhED3N/+S0ie/RcgX+uR+0nAQpp5NmHp2n9+ns3LXngIu0JM+TmPhfHKhtndYCAkNhdOI8UQg59KW6hX5JGF8c//PCH0xlbiecroSgEg3HZXbaS683kJakiRJkiRpEEuShC9/+ct8/vOf54/+6I/YvXs3Rx99NN/4xjeYN2/eQV/Hgk6HLF23jO6vfRLK3ZDLU3zHX5ObfVyv3ydueWq/QYSuNmjfBSPGvvBJkgaESly351UEIpV0A7nciAPeE4Jlu4a2GLuedaSH2r8TFnSSJEmSJEmD2dixY7nyyiuP6BpOW9Ahq9z6P1Ap1wZplcrN3++T+yQzjoa6BkgSCAlh4ixoHt0n95LUuwKN7F9CJOG5m6ZKfWnN9nYe27ibaprd3m/5ZDKwb8/FQpjpjFFJkiRJkiQBzqDT4cgX9xsEKBRf8K1HIrSMoe59/0jl7p8TiiXyZ15CSPxgUxoMGvJn0Fm9kxg7KSSzyIepWUfSMPLV21bytTtXA3DitFH80yXHU8hgX7okNNBUuIBy+hQJJfKJ/x5IkiRJkiSpxoJOhyz/yrdQXfkA7N4GDc0ULvj9PrtXMn46xQvf22fXl9Q3cslImpJXZR1Dw1BrV5mv7ynnAO5dt4M7ntzGWbPHZZInCQ3U5Q5+7XFJkiRJkiQNDxZ0OmTJmEmUPvZ14s7NhBHjCH00g06S1P+e2NrGF296nLaeCm8/aSbnzJuQdaRDEoL7u0mSJEmSJGngc71AHZaQL5CMnWI5J0lDSKWa8uH/vo97n9rBY5ta+dS1D7Nya1vWsQ5JU12ed58+a+/45OmjOX3mmAwTSZIkSZIkSc/lDDpJkgTAzs4y2zt69o4jsGpbG7PHNmUX6jC867RZXLBgIh09FeaOayZxVp0kSZIkSZIGGAs6SZIEwOjGIjNHN7J2RzsAhVzCookjDvk6W9u6+enSpykkCa8/dgpNdf3/x41pIxv6/Z6SJEmSJEnSwbKgkyRJACQhcNVlJ/DNu56kvafCZUumMXlE/SFdo727wju/cxfb2ruJEX6+bANXv+VUcomz2CRJkiRJkqRnWNBJkl5QubqWnnQlgRKl/BKS4KykoW5MYx0ffeX8wz7/kY272NLWvXe8YksbT+3sYMboxt6IN2SV06foqjwAQCl/HIVkaraBJEmSJEmS1KeSrANIkgamSrqVzuodVOMWKvEpOsq/PaLrxY5NxLU3Ejc/QIyxl1JqoJnQXGL/uXKFJDCqoZhZnsEgjR10Vm4n0kGk9jqNnVnHkiRJkiRJUh9yBp0k6Xmlccd+o0jKLmJMCeHQn+2I7RuJ934e0goQYdorCbNf32tZNXDMHN3IJ85byL/d+gSFXMLHz1lAS6mQdawBrVbG7V9aR2LsgHBoy4tKkiRJkiRp8LCgG6ZiuZvqXdcR23eRO+4ckvHTs44kaYDJhbH7jQJJGHVY5RwAWx7YV84BPH07WNANWW84dgpvOHZK1jEGjVwYQaCRSAcAgQaSMCLjVJIkSZIkSepLFnTDVM+3P0O6/B4IgcptP6buw/9CMnpS1rEkDSC5ZBT1+bMoV1cRQom63KLDv1hxBPtmCAWos3zQ8LGtvZtv3LWaju4qb1wylWMmHfjPfwh5GgvnUk5XAlBIZhOCf0STJEmSJEkayvz0ZxiK5R7S5XfvGUQod5M+cT/JKRZ0kg5USCZRSHrhvw0TT4Fdq2DzvVA3irDw7Ud+TWkQSGPkgz+8jzU72gH41fKNfPfy05kysuGA9yVHWoJLkiRJkiRpULGgG47yBWgaBe07awUdEJw9J6kPhSRHWPhWWPjWrKNI/WpnZ5nV29v3jtNq5JGNu59T0EmSJEmSJGl4saAbhkII1L390/T86AvEtl3kz3w9uTnHZx1LA1i6cwuV6/+D2NFK/vSLyc09MetIGmRipQu2L4NCA4ycSwgh60hSv2gp5RnbWGR7Rw9phADMHtuUdax+E2MPHZU7qMZt5MIYGvKnEUIx61iSJEmSJEmZs6AbppKp8yh9+F+zjqFBIMZIzzf+jLhtA8RIz/J7qPvQVSQTZmQdTYNELHcQ7/08dG2rHZhyFmHupdmG0rC2q7OHaoTRDX1fFOWThH9+4wl88TfLae2u8LYTZzBnGBV0XdWHqMZNQKQaN9FVfYT6/AlZx5IkSZIkScqcBZ2kF9fVRty6ft84RtKnHreg08Hb9si+cg5g/W+Jsy4m5JxFo/739TtX8dXbVhGBNx8/jT86e16fz+icNbaJL75xeJZSaWwD4p5R3DOWJKlvxJhC12OQ7oLCdEJxataRJEmSpBeUZB1A0gBX10gYMxlCAgQICcnUeVmn0mCSKx04TvIQctlk0bC2qbWLr+wp5wC+d/86lm9pzTTTUFdInnmYI+wZT88ujCRp6Ou4Gzrvhe6V0HYjsWf9S58jSZIkZcQZdJJeVEgSiu/8O8q/+iZ0tJE//WKSCTOzjqXBZOwxMO542HI/hBxh/u8Rkpcu6GLbBti1EpqmEkbM7PucGvK6ytXnHOsspxkkGT6KuaMIoY5quo1cMpZCMinrSJKkoay8bs+LCAQor4filCwTSZIkSS/Igk56lphWD6o8GE6SUROo+50/yTqGBqkQEsKidxB7LoVc8aCWtow7VhAf+leIe8qThW8jTDipj5NqqJs+qoGXzx7Hb1ZuAeC4KSM5ZlJLxqmGvkIymUIyOesYkqThIDcK0k5qBV2E3MiMA0mSJEkvzIJO2iN2d9Dzrb8lXfkAYcwUipd/mmRs/+9ZEGMkrnucWC2TzDjaslBDRig2HfR744Y7IMZ946d+Y0GnIxZC4MqLFnPPuu1U08jJ00eTT1ztW5KkIaPxDGi/A6o7oTgD6uZmnUiSJEl6QRZ00h6V3/yQdNVDAMTtGyj/5F+o+4PP9GuGGCM9P/w86QM3ApDMOYHiO/7Kkk7DT6Fxv0GAYnNmUTS05JLAqTPGZB1DkiT1gZDUQ/Mrs44hSZIkHRQfG5f2iG079xukxN3b+j/D9o17yzmA9In7SNcu6/ccUtbCjAugeVptUD+WMOeSbANpWHtkwy7+/vrH+LfbVtLeXck6jiRJkiRJkoYAZ9BJe+ROOJfqfb+qbVcA5E+7mJimhP5c/iz33JlyITd0/zWNWx4irvpfCIEw+w2EMUdnHUkDRCg2EU78KLHaA0mBEELWkTRMrd7Wxvu+f09t+WHgofU7uepNJ2YdS5IkSZIkSYOcM+j0otIdmyhf91XKP/96JjPK+lNuxiLqPvDPFC58L4W3fIrKQzfR9RcX0XXVh/vtrz0ZOZ782W/el+nE8wlT5/XLvftb7NpJXHo1dG6Bjs3ER75G7GnLOpYGmJArWs4pU/eu20EljVQjpBHufWoH5WqadSxJkiRJkiQNckN3ao6OWOzqoPvLH4H23QBUHv4NpT/6CqFQzDhZ30kmHkUy8Sh6fnIVcc/SknHDKnp+9jXq3vwn/ZKhcME7yJ3yWkirJKMn9ss9M9G1HeJ+H3LHKnTvgGJTdpkk6VmOGrNvP8QkwKSWego5n2+SJEmSJEnSkfETJr2gdMNKaNtZK1FiCjs3E7esyzpWv4it2yHuWesyptDav7MHk5HjhnY5B9A0BYot1P4zFKA0GhomZJ1Kkg5w4rTR/PE5C5g5uoHjp4zi8284LutIkiRpgKmmO+iprqCaDu1VZyRJktS7nEGn54hplXTdMuhqgyQHaRUIkM8TRo7POl6/yJ9wAT1Lb987zp386gzTDE0hXwcnfIS4/pbaHnRTziLkhu7sTEmD16VLpnLpkqlZx5AkSQNQOd1AZ+W3e8f1+TMoJP65QZIkSS/Ngk4HiGmVnv/8a9LldwMQjjoW2ndBkqPwmncTGpozTtg/cgtPpe59/0h1zVKSqfPIzTwm60hDUiiNIsy+OOsYkiRJknRYytWVB4x7qk9Y0EmSJOmgWNDpAOlTy/eWcwBx9cPUfeSrJGOnZJgqG8m0BSTTFmQdQ5IkDTErv3U9d//xlwE45fNXMOv3zsk4kSTpcIVQghiACAQCpawjSZIkaZBwDzodICS55x58vmOSJEk6ZG3rNvPbd/w9nRt30LlxB7+5/Era12/JOpYk6TDV5RaRhBEAJDRTyi/OOJEkSZIGCws6HSBMmUvuxPP3HSjW0/3vf0LlwV9nF0qSJGmI6Fi/lZime8exmtLx9LYME0mSjkQS6mkqXEBz4VKaiq8mCQ1ZR5IkSdIgYUGnA4QQKFzyRxTf9wUICfR0wq6tlH/wOdIdm7KOp0Ei3bGJdMtTxBizjiJJ0oAy+rg5tMydAkmAJNAyfxqjF8/KOpYkDSqxspO4+5fEXf9L7F6VdRwAQnDlGUmSJB0a96DTc4QQCLk8xH1PdxMjcdcWGDUhu2AaFMq/+g8qN30XgGTx2RTf9MeExGcBJEkCyJeKXHjbl1jxtZ8BMO/dryVXV8w4lSQNHjFGaL0eYicQof0WYm4EIT8m62iSJEnSIbGg0/MK46cTxk4hbttQO9AyhmTynGxDacCLu7ftLecA0oduJj31QnIzj8kwlSRJA0tpzAiO/ZPfzTqGJA1OsQdix4HHqjvBgk6SJEmDjAWdnlfIF6h77+eo3HUdxEj+5FcTiqXnvC/2dFG58VukG1aTW3AKudMuJoSQQWINBPvvqbNXWu3/IJIkSZKGplCE3Gio7njmAOTHZxpJkiRJOhwWdHpBoXEEhVf+3ou+p3ztv1G995cQI+kT90GxRP7EC/opYd+oPvko6dqlJNMWkDvq2KzjDCrJyHHkTnkt1buuq43nHE8yw9lzkiRJknpHCIHYfB50PQJpD5TmEXLNWceSJEmSDpkFnY5IuvphiLE2SBLSNUvhCAq6GCPVB28iXfMoyfSF5I47p19n5FUfuYWe73wGCECk8OZPkF98dr/d//nEGCGt1vYFHAQKr/sA+ZNeRaz0kExbQEjcLF2SJElS7wlJCRpOyjqGJEmSdEQGxyf+GrCSmYuobt8IMYU0JZm+8IiuV73rOso/uQqSXG0WVmcb+TNe30tpX1rlvuv3vKqVjtV7fpFpQZduXE33f/4V7NxMMu9kir/3yeddanQgCSEQpszNOoYkSZJ02GKMlMspxaIPm0mSJEnqGxZ0OiKFi94PpUbixifJzT+F3BEub1lddmftxZ59y6rL7uzXgi60jIGQ1ArHkBBGjO23ez+fnh99EXZtBSBdcQ+VO/6XwsvflGkmSZIkaShbs2o7X/i7G9mxrZNjjpvEh//0bOpKhaxjSZIkSRpiLOh0REKxRPG17+216yXjp5OuuG9fQTZ+eq9d+2AUzr+cdPMa4tplhKnzKLzqnf16/2eLbdtrfy8AQoC2nb1z3RghTQk5nwiWJEmS9vf1q25n544uAB59cAO/uvZxLrrUfZUlSZIk9S4LOh2WmFahpwvqGnp1j7j8uW8jtu8mXf0QYeYiCue/o9eufTBC4whK7/0cMcZ+3fvuheRPfx2Vn3+9Ngg5csedc8TXrK56qLbPXmcruePPo3DJh90nTpIkSdqjdVc3Ma0teR9CoHVXV8aJJEmSJA1FFnQ6ZOn6J+j+5l9C+07CjKOpu/yvCaWGXrl2KJYoXvbRXrnWEeUYAOUcQOGsy0gmziJufYpkzgkk46Ye8TV7vvdZ6GgFItX7fkUy53jyS15xxNeVJEmShoILLl7Ad75xLwC5fMKZr5yVcSJJkiRJQ5EFnQ5Zz4+/BB27AYhrH6Ny2zUUznlLxqmGrtzcE2DuCb1yrRjj3nKupveWzZT6UowRKAOFAVOgS5KkoenVrz+a6UeNYuPTrSxaMpEJk1qyjiRJkiRpCLKg06HraD1gX7TY2ZptHh20EAK5U15D9Y6f1g6UGkkWnZFtKOklpLGDjvLNpLQSaKKxcDZJaMw6liRJGsKOXjyJoxdPyjqGJEmSpCHMgk6HLH/WpZR/clVtkCuQP/GCTPNUH/4t1cfuIIybSv6sywj5QqZ5BrrChe8jN2sJsXU7uYWnE0aMzTqS9KK6q4+Q0gZApJ2uysM0FE7LOFXve3zzbq55eD2NxTxvP2kGI+qLWUfSEJDGlHVtj9BW3s6ouslMapjrLFRJkiRJkqQBwIJOhyx/6oWESbOIW9aRzFpCMmpCr1w39nTR84PPkT5+D4yZSN3bPk0y5sWfWq0uvZ2e714JIQEicedmipf8Ya/kGapCkpBbdGbWMaSDFmM3+5ZljUR6sozTJzbs7uS937uHSjUlAnet2c4333qKRYqO2Krd9/JU+1IAtnStoRo3M7XxFEKwAJYkSVJNLG+CyibIjyUUJmcdR5KkYSM51BM2bdrE/Pnzn/PrRz/6UV/k0wCVm76Q/IkX9Fo5B1C5+fukS2+Dag9sXkv3v3yI2NP1oudUVz4ASa625GaMVFfc22t5JA0MxdxcIDxrPLQ8sH4n3ZWUaoQ0wvItrezqKmcdS0PAju6nnzV+kvbyDcRYzSiRJEmSBpLYsxZafwGdD0Dr9cTuFVlHkiRp2DjkGXTLli2jrq6O66+//oAn+5ubm3s1mIafdNuBHyLS1UH6+N3kjj3rBc9JJh5FNd3zIWNISCbN6cOEkrKQTybSmL+AatxOLowil4zMOlKvmzVm3556SYAR9UWa6g59kvua7e20dldYML6ZfO6Qn8HRENRcGEt7ZefecX0+IaWVatxOPozLLpgkSZIGhu5Vzxo/AXVD76FISZIGokP+9G/58uX/P3v3HSdXVbh//Dn3Ttved9N7JSQkIYQSeq9SFFBRwYYUBSni90eRbgUsCAiioigogiAI0ptAIIGQXkjv2Wzvu1Pu+f0xYZOQtpvM7t3yeb9ekTkztzwRkt2dZ845GjJkiIqLizsiD3oxd/yR8ua9vf2Te9hPzj3wRNm6SiUWvCtTPFihMy7pwIQA/OI6OXKV43eMDjO6OFs3nzROj364SlnhgK45ZowCTvsKtkdmrNTv3l0uSRrXJ1v3nXugIgG3I+KiGxmRM1WSp9roSmWHXBVHkv9NOCbN32AAAADoGpwMJVcsscl/Opk+BwIAdBWOtcqq3/0Kd92ZY+22i3b5ot0F3ZIlSzR8+PCOyIIuyForb80iqaVRztDxMsFwh90rMO4weYedqcR7/5YkOaOnyhl10G7PMY6j4LFfVvDYL3dYLgDoDKfs11en7Lf7fTd3pTme0EPvLW8dL9hUq/8tL9MJo/ukKh66qYAT1Ji8IxRNDFRz4mNJUsSdIMfwxgsAAAAkpR0gJaqTe9C5BVL6FL8TAQDQa+zVDLq8vDxdcMEFWrlypQYPHqxLL71URx55ZEfkg89iLzzUWpiZPkMV/s7dMqFIh90vdNp3ZI86X7alSSa/z3bLqAJdha3fIJXPkyJ5UskUGcNSgvDXzv6mdPj7E9sIuUMUcof4HQMAAABdjHFCUvYJfscAAKBXate7yvF4XCtWrFBNTY2+973v6aGHHtLEiRN18cUXa/r06R2VET6xzQ2t5Zwk2U0r5S2Z2eH3NZm5cgr6Us6hS7L1G2Q/ult21Yuyix+TXfa035EAhQOuvnvE1n0iJvXP1RHD2F8MAAAAAAAA6KraNYMuEAjogw8+kOu6ikSSs6j2339/LV26VH/4wx906KGHdkhI+MRxk7+8xNbngiH/8gBdgC2bI1lPyfX5JW2aIY38vK+ZsO88a/XaJ6UqrWvWkcOLNSgv3e9I7fblAwfrmJHFqm+Ja1hBplyn63zIYXltqeZVrFV+JFPTSkbJbef+ep0pnvAko3bvAdgWKyvq9dhHa+Q6Rl+dMlj9c7vff2cAAAAAAABIjXYvcZmRkbHDcyNHjtQ777yTkkDoOkwoouDplyj23P2StXLGTZMzirXIuzprreLvPq3E/HfkFA9S8JRvyqRl+R2rxzCRfNlPyzmZ5DKX6PZ+9eYSPTF7nYykh6ev0J8vOFiD83f8ercnNtEiNZVLkQKZQMctB7wrfbPTOv2ee7KqrkwPLnxNRkaerDY1Vuu84Yf4HWun/vD+Cv3h/RVyHUc/OHa0Prd//5Rdu6Y5pov/8aEaonFJ0v9WlOmpr09TJOim7B4AAAAAAADoPtr18fClS5dq8uTJ+uCDD7Z7fv78+RoxYkRKg6FrCBx8miLX/13hH/xZoS9dL+PwRmJXl5j9uuL/fVh27WIlZr2q6L9+7XeknqXPQVK/wyQ3JKWXyIy90O9ESIFn52+QlJwXGU14enPZ5nZfwzZskn3/NtkPfyH7/q2y9etTnLJ7WlS1obWck6T5lWt9TrRzn2yu0++nr5BnpVjC009fXaSqxmjKrr+srE51LXF5VvKsVNEQ1drqxpRdHwAAAAAAAN1Lu2bQDR8+XMOGDdNtt92mW2+9VXl5eXriiSc0e/ZsPfXUUx2VET4z6Vky6czA6i689Uu3Lk1qPXlrF/sdqUcxxpEZdZ406jy/o3RZNt4irX9bNtYo02eqTGbf5PNeIrlnX8VCKWuAzOjzZYLtn6XWEQoywtpY29RanhRmhNt9Dbv6ZSm2pXCJN8uu/K/M+G+lOGn3U5yW3VrOOTIqTsvxOdHOVTdtX8Z5VqpriSsvPTVLOw/Ky1DQNYonbHLybcDtkjMeAQAAAAAA0DnaVdA5jqPf/e53uvvuu/X9739ftbW12m+//fSnP/1Jo0aN6qiMANrBHTpBienPJgfGyBk+0dc86B1swybZZc9I8UYp3iI1bZZkZDe8Kx30Q5m0AmndG9KGLcsht1TLGldmXNeYgXj7qfvrhufnaXN9i07dr69OHtu3/Rexid2Pe6lJhUNU1lyrj8pWqjCS1WWXt5zQP1dD8zO0srJBknTQwDwNzE1dgVaUGdY9Z03S76cvl2uMLjt8hDLD7V5pHAAAAOgULS1xTX97pWLRhA49cqgys9r/IUYAALB77X5nqLCwUD/5yU86IguAFHDHHabgF65RYtF0OYUDFDj6i35HQg9nrSc75wEpWiu17s+n5GMvKlUvldIKZBtKlVxZ2Uv+atjoS96d2a9Pjp7+5uH7dA0z6HjZysVSokVyAjKDT0xRuu7NMUYnDzxAJw88wO8ouxUJuHr4SwfpjaWbFXQdHTuyWMYYJbxKtSQWSTIKu+PkOns/A/CgQfk6aFB+6kJ3MGutWhILFPOWy5g0pbkH79PvHwAAAN2D51n94uZXtXRxmSTppWcX6Y5fna5IWtDnZAAA9Cx8dBu9nm1uVGLRdJlQRM6YQ2Tc7r/PXmDScQpMOs7vGOgt4k1StGbXr6cVSZJMwTjZ0pmScSTrSUUTdntZ21Ij+8k/pcbNUvEkmSEnyxiTyuQpZbIGSgffJDVskNL7yISz/Y6EdsoIBXT6uH6tY882qyH+hqSEJKN4fLOygqfJmN7xxkTcrlfUWyhJsrZFjfF3lRU61edUAAAA6GhlpXWt5VxyXK+li8s0flK/3ZwFAADai4IOvZptaVLLA1fKlq+XJDn7HabwBTf6nAroGmxTuVT6kRTMkPoeIuPs4ktGIF3K6Cs1lEqykjHJUi4RlRl4tEzucEmSKZ4omW/IVi2Ryegn9Tt09/df/DepapkkT1r9khTJl/oenNLfY6qZUKYU6p1LPtuGGnmrF8oU9JNTMtjvOCnh2VolyzkpOTs0Ks/WyzV5PqbqPJ6t325s1SBrbZcuygEAALDvMjLDclwjL7F1hZScPPZPBgAg1Sjo0Kt5y2e3lnOS5C18T7a2Uia7+yxBBnQE21wt++FdyeUaZaXKRTLjv73TY40x0gGXya5+WYo3yfSbJpMzdOfHFk2Q2cPMuVb1G5RcDlOSHNmGTaIW6Jq8ig1quf/7UnOy0Fl7wlc0s/9g9UvP05H9xsg1jr8B95JjsiW5+nQGnRSQYzL9DdWJAk5ftSTmK1lOWgXMAMo5AACAXiAzK6yLr5ymP//uA8Xjns758gEaNKR3fEgNAIDOREGH3i09a/ux40qhiD9ZgK6kcpGUaN46rlggm4jKuKGdHm5CWTIjP7/D87Zhk+zGD2SCaVL/I2UC7fjzVTBO2vSBPt23zuSPad/vAZ0mMeO/UkujpGSVk/HuM5pz3FmaXbFaTYmoTh000dd8e8sxEaUHjlZ0mz3oesvylpLkmhxlBI5TzFsrYyIKOcP9jgQAAIBOcuiRQ3XIEUMkiQ9pAQDQQSjo0CY21iI11klZ+TJO95wJsTPO4HFyp52txLtPS25AwbOvlImk+x0L8F9k21mkRgqkSbta4nIXbHOV7KxfSomYrKxUsUiadEWbf7gzo86V0opkm8qSM+/yR7fr/uhEwfA2A6OYG9Cni+Esrt7QbQs6SQo4BQo4h/sdwzeukyfX4dPSAAAAvRHFXOrVRBv1/OrZqos16ZCSETqgoGdsDwAA2DsUdNijxIq5iv71VqmlSab/SIW/8ZMeU2IZYxQ69duyx39VcgMyLn8kAElS3iiZISfLrntLCqTLjLlApr3LFFYv3bJE5ha1K6V4kxRs298fxglIg49nWct2qGmKKhJ0VVbfojnrqzW8MFNjSrI7/L6Bw85UYuF7sqWr5AVD+s/4gyRJRkYDMwo6/P4AAAAA0B38cfGb2thYIyurZbWlygmla0hWkd+xAAA+oY3AHsX+/Vspmlzqzm5YpvgHzyl41Pk+p0otw7KWwHaMMdKQk2WGnLz3F0kr3vaKyWKuPUtcos3iCU83PD9Pby0vU9A1slaKe8k5bLeesr9OGtOnQ+9v0rMU/u69sjXl8tKzNLx0qeLVG9Q/M1+fGzy5Q+8NAAAAAN1Bwnra0Fi93XNr6yso6ACgF6Ogwx7ZaLNkP12szEgtzbs9HgAkyeQMkUZ+QXbNa8lZeKPPa/8sPLTJK5+U6q3lZZKkWMJu99rfPlzd4QWdJBnHlckrkSPplEEH6JRBB3T4PQEAAACgu3CNo4EZ+VrXUCUrKyNRzgFAL0dBhz0KHvPF5Cw6SYqky51yor+BgN2w1squfF7aNEOK5CeXZkznG16/mP6Hy/Tvvft3dYby+hY98M6ynb7mGCk7wpd6AAAAAOgKvjHmaL24dq7qok06uGS4BmayJQAA9Ga8a4c9Ckw9Vc6A0bKVG+UM2V8mM9fvSMCubZ4lrXk1+ThaJ7vgEZmDfuBvJqADPTR9ucobWrZ7Li8tqKqmmPLTQ7rq6NE+JQMAAAAAbCszGNEXhk31OwYAoIugoEObOP2GS/2G+x0D2LOmMklGkk3+airzORC2Zde9LbvmVSmQJjP6fJmcYX5H6rJs9XKpYZOUN0ImvWSXx1U1RreuQixpdHGW/vSlg1QXTSgzFJDrmE5ICwAAAAAAAKA92AwIQM9SME4yRvp0r7Piib7GwVa2dpXssn9J0VqpcbPsvN/Legm/Y3VJdv07srPvlV36T9mZv5CtXbPLY8+eMKD1sZF00dShchxHOZFgry7nPGv167c+0XH3vaEv/WW6lpbV+R0JAAAAAAAAaMUMOgA9iskaKE26QnbzHJlIntRvmt+R8Kmm8m0GVoo3JX+FMn2L1FXZdW9tM/BkN30gkz1op8ceNrRQj1wwVfM21mhcSY7G9snupJRd22uflOrxWclic3Vlg67/zzz98+uH+ZwKAAAAAAAASKKgA9DjmOwhMtlD9nicrV0ju+YVSUZmyEkymf07PFuvljtSciNSIirJStlDpGCG36m6pmDmlkJzy1Ktwd2XmKOLszW6eGsxt6qyQS8u2qjctJDOntBf4YDbsXm7oI01zXKM5Nnkr9K6Zr8jAQAAAMAOmuJRLahap5AT0Lj8AXINC54BQG9BQQegV7LRetnZv5W8WHJcvVQ65GaZQMTnZD2XCedIB16TnA0WiEj9jpAxvXcJxt0xo8+TnfuQ1FIl5QyTGXhMm8/dUNOkrz82Qy3xhKyVZqyp0D1nTerAtF3TEcML9fD7KxT3PHlWOnFMH78jAQAAAMB2WhIx/Wb+SypvTi7JPy6vvy4cdSQ/KwNAL0FBB6B3atwkedGt43iT1FQmZQ30L1MvYNKLZIad7neMLs9k9JUO+ZHkxWXcYLvO/WB1hZpiW/f2e29lhVriiV43i25oQab+9OWpev2TUhVnRXTauL5+RwIAAACA7SyrKW0t5yRpQdV61caalBNK9zEVAKCzUNAB6J3S+0hueMtyi5ICESmtyLc4trFMdsk/pJZKmb6HSINO4BNzvZwxRmpnOSdJ/XPStrmGlJsWUsjtnUukDC/M1PBC9jgEAAAA0DVlBMPbjR0ZhZ32/xwIAOieeuc7dgB6PRPKlDngcqlwf6lwgszE7/m6vKVd8CepZrnUXCm78gWpfK5vWdC9TR1coEumDVdeWlBD8jJ015kHUPYCAAAAQBc0OLNQR/cdKyMpYBydN/wQRQLtK+gaPp6rtdf9SOtuvEPNK1Z1SM7uwnqeWlavVby8wu8oANAmzKAD0GuZ7EEy+3/T7xhJTZsl2S0DIzWW+pkG3dxFU4fqoqlD/Y4BAAAAANgNY4xOGzxJJw2cIGOMXNO+uRSx0jKt+3+3SomEZIyaFi7W8Mf/ICcc3vPJPYyNxbTu/92mxtnJDzwXf/di5Z11ms+pAGD3mEEHAF1Bwf6SjFr/Ws4f62caAAAAAAB6hejadSp/5G+qevo5edHonk/oAAHHbXc5J0ktK1dL8bhkreR58mrrFN9c1gEJO17Dhx+r4h//UvOSpXt1ft27H7SWc5K0+YE/yIvGUhUPADoEM+gAoAswYy6QsgbINlfLlEyWyRrodyQAncSzVgs31co1RmNKsliSFAAAAOgksdLNWnXZNbItUcnz1PDRbA244ya/Y7VZZMRQmXBYNpYsoty8XAVKSnxO1X5V/35Bm+99UDJG5ZIG/OxWZUw+oH0XSSS2H1tPW1cqAoCuiYIOALoA4walQceLt+WB3sWzVj98dq7+tyL5KddTx/bRTSeNo6QDAAAAOkHDzI9lm5q3jt//UF5LS7dZIjJQWKCBd9+pqiefkQmFVPCV8+SE2reHXVdQ88LLyQfWSo6j2lfeaHdBl3nYwQqPGKaWZSskSQVf/aKcUCjVUQEgpSjoAABdhi2bK1s2R0orlBl0nIzLN9Po2RZuqm0t5yTphUWbdOHUoRqcn+FjKgAAAKB3CPbdZraZMXJzsmW6WamTNmak0m78gd8x9kmgqCC5XKeXnPUWKCxo9zWctIgG/ebnal60RG5WpsLDhqQ8JwCkGnvQAXtgPU9e2VrZ+iq/owA9mq1cLLvgj9LmWdLql2WX/MPvSECHCzg7zpRzd/IcAAAAgNTLOHCiCr9+gdzsLIUG9FP/229gNYt2qHr6P1r+5W9p1Xe+v9d7x0lSyfe+o/DQwZLrKH3yRBV86fN7dR0nFFTahHGa42bpv4s2qrrJnz0FAaCtmEEH7IaNRRV95CZ5q+ZJxih41hUKTDnJ71hAj2SrPlHycyNe8onKxX7GATrF6OIsnbZfXz2/cKMk6YuTBmpAbrrPqQAAAIDeo+CC81RwwXl+x2iz2KZSNS1eqsjwIQoNHOBbjsZ5C7X5vt9LkuLlFVp3w+0a/sQjMk7754MES4o15MFfpSTXfe8s018/XC1JKkgP6S9fOVgFGd1jyVIAvQ8FHbAbifn/S5ZzkmStYs89IHfy8TKO628woAcymf1lPy3n5EhZ/X3Ng+4r4VWqKfGhrG1RyB2tsDvK70i7ZIzRjSfupwunDpVrpP6UcwAAAAB2oWnhEq299gbZaExyHPW/7XplHnKQL1li6zdsHXieEtU18pqa5Wb49zONZ63+PmtN67iiMarXl27WuRMHpuwe1lpFW+IKR/a811+8qlq1r78tJxJR9glHsycegB1Q0AG7k4hvP/YSkvUnCtDjFU+WaamR3fyRlFYkM3LvlrRA72atVWP8f7JqkSS1JGbLNXkKOEU+J9s1Y4wG5fnzQ2zMW6/m+CxJnsLueIXcYb7kAAAAALBnVc/8RzaeSA6sp8onnvatoEufOF4mEk6WhdYqbfx+vpZzkmQkpQVd1bVsfT8vK5y6t7/Xra7SXbe9rqqKRo0cW6SrbzxW6Rk7L90SdfVafenVildUStaq7q13NOBnt7KEKoDtsAcdfJVYOkvxd5+Rt2ml31F2yt3/CJniQa3jwPFfkXGZPdfRbGOZ7OpXZTfNkLXenk9Aj2CMkRl0rJwpP5Az7iKZUJbfkdAtxVvLuU95ts6nLF2bZ1vUFH9PVk2yalFz4kMl+P8KAAAA6LKctLStA+NsP+5kwT4lGvzbu5T3+c+p8OsXaMCdN/mW5VPGGN1y8v6KBJJveR87sljHjy5J2fUf+d0Hqq5qkiQtW1yu/z6zcJfHNs6ep3h5hWSTn/RvnDVHiYrKlGUB0DMwgw6+ib/7jGIvPJQcOK7CPJtvQQAAo6JJREFU3/6FnEFj/A31GSaSrvBlv5a3ZpFMRo6cPkP9jtTj2aZy2Q9/IXkxSVaqXi4z5kt+xwLQCf49b72enLNWhRlhXXPM6L3ai82YoFxTpIQtU/Lzk44CTup+IOtJrG3WZ6eFW9soGcpxAAAAoCsquOBcNX48R7ENm+Tm5qjo4gt9zRMeMkjF3/m6rxk+a9qwQr162dFqjnvKTOHsOUmqr22R9ZI/Qxkj1de17PLYQEH+dmMTCsrJyEhpHgDdHzPo4Jv4B//ZZmQV//g137LsjgmG5Q6fSDnXWcrnbS3nJGnTTFnLuqJAT/fR2kr95NVFWlpWrw9WV+iaZ2bv9bXSA4cnl2t0RikjcLwc07V/CLLWav7GGn24plLxROfNGnZMlhzltI6N0uSa/N2ckWRtXM3xOWqMvatoYnVHRgQAAACwjWBxkYb+6X4Ne/wPGv7YwwoPHrTnk3qhgOukvJyTpJM+N7b1seMaHXn8iF0em7bfaBV+/QKZUEhOdpb63vADOWmRlGcC0L0xgw6+MVn5spWbJOtJ1spk5fkdCV1BOE9bZ3QYKZzN+txAL7CsrL71sWel1VWNinueAk77P0tkTFBhd+yeD+wifv76Yj09d70kaUK/HN33hQMVdDv+M1TGOMoIHqOot0KSp6AzVMbseaPzpvhMxe1aSVI8sV7GBBR0+ndwWgAAAKD3iZVXKLZxk8LDhrbu72ZcV8GiQp+T9U7HnDRKAwbnav3aGo3dv0QlfbMlSV5zizbd9Rs1fDRHkVHD1ff/Xa1Abo4KLjhPBRecJ+t5apq/SA0fzVb6AfvLBHhLHkASM+jgm+BZV8jk95WMkTNisgKHn+N3JHQFRROk/kdKTlCK5MmMu8jvRECv1BxPqGGbjbU72uSBeXKNkWMkx0iT+ufuVTnX3VQ0tLSWc5I0d0ONPlzbefsSGBNS2B2jsLufHNO2/SsSdvO2V1DCK+uYcACALs1aqw0NVSptqvE7CgD0SPXvz9SKC76ttVddr5UXXarYplK/I0HSyDHFOvqEka3lnCRVPPaE6t56V15dnRo/nqvN9z/c+pq1Vht/9iutvfp6rfvhzVr7w5tl4533szaAro26Hr5xigYocvXvZT1Pphe8CYu2McaRGXmONJLCFvDLs/PX6+evLVbcs/rCAQN0zTGjO3wm68iiLN37hcn6z4INyk8P6cKDhnTo/bqKgGNktP1OcKFOmD23L1xToLjdqGRq26ZlMQEAPYtnrR795H+aX7VOknR4n9E6c8iBPqcCgJ6l7A+PSl5yCfxETa2qnnlexZd8w+dU2JnYhk1bB56n6LoNW1/bWKq6195qHTfNma+m+YuUPnF8Z0YE0EV17XeA0CtQzgFA11HfEtdPX12k+JaNr5+cs04fr6/ulHtPHpCnH500Tt89YqSyIntearEnyEkL6dLDt+5bcMLoEk0a0LWXfE4LHKSgGSLXFCjsTlTAGeh3JABAJ1tdX95azknSO5uWqKqlwcdE6O5sS63sqpdkV78iG+O/JUDSjh+SZPuPLivryGmS3fqxy0D+1p/pTGjHn21NKCSbSKhx9lw1zp4nm0h0Sk4AXQ8z6AAAQKvmWEKe3f65+paYP2F6ia8dNESn7ddXLXFPfbMjXX7fTWPCSgse5HcMAADQQ9h4i+ysX0ot1cknSmdKU66TcXjLCr1b0Xe+rvU33SEbjSlQkK+8c87wOxJ2IXPawTJpEdmmZklSw/sz1ThvodLH76dgYYEKLvqyKh55TJKUc+oJCo8eofU3/1gN738oSco4bKr63/L/mMQA9EJ8twMAAFoVZoZ1/KgSvfpJcn+DofkZOmhQgc+per6CjHCHXt+zjWqKz5Bn6xRwBijiHiBj+OEPALB3BmcWalzeAC3YMotuWsko5YUzfE6FbqtujdRStXXcuFlqLJUy+/uXCegCMg6cqGGP/1Hx0s0KDR4oJ9yxPzNg73mNTa3l3KdiGzdJ4/eTJBV+5XzlnnaSbDyuYFGhmj9Z1lrOSVLDezPUsnK1IsOHdmpuAP6joAMAANu59ZT9dfLYPmqKJTRtaKHSgq7fkbCPmuIzlLBlkqxi3lK5Jkshd8QezwMAYGccY/S1UUdoY2O1AsZRcVq235HQnUXypG135TWOFMrxMxHQZQRyshXI4e/Yrs7JzFD6pAlqnD1PMkZOJKL0yQdsd0wgL1eSZK1V5b+e2/EaO1kKE0DPR0EH7CPrJZT44AV5ZWvkjp4qdzTLfgHo3lzH6PBhRX7HQAp5tk6tb3rJbBkDALD3HGPUP6Nr75uK7sGkFUpjLpBd8axkHJkR58iEMv2OBbSZjccl1+3yS9Wj4xhj1P/2G1X9nxfl1dUr+8RjFSzc+Uo0DTM+Ut2rb273XN65Zyk0cEAnJAXQ1VDQAe1gbUJqWS7ZqBQeJuOkK/biH5V492nJcZT44HmFvnqL3DFT/Y4KAECrgDNAMW+pPv10esDp53ckAACAVqbPFJk+U/yO0Sutra/QB5uXKz0Q0tH9xio9wDKKbeU1NWn9LT9V40ezFSgp1oAf36Tw4EF+x9qlxtnz1Dh7rsIjhytr2iF+x+lxnEhY+V84c4/HJSqrd3iu8MIvd0AiAN0BBR3QRtZaqe51Kb4x+UTzQtmcz8lb+F5y7HnJkm7JDAo6AECXEnEPkGuytuxB108Bp8TvSAAAAPBZeXOd7l/wihLWk2S0tGaTrtj/JGaCtVHlU8+qcdYcSVK8rFyb7rlfg3/9U59T7Vz9ex9o/Y9+LDmO5Hkqvvzbyjv7dL9j9UoZh0yRm5ujRHWNJCnr2CPlRCjGgd6Kgg5oK9uytZyTJNssxTbKFA+WrS6TrCd5npyigf5lBABgJ4xx2HMOAAAA21myeK7i1tsyslrXUKnmRExpgZCvubqLRFWNZIxkreR5SlRV+x1pl2rf+F8yq5f8913zyhsUdD4J5OVqyIO/Ut070+VmZSnrqGl+RwLgI8fvAEC3YYLaodN20hU650o5o6bI5BbLPewsuQdv/w2OjTbLW79MtpH9fgAAAAAAQNcQeu615ANrZTxPmVFPYTfob6gUsomEKv72hNbdeIcq//mMrOft+aR2yDnxmOSMtC26cuEVLC5KFnSS5DgK9evjb6BeLlCQr7wzT1P2sUfKuK7fcQD4iBl0QBsZ48pmHiU1vCfZmJS2v0ywRApK4a/dIim5DGb8naeUmP+OnOJBChx2llr+crNUWyEFwwp97Va5wyb4+xsBAAAAAAC9XnFprY586gPNmzZa4aaoTqwJyzmy5yxvWfHo31Xxt39K1qrh/ZmSpPxzz0rZ9SOjR2rIQ79W48dzFBo0UBmT/H+/x8abpXiTFM7dbqnSgq+cp5a169X48RxFRg5X8WXf8jElAOBTFHRAO5hQfyl07i5fT8x+XfEX/5h8vH6ZEqvmS3VVyRfjUcVe+qPcS3/VCUkBAAAAAAB2reBrX9Kom+7UqI9XycnI0KAuun/a3mqcPS+5/OQWTXMXSCks6CQpPGiAwoMGpPSae8tuni276FHJJqS8UdL4i2Wc5Fu/TlqaBtx2vc8JAaDnWrlypc455xzddNNNOuecc9p8HgUdkELe+qWS40peIrknXV2VZCTZLb9SvJwCAAAAAADA3siceqCG/eV3iq5dr/DI4QrkZPsdKaUi+41R04LFyZLOGEXGjvI7Uoex1sou+XuynJOkqk+k0o+kvgf7GwwAeoFYLKZrr71WjY2N7T6Xgg5IIXfoBCWmPyvJSEZyRh4ob9V8qbFWcl0FT/ia3xEBAAAAAAAkScGSYgVLiv2O0SEKL7pAxhg1LVys9InjlX9+22c0pEq8skqVf39KXmOTcs88VZGRwzvuZl5s+3Ei2nH3AgC0uvfee5WZmblX51LQASnkjjtMwXN/oMSi6XIK+ytw9BelRFzexhVyCvrJZBf4HdE31lqpuUJyIzKhvfsLCwAAAAAAoC2cUFBF377Qt/tbz9Paa29UdN0GSVLtG29r6B/vV7CkKOX3MsZIg0+SXfVC8olwnlQ8KeX3Qdt4Tc0q/8vjiq5Zp8zDD1HuKSf4HQlAB5k5c6b+8Y9/6JlnntHRRx/d7vMp6IAUC0w8RoGJx2x9IhiWO3S8f4G6AOslZOf/XqpcLMlIo86T6Xeo37GAVrapXCqdJQXTpb6HtK7TDwB+sDah5sRcJWyZXFOkiDtBxrh+xwIAAEA7JCqrFF2zrnVsW6JqWrSkQwo6STJDTpTyR0vRWil3pEwg0iH3wZ5t+uV9qnvzHcnz1PDBh3LT05V11DS/YwHYiY0bN+q4447b5euvvfbaLl+rra3VddddpxtvvFF9+/bdq/vzDiSAjlc+b0s5J0lWdumTUp+pMg5vNsJ/trla9sO7pESLJCtVLJSZcLHfsYBuydqEYt5KWUUVdAbJMcyY3hstiYWKeUslSZ6tlpGrSGCCz6kAAADQHm5ujtzcHCVq6yTPk4xReMigDr2nyR7coddH2zTOmZ/8dy5JrqPGeQso6IAe6JZbbtGkSZN0xhln7PU1KOgAdDwvvv3YepKsL1GAHVQtlhLNW8eVC2XjLTKBsH+ZgG6qKT5dcZtcwqclsUSZwZPkmHSfU3U/CVu52zEAAAC6PhMIaMDPbtXmB/4gr6FRBV/6fIcXdOh81vMU31wmNztLTnryZ5/0cWNU9877yZIu4SltvzE+pwSwK3379t3tLLldeeaZZ/Thhx/queee26f7U9ChR7FN9bIN1TL5fZmd1ZUUjpfS+0iNm5LjwSewhCC6jkj+NgMjBdIkN+hbHKC7sjbeWs4lxRT3NinkDvMtU3cVcEqUSJRuNwYAAED3Exk+VIPuusPvGOggXlOT1l53s5oXLZEkuQX5Krn82yq55ntyc3PUsmadsg4/VFnHHCFJSjQ0qmneQgUK8hUZyc9JQHf21FNPqaKiYod9526++Wa98MILevjhh9t0Hd4hR4+RWDhd0b//RErEZfqNUPibP5WJ8Kn9rsAEwtKBV0s1K6RghkzWQL8jAa1M3ihpyCmy696UAukyY74sYxy/YwHdkCspJCna+gyz5/ZOyBktI1dxWy7XFCjkjPQ7EgAAANBt1b/3gRo+mqPwiKHKOfl4GWNSct3qF15R8+IlreNERaU23PELDXv0QZVcccl2x8ara7T68msULy2TJBV9+0Lln39OSnIA6Hx33XWXmpubt3vuxBNP1BVXXKHPfe5zbb4OBR16jOhz90uJ5FKKdsNyJT56SYFpZ/ucCp8ybkjKZ0o/uiYz5CSZISf5HQPo1owxSg9MU1N8hqxaFHJGyTXM/NobxhiF3JEKiWIOAAAA2Bd1b7+rDbf9XHIdKeEpXlGpwq+cn5Jr25aoJKPttnHxPMU2lipYUrx9jjfeVnxzeeu4/C+PU9AB3VhJyc7f7ygoKNjlazvDFAH0HPHY1sdGstuOAQBAhws4RcoKnabs0DmKBPZP2SdTAQAA0DXUT5+h0nsfUvULL8t6nt9xgD2qf2+G5CTLOUmqf/u9lF0758Rj5ObmbH3CGLn5eQqPHL7DsSYYkuzWIs+EQinLAaD7YgYdeozg8V9V7Nn7koOsAgUmH+9vIAA9RlMsoY01TeqXk6ZIkP0tAQAAgK7AxjZI8XIpUCwT7ON3nB6v7u33tOG2n22diVReqcKvfdHvWMBuhQb031qMOY5Cg1O37UqgsEBD/3if6qfPUOO8BQpkZyv3c6fIzdhxqf/sE45W7etvqWnuAikQUJ+rLktZDgBdw5IlS/Z80GdQ0KHHCBx8mpyh42VryuQMHMv+cwBSYll5vS7750eqbY4pLy2oB86boiH5GX7HAgAAAHo127JManhPny4vZzOPkgkN9jtWj1Y/ffuZSHVvv0tBh92y1qrmxVfV8P5MhQYPVMEF58kJhzs1Q955Zyu2ebMaZsxSeNRwlXz34pRe383KVM6JxyrnxGN3e5wTDmvg3Xcqtmmz3KxMuZkZ8ppbFK+qVrC4UMblw8BAb0RBhx7FKR4kFQ/yOwaAHuSh95arviW5ZG5Nc0x/fH+Fbjt1vM+pAAAAgF6uZfmWB1tmxrSskCjoOlRo4PYzkcIpnImEnqnu9bdVevdvk4P3ZihRVaM+13y3UzM4oaD6XN2599wVY4xCfZN7UzXOW6j1198mr6lJocEDNfCeHyuQk+1zQgCdjT3oAADYjXjC23aZeMUS7LMAAAAA+M7JUHL2nJL/dFjloqPlfeEs5ZxyggKFBco4+EAVX3GJ35HQxTXOXZCcdSlJ1qrx47n+BupCNt/3e3nNzZKk6Nr1qnrq3z4nAuAHZtABALAbX5s6VB+trVJLwlPIdfSVg4b4HQkAAABA+oGSV79lD7oSKe0AvxP1eMmZSJf7HQPdSGTMSNU8/1Jy4DiK7Dfa30BdiNfSom0/DWxboj6mAeAXCjoAAHZjYv9cPfmNaVpRUa8RhZkqyOjc9fIBAACA3sZG62TXvColojL9pslkDdjhGOOkSdkn+5AOQFvlnHy8vNo61U+fodDQwSr61oV+R+oyCr9yvjb+9JeStXLS05R7Bn+fAb0RBR0AAHtQlBlWUSbFHAAAANDRrPVkZ98nNZZKMrKlH0pTr5eJ5PkdDUA7GWOUf/45yj//HL+jdDnZxx2l8Ihhiq3foMjY0Qrk5fodCYAPKOiAFLAtjYq/8y/Zuiq5k4+XO2is35EAAAAAAOh+onVS46YtAyt5nlS7UqKgA9DDhAcPVHjwQL9jAPARBR2QAtHHfixv+ceSjBIfvazwd++VUzLE71gAAAAAAHQvwYzkr1ijJCvJSOl9/E7VJdS8/Lrq35uh0MD+KvjKeXLCrPIBAEB3RkEH7CPrJeQtm/XpKPkBv+Wze0RBZ72EEh88L2/DMjnDJ8kdOVne+qUyRQPl5JX4HQ8AAAAA0A6etXp+wQatqmzUYUMLdODAfL8j7cA4AWnCpbLLnpbizTKDj5PJ7Od3LN/Vvf2eNv3815KRJKN4RaX6Xnel37EAAMA+oKAD9pFxXJmCfrKVmyTrJZ8rHuxzqtSIv/644m88JhlHiVmvKhYISfGo5LgKfeVHckcf5HdEAEAns9bKqlFSQI7hU9sAAHQnD763XH+esUquMXrso9X69TmTNHVwgd+xdmCyBshM+p7fMbqUxjnzJdeVEglJVo2zZvsdCQAA7CPH7wBATxD66i1yhuwvUzhAwdMvkTtikt+RUiKx+P3kgy3Fo+LR5D+9hGKv/82fUAAA31jrqSk+XfWx51Uf+7eiiaV+RwIAAO3w8uLk3m4Ja+UYo7eWl/mcCG0VGT1iSzknyXEUGTvG30AAAGCfMYMOSAGnaIDC3/qp3zFSzuk7XIlNq7YWdDKSrGSMjBv0MRkAwA9xW6q4Xdc6bk58rKAzRMbwNQEAgO5gcF66Suua5dnkcpf9c9L8joTPaF6yVFXP/lduRrryv/QFBfJyJUnZJxyjRE2t6v43XaHBA1X8nYt8zQkAAPYdBR2AXQqedrGsl5Bd94nM4P3kLftYqimTQmkKnvJNv+MBADpdYifP2U5PAQAA9s71J+ynW16crxUVDTp6RLHOmzjQ70jYRmxTqdZcdb1sPC5Javhotob8/jcyjiNjjPLPPUv5557lb0h0iljpZsWrahQZPkQmyIfhAKCnoqADsEsmkqHwude2jm08Jlu1SSa7UCbMJy0BoLcJmD5yTJ48WyVJCjojZEzI51RJ1sYV81ZLsgo6g7pMLgAAupLirIjuP3eK3zGwC00Ll8hGo63j6Oq1SlTXKJCf52MqdLbq519W6S/vkySFhg7WoF/9VG5Gus+pAAAdgYIOQJuZQFCmiE9YAkBvZUxAGYFjlbBlkoJyTb7fkSQl98ZriL8pz1ZKkqKJpcoIniBj+FYXAAB0H+GhgyVjJGslx5Gbky03O8vvWOhE1lpt/t0fWsfRlatV++qbyjvzVB9TAQA6Cu9aAAAAoM2McRUwffyOsR3P1rWWc5LkqU4JW6mAKfYxFQCgu7HWkxJRyQ3LGON3HPRC4aGD1e+mH6ji7/+Sm5Gh4ku/IRPgrTsAAHoqvsoDAIAeoTmW0OOz1qi8oUUnjemjCf1y/Y6ETmJMeCfPRXxIAgDormztatl5v5di9VLuCGn8t2XcHb++AB0t68hpyjpymt8xuqVEfb2qn3tRNhpVzsknKFhS5HekdjPGqPiSb6r0V/dL1io0dLCyjz/a71gAgA5CQQcAAHqEm16Yr3dWlMkxRs/MXa8/fXmqRhWzJFBv4JiIIu5UNSdmSbIKu+Plmmy/YwEAuhG75B9SrCE5qF4urf+fNOh4f0MBaDObSGjttTepZflKyRhVP/eihv7xvm65RGjuaScqY8pExauqFRk+VCYY9DsSAKCDUNABAIAe4b2V5bKSEtbKSJqxpoKCzieebVZLYp4826SQO0xBZ0CH3zPkDlHQGSxJLEsGAGi/eKMku2VgZGON2t1XE882K5pYJslTyB0ux2R0fEYAuxQr3ayWZSuSA2uVqK5R08LFyjzkIH+D7aVgSbGCJSzXDgA9neN3AAAAgFQYlJcuZ8s7aVbSkHzeKPNLU/xdxbxVSthNaoq/p7hX3in3NcZQzgEA9ooZeMzWgROQ6TN1l8dam1Bj7HVFvUWKekvUEHtV1kY7ISWAXQnk5siEQ9q2WQ/2KfEvEAAAbcAMOgAA0CP87HMH6KevLlRpXYvOntBf04YW+h2pV7LWKmErtnsuYcsVEP8+AABdlxlwlJQ5UGoqk/JGyUTydnmsZ+vlqb51bNWihK1SwFAGAH5x0tPV/9brVfqb38m2RFVw4ZcUHjLI71gAAOwWBR0AAOgRBuWl6/5zp/gdo9czxsgx+fJslT5dKsw1Bf6GAgD0OpX/fEYVjz8pNz1NJdd8TxmTJuzxHJM7TModtsfjHJOm5IJE3jbPdc2Z+/XvfaDq51+Wm5ujom98RYGCfL8joYM1zp6n6mf/KycrU4VfPV+Bwt7zfVjGlEka9pcH/Y4BAECbUdABAAAgpdIDh6slMTe5B50zTAGnyO9IAIBepGnhEpU9+CdJkldXrw0/+rGGP/WonFAwJdc3JqT0wDQ1x2fLylPEHS/HZKbk2qnUvGSp1t/8E0lWMo5alq/UkN/90u9Y6EDRteu09oc3S54nGaOmeQs05A+/ZQlwAAC6KAo6oA1sU70Siz+QCafJGXOwjOP6HQkAgC7LMRGlBXa9dw8AAB0pVlq6dWCtvKYmeQ0NckK5KbtHwOmrzFDflF2vIzQt+kSyydnssp5alq2QjcVkgqkpKtH1NC36REokkgNrFV2zTl5dvdzsLH+DIWVsIiGvqVlORjrFKwD0ABR0wB7Y5ka13HeFbNUmSZIz4WiFz7/O51QAAAAAgJ1JnzhBTnaWvPoGyVqljR8nNzfH71idLjJm1NaB4yg8dDDlXA8XHjFMMiZZzDqOAkWFcjK75vKraL+mRUu07obb5dXWKW3ieA24/UY5aRG/YwEA9gEFHbAH3tKPWss5SfLmvil7xiUy6dkdel/bUKPok3fLW79MzsjJCp31PZlguEPvCQAAAADdXSAvV0Puv1s1r74pNz1dOaee2CtnmqSNGal+t/yfqv/zkgJ5uSr65lf9joQOFhk2RP1u+T9VPfWs3KwsFV18kYzj+B0LKbLprnvl1dVLkprmzFf1sy8o//xzfE4FANgXFHTAnqR/ZikINyB1QlEW/c+D8pbOkqwnb84biuf1UfD4r3T4fQEAAACguwv2KVHhV873O4bvsg4/VFmHH+p3DHSirGmHKGvaIX7HwB7YREJynHZ9eCBRV7912VpjkmMAQLfGx2iAPXCGHSD3kDOSg0BIwc9f1Skz2Wz5Wsl6W8cV6zv8ngAA9BTWWsW9MsW9jbI24XccAAAAQNZald73e31yyhe07OwLVP/Bh20+N/+8s1sfm3BIOScdu9PjvKZmbfzZr7T8i9/Qhtt/rkR9wz7nBgB0DGbQAXtgjFHojEtlT/q65AZk3M75Y+OOP1LxDcslx5E8T+64aZ1yXwAAeoLm+EzF7CpJkmPylRE4Rsa4/oYCAABAr9Yw4yNVP/0fSZJX36ANd/xCI595TMbd8/ep+V84U5HRIxTbsEnpEycoWFK00+Mq/voP1b72puRZ1f1vupysLPX5/qWp/G0AAFKEgg5oIxPq3I13A0d8QSa7UHbj8uQsvtEHder9AQDorjzb1FrOJceVitvNCpq+/oUCAABAr9bw4ceqfeWN7Z6zTc2y0ZhMWts+SJY+fpw0ftxuj2lZs07ytiyF6XmKrlm7V3kBAB2Pgg7ooowxCkw8Rpp4jN9RAABIKc82K2Er5JhsuSZrzye0k9nJKu5GzJ4DgN7OxuOqeuZ5RdeuV+ZhU5V58BS/IwHoJaqe/o823/d76TNbzmUdd5SctNR+IDzrsIPVMH2G5LpSIsE+lADQhVHQAQAAoNMkbI0aYq9JikuS0gKHKegMSOk9jAkr7B6glsQcSVLADJZrdr4EEACg9yi9/2HVPPeiZIxqnn9JA35yszIOmux3LAC9QPVz/00+sJIcR5Exo5R39mnKOjL125nknHK8nPQ0Nc5doMjYUco+7qiU3wMAkBoUdECKxN/7t+IfPC+TXaDgmd+VU9jf70gAAHQ50cQySYnWcUtiQcoLOkkKu6MVdIZISsgx6Sm/PgCg64iVlqn62RckY5R31mkKFBbs9LiG9z6QrE3+ch01zJxFQQe0U/PylfLq6hXZb4ycUNDvON1GoLBA0XUbJM+TrFXG5AnKPubIDrtf1lHTlHVU6ss/AEBqUdABKZBYOkux5x+UJNmKDYr+9TZFvv+gz6m6P2/DciWWfyynZIjcUSw/AwA9wWeXmjQd+O2oY8Iddm0AQNfgNTZq9fd+oER1jSSp9vW3NfRP98kJ7/g1IDRksOKV1ck3yBOeQoMGdnJaoHsrf+RvqvjrE5Kk8MjhGvTLn8iJ8P1WW5RceanW33SHomvXK33yROWfd7bfkQAAXQAFHZACXukqJRcSt5L1ZMvXyXqejLPjHjhom8Sq+Yr+4f+2bGxsFTztYgUOO8vvWACAfRRyRyvmbZBVvaSgwu5EvyMBALqx5uUrlaisah3HN5cpunqtIqNG7HBs3+uu1KZ77lN0zTplHXmYck49oTOjAt2a19Ssir890TpuWbpc9dNnKPuYI3xM1X2E+vfV0D/ex3tFAIDtUNABKeCOmKS44yhZ0Fk5IybzDdc+Snz8enJt9uT/KP7BCxR0ANADOCZNmcGTZdUoo4iM4dtRAMDeC/YpkVxXSiQkI5lAUIHine87GsjP04A7buzkhIB/rLVqWbZSkhQeMVTGmL2/mGMkZ8uftS2M6+7mhNTwmppU/dyL8pqalHPScck/853Mep4aP54rr6lJGVMm79OsQd4rAgBsi3dEgBRw+gxV6Fs/VeLj12Wy8hQ4/PN+R+r2TFa+Pi3nZByZnEJf8wAAUscYR0aZfscAAPQAwaJC9fvRD1X+h79Ixqj4O99QIDfH71iA76y12vjje1T3xtuSpOzjj1afH35/r0s6JxxW8SXf0Ob7fi9JSp8ySZmHTU1Z3p2x1mrtD29R86IlkjGq+vcLGvrH+zr9z/imu+5V7cuvS5JCQwdr8L2/kBMJq2XVGjV+PEfhoYOVPnFCp2YCAPQMFHRAiriDx8kdPM7vGD1G4IjPy1v/ibyls2SKBih45vf8jgQAAACgC8qadrCyph3sdwygS2lZsaq1nJOk2lffVP55Zys8bMheXzPv7NOVdeRhSjQ0KjSw/77NyGuDeEWlmhcuTg6slVdbp6a585V15LQOve92GaqqW8s5SYquXK2Gjz5WIC9Xa666vnVGYfH3vqO8M0/ttFwAgJ6Bgg5Al2TCaQpfeJustR3+TT8AAAAAAD3JTn+OTsHyioGCfAUK8vf5Om3hZmXKpEVkm1skm1xhp7OXuDShUPL/N89rfc5JS1PNi6+1ZpKk6meep6ADALQbCx8D6NIo5wB0pqVldfrN25/oLzNWqSmW2PMJAAAAQBcUGjpY2Scf1zrOOfUEhQYP9DFR+znhsPrfer2CfUrk5uao+PJvKzJqxF5dy2tuUflf/6FN99ynxtnz2nyem5Guku9d3FpuZp98vNInTVAgL3eboI7cgry9ygUA6N2YQQcAACBpXXWjvvX3mYonrDxrNXNtpe79/GS/YwEAgBRqWb1WVU8/JxMIKP/csxUsKfI7ErqxxrkLFFu/UemTD+hy/y0ZY9Tnmu8p/7xzJKlTlqTsCBmTD9CwRx/c5+ts/Ok9qn/3A8kY1bz4igb95udKGzNqj+clGhoVKCzQwLtuV2jwIAVysiVJeeedraYFi9U4e66CfUrU58pL9jkjAKD3oaADAAA93tKyOr25bLP6ZqfplLF95To7vjkxc02lWuLeduPmeEKRgNuuezXHE1q0qVaFmWENzE3f5+wAACA14jW1WnPlD+U1NkmS6t+boaGPPCAnFNzlOV40pujqtQoUFSiQm9NZUdENVD75b5X97o+SJBOJaPB9dyncxWaoGWMUHjTA7xhdQsMHHyWXpLRWcowaP5q9x4IuXl2j1ZderXhZuSSp8FtfU8EXPy8pObNu4F23y8bjMgHeXgUA7B2+ggAAgB5tWXm9vvHYDCWslWelBZtq9MPjxu5w3KC8rWWaY6T89JDCbvtWA69tjulbf5+pNVWNMpJ+cOwYnXMAb4oAANAVtCxdLq++oXUc31ym2IaNCg8ZtNPj41XVWnPlDxXbsEkKBNT/lv9T5iEHdVZcdHGV/3ym9bGNRlX78usq+vaF/gXCboWGDFTL8lXJveQ8q9CQwXs8p+71txUvr2gdVzz699aC7lOUcwCAfcEedAAAoEd7a9nm1nJOkl5ctGmnxx04MF9XHjVSJVlhjSzK0rcPHa7vPTVLV/5rlhZtqm3Tvf67aKPWVjVKkqyk3/5vaSp+CwAAIAVCA/tLrisZScbIpEUUKCrc5fHVz76g2KbNyUEioc33P9w5QdGl2FhMFY8/qY0//7Xq/je99Xk3K1P6dMlIa+VkZ/mUEG3R70f/p/RJByg4sL+KLr5ImYdN3eM5JhxOzrj7dBwK7fS45k+Waf2tP9OGO36hlpWrU5YZANDz8TEPAADQo/XNjrSWc46R+mRHdnnslyYP1pcmD1ZZfYs+/8d3FUt4Mkaav3GWnv3W4coI7/5bJ9cY2W3HO1lKEwAA+CNYUqz+t16v8r88LhMIqPg7F8nN2M1y1N42X9WtlY0nZBMJGbd9y1+3h43FVPnkvxVdt16Zhx2srGmHdNi90Dal9z2smudfkoxR7cuvq//tNyjz0Knqc+33tP6G25WoqVX6xPHK+9ypfkfFboT6lmjgz25p1znZJxyt2tffUtOc+TLBgPpc/d0djonX1GrNNTfItkQlSQ0fzdHwvz0kJ52l7gEAe0ZBBwAAerSTx/bV4tJaPb9wo/pkRXTbqeP3eM6qygZFE8n96KyVGqJxbaht0sii3X8y+pT9+urZ+Rv0SVmdHCNdffTolPweAABAamQeMkWZh0xp07E5Z5ysmpdea13iLr65TCu+dokG/uJ2hfr1SWmuaDShhvoWtfzlEdU8/3KyDHrpdfW/46Y25/VDw8dztelnv1KioUH5556twq990e9IKdfwwYdb9y5zHTV8OFuZh05V2phRGv7PP8trat590YtuywmFNPCuOxTfXC43K2OnpVt01RrZpubWsVdXp+j6jYqMHN6ZUQEA3RQFHQAA6NEcY3T1MWN09TFj2nzOiMJMpQddNccTkqSctKAG5u75jZeMUEB//PJBWlnRoPz0kAoywnudGwAAJFnPU2LWK7Kb18gZNUXuiEmdct9gYYGG/uk+rb/lp2qcNUeyVvGycpX/6a/qd8O1KbvPkgWl+uWdb6ipMabvt7yj9O3KoFldtqCziYQ23PITeY1NkrWq+MvjSp+wn9InTvA7WkqFRwxVvKIyuXdZwlN42JDW14zjUM71cMYYBUuKdvl6aNAAmXBYNhqVjJGTlqZgv76dmBAA0J1R0AEAAHxGXnpID54/RX/7cLVcx+jCqUMVCbZtOauA4+xxph0AAGi7+KuPKv7WPyTHld59WqELb5M7qnNKKyctbft9p6yVV9+Q0ns88sAHam6KSZLWe1kaYRplrE2WQUOHpPRen2pZvVaNs+cqPHjgXhdqXnOLvIbG7Z6LbS5PRbwupc+1V2jzb36nltVrlXXEYco55Xi/I8FnXjSqzfc9rMZZsxUZM1r9b79BVf96TnKMCr/2JUpbAECbUdABAADsxMiiLN1yyv47fW1pWZ3eWrZZa6ublBlydcKYvprYP7dzAwIA0Esk5r2dfOAlJMdRYuH0TivoJCnv7NPVMOMjKZGQHKO8c85I6fWbm2KyW7a7eyFtqi7MX6oiWys3I0Nlv39E1f9+Xn2vv0bhIYNScr+mRUu05qrrpXhcklT8vYuVd+Zp7b6Om5GujEMOUsP7M5MzhzIzlTGlc2Y3dqZATrb63XSd3zHQhVQ+9k/VvPCyZK1ipWVy0iMacMeNfscCAHRDFHQAAADtsHBTjb79jw+V8JLvpBlJT89brz98carG9sn2NxwAAD2QKRogW1UqWU/yrExh/069f8bkAzT04d+oackyRUYOV3jwwJRe/3PnjdcjD3wgSbIZmRpy5/VKWzhLG3/yS0lSS2OTNtz+cw39w29Tcr+al15PLte4RdUzz+9VQSdJ/W/+oWpeel2JujplH3uUAvl5KcnYWbxoTInKSgWKCmXctq2W0B6x0s2KbSxVeORwZlX1IC2r124deJ5aVqz2LwwAoFujoAMAAGiHVz8plezWsVWypJu+upyCDgCADhA66wpFn7xbXulquWMPUeDQz3V+hoEDFBo4oEOufcxJozR0RIFKN9Zp9LgS5ealqfy1UslxkkWa5ylWunmf7hEvr9CmX/9OsXUb5BbkqXXKnuMokJe703NqXn1Tda+/pWBJiQq/8RW5WZk7HGOCQeWeftI+ZftUdGOp6t9+V25errKPO6pDCrNtNS9bobXX/UhebZ2CfUs08J4fK1hU2Pq6tVYVj/5Dta+8oWC/Pupz9Xd3uxfZZ9W9/Z423PELyfPk5udp8L2/aNf56LoyD56i+v9Nl1xHSnjKPHSq35EAAN0UBR0AAMBnJDyr5xZs0NqqRh05vEgHbLN8ZUlmRJ612x3vWWlIfkYnpwQAoHcw2QUKf+PHfsdIKZtIKLZho9y8PLmZGRoyvEBDhhe0vp552MGq+OsTyYHnKfuYI/fpfht+fLea5i9KFn5r1yk0eKCiq9cqWFKkkisv3eH4hpmztOmnyRl8chxFN27SwJ/esk8ZdidWulmrv/N9eU1NkrVq/Hiu+v7w+x12P0kqe+iR1v0EY6Vlqnz8SZVccUnr63Wvv62Kvzzemm/Dj+/S4F//rO3X/8NfWmcqJqprVP3sCyr69oUp/B30fDUvv66y3/9ZMkYll39bWUdN8zuSJCnn5ONlQiE1zp6nyOiRyjn1BL8jAUDHiLbIzp3ld4qOE22RIjt+AKkzUdABAAB8xr1vf6K/f7xWrjF6fNZq3X/ulNY95s45YIAWltbq9aWlco1RVjigsw8YoGNGFPsbGruU8KqVsGVyTK4CDp9cBwD4K1FbpzVXX6/oqjUyoZD633b9Dnu3RYYN0eDf/kJ1b7+nYEmxck4+bp/u2bJi1dZlLR1HmYdOVeGDv5IJ7PxtoaaFi7ebwdc0f9E+3X9P6t+bIa+xsXVc++qb6nPt9zp0Fp3X1LzdUp9ec8t2r7esXrvd/wfRbZc1bAPjusllFj79XFcHzwjsaaIbS7XpF79pne254cd3afj4/brMMqrZxx6p7GP3rTgHAICCDgAA4DNeXlIqSUpYK9cY/W95WWtBF3Qd3XrK/rr1lP19TIi2inub1Rh/S5++OxZxpyrkDvE1EwCgd4luLFX5w39WorZOuWedrujK1YquSZY9NhZV6b0PadifH9jhvMiIYYqMGJaSDJmHHKTa196SjJE8TxlTJu6ynJOktLFjtiv00saNSUmOXQkUbZ09KGPk5mQny7EOVPDlL2j9LT+REp5MMKi8s0/f7vWMgyar8vEnkzmsbfcyhsWXfFPrb/6xbCymYEnRDtfH7sXLy7cuxSpJCU/xiqodCrpEfb0qH39K8eoa5Zx8nNLHj+vkpAAA7D0KOgAAgM8YmJuu6qaoPJss6frnpPkdCXsp5q3UtpsGRr2lFHQAgHax1qr63y+oYeZHCg8bqoKvni8nFGrzuet+eLNim0olz1Pj7HnKOeUEtU6tspKNxTo0vySVXH25QgP7K7axVJlHHqb0iRN2e3zG1Mnqc92Vqn3tLQX7lqjoG1/t0HyZ0w5R7jlnqOa5F+XmZKvvDdfKGNOx9zx0qob+4T61rF6jyOiRChYWbPd6+vj9NODnt6nurXcV7FuivLPPaNf1M6ZO1rC//1HxsnKFBg2UEwqmMn6PFxk5QsE+Ja37L4YG9ld4yMAdjlt/051qWrBYklT76hsa8sAvFR42pDOjAgCw1yjoAAAAPuPmk8fp5v/O19rqRh0/qkRnju/vdyTsgWcbFfc2yTHpck1J65t6RmFtXV/KyFHEz5gAgG6o5sVXtfm3D0mSGmbMUqKhQX222atsd7zGJsU2bNz6hLUK9u8rNztLieoayRgVXvTlfcoXXb9RVU/9WzKO8r5wpkJ9S3Y4xgmFVHDBee26bs6JxyrnxGN3e4xNJNQ4e56U8JQ+ecJuZ+XtjjFGJZd9SyWXfWuvzt9boQH9FBrQb7vn4pVVKvvDXxSvrFLuaSepz/d33KOvrQI52QrkZO9rzF7JiYQ16Le/UM1/X5EcR7mnnigT3L7ktPG4muYt3O65xrkLKOgAAN0GBR0AAMBn9MtJ0++/eJDfMdBGnq1XfewVSckZCCFnP0UC+295PFYxb52sGiUFFXZ3P2MA6Gps7RrZlS9INiEz+ESZvJF+RwJ6naZ5C7fuRWatmmbPa/O5TnqaQoMHJZe0tFZyjDKmHqjcU09U8+JPFOxTrNDAAXudLVHfoDVX/FCJujpJUt3/3tOwP/9OTlrHfyDFWqsNt/1c9e++L0lKO2B/Dfz5bR26b1xnWHfD7WpZvjI543Hmxxp078+VNna037F6pUBujgq+9IVdvl7rVanl9PEKvL9CbnmDJCk8dHBnxQMAYJ917ILeAAAAQAeLeWv0aTknSVHvk9bHcbt2SzknSVFFvRWdGw7YBzbeLDvnfqlqiVS9THbeg7ItNX7HAnqdtLGjtu7HZozS9t+vzecaYzTgJz9S4NPlEz2rmv+8KDcrUxkHTd6nck6SWlauUqKmJpnP85SorGrd325fNa9Ypbp3P1Citm6nr0fXrm8t5ySpac58NS36ZKfHdhc2kVDL0uVb/31Lau7mv6eean3DYn1c/oIqzxupsp+eIHPwGJVcdbnSD2CfaABA98EMOgAAAHRrRqHPjMOtj+O2fLvXEnZzp2QCUqK5Uko0bx17camxVArn+JcJ6IVyTj9ZXmOT6mfMUmTEUBV+/SvtOj+2abPiZVu/HlX/+wXln3eOgiVF+5wt1K+vTCAgm0hIkkwwqGCfHZe4bK/q5/6r0l//TpLk5uZo8H1375DXCYd3OM+J7Phcd2JcV+GRw1tn0ElSZOwon1NhZ9bWz299bEOunOu+oNwcVsAAAHQvFHQAAADo1oLOUMW9TYrbDZJCSgtMbX0tYAoU15rWsWva/mZoS+ITRROLZRRSJDBFAacwlbGBPUsrlIJZUqxBkpXcsJTRb4+nAUgtY4zyzz9H+eefs7cX2PE5ZyfP7YK1VpV/f0o1L72mYEmJ+lx1aWsJFyjIV/87blT5n/4mGanoW1+Tm4I9z8r/8vfWx4naOtW89JoKv/bF7Y4JlhSp4KIvq+KRxyRJueecofDwoft8b78NuPMmlf3h0S170J3I8pZdlGtCkhq2jKwCTmh3hwMA0CVR0AEAAKRYNO7prjcW672V5RpdnK0bT9xPeem8adBRjHGVHjxc1sYluTLbvBEadEbIKq64VyrX5Cnstm3Zo7hXoZbEbEmSVbMa4/9TVvBMGcMK8eg8xg1Jk66QXfOKZD2ZAUfLhDL9jgWgndLGjVHmkYep/u33JEl5552lYNGeP/RhrVWiqloNs+ep/A+PSpJiGzZpw+0/1+D77m49LmPKJGVMmZTSzE4krISRZCVZKxPe+fcxhV85X7lnnCJ5ngJ5uSnN4JdAfp76/uAKv2NgD0bnHqa5Fa8qbluUHSzSgIyxfkcCAKDdKOgAAABS7G8frdZz8zfISqpcVa673lisO0+bsN0xa6oaNHdDjUYWZWp08b5/0h2SMTt+a2uMUdgdq7DbvjdtPFv/mWdiW35176W70P2Y9CKZMV/2OwaAdoiuW6/yPz8ur6VF+eeepfTx49TvpusUXb1WJhBQaMCeZ8J6Tc1ad8Ntapq7QAoEkrPwrJU8Ty2rUrPH3O6UXHmp1t/8Y9mWqMKjhiv39JN3eWwgBTP2gPbKDhXqsD7nKWFjCpjQdh/QAgCgu6CgAwAASLE1VQ1b30ez0qrKxu1en7O+Wpc/+ZHinpWRdMdp43XcqH3fLwapE3CKpURAUkKSlWsKJe189oC1CVnFZcSbQwDQ29lYTGuuuVGJqmrJWjXO/FhDH3lAwZIihYcMavN1ql94WU3zFiYH8Xjyn44jWavMQ6akPvhnZEyZpBFPPqpEba0CRYUyDjPI0fU4xpFj+PAUAKD7oqADAABIsSOHF+u/izbJNUYJa3XsyOLtXv/X3HXyrJWUXDnqsY9WU9B1MY5JU0bwBMUSq2RMUCFn+E7Lt7i3SY3xdyUl5Jo+Sg9MkzFu5wcGAHQJsbIKJSoqW8c2FlPzshUKlrR9D1RJsk3NW2fNSTJpEWUfe5SCJUXK+/znUpp5V5y0iJy0SKfcCwAAoDeioAMAAEixY0YW664zD9DMNZUaUZip08dtv5RVVmTrt2COkXIiwc6OiDZwTZbcwPjdHtMUn6HkLDspYTcp5q1SyB3eCekAAF1RoLBAbn6eEtU1yXLNdRUZMbTd18k+4RhV/utZebV1kqTCC7+s/C+cmeq4AAAA8BEFHQAAQAc4fFiRDh+280/Lf33qUH28rlrLy+tVlBnWlUeN6uR02FvWxhW3pTIKyjVFsopt//pnxqmS8KoU89bJMekKOkNlDEuNAUBX5ISCGnT3HSp75DHZlhbln3u2giXFez7xM4IlRRr6x/vUNGe+AiVFShvD9woAAAA9DQUdAABAJyvICOuvXzlY9S1xZYQDcti3rFuwNqaG2KvylJzNEHSGK+yOUUtigSTJKKyg0/b9hdoq4VWrIf7qpymU8CqVFjwo5fcBAKRGaOAA9b/pun2+TiA3R1lHTUtBIgAAAHRFFHQAAKDDWGsV81Yo7pXKdXIUcsawP9cWxhhlsbRltxL3NrWWc5IU85YrK3i2XFMsaxvlOiVyTOr36onb9VseJfchitk1ShMFHQAAAAAA3RkFHQAA6DAxb5WaEx9JkuKJdfJsVGmBST6nAvaS+ey3zkaSUcDZ+VKmqeIoU5+Wc5KRo4wOvR8AAAAAAOh4bF4BAAA6TMJuVrLE2DL2Sv0LA+yjgOmjgPl0CUujiHugzA6lXQfc1xmkkDNKUkiOyVFa4NAOvycAAN1F9X9f0bJzL9TyL39T9e/P9DsOAABAmzGDDgAAdBjX5Cum1VtGRq4p8DUPsC+MMUoPHiLPTpSRK2M6Z4lSY4wigYmKaGKn3A8AgO6iZc06ld792+TAGG249Wca/s9H5GZm+hsMAACgDSjoAABIoepFq7X6X+8oY2CRhl1wnBy3d++3FnRGyCqquLdRjslTxJ3gdyRgn3XEPnMAAKD94pvLtg6slY3FlKiqpqADAADdAgUdAAApUr14jZ6dcom8lris52nz+wt12P3f9zuWr4wxCrvjFHbH+R0FAABgp2LeRnm2WgFTItfJ9zsO2iEydrTcgnwlqqolaxUeOljBfn39jgUAANAmFHQAAKTImqffaS3nJGnZIy/1+oIOAACgK2tJfKKWxOzkY81TeuBoBZxif0OhzdyMdA257y5Vv/iqTCCg3NNPlunlK1gAAIDuw9nbE1euXKlJkybpX//6VyrzAADQbWUMKm4t54zjKGNgkc+JAAAAsDuxxIptRkYxb/Uuj0XXFCgsUOFXzlfBFz8vNzPD7zgAAABttlcFXSwW07XXXqvGxsZU5wEAoNsa9qVjNeayMxVIDytrRD8d/feb/I4EAACA3TAmXZLZMrIySvMzDgAAAHqRvVri8t5771UmG+4CALAd4zg69LdX6NDfXuF3FAAAALRBWmCyGuPvyrO1Cpg+Cruj/Y4EAACAXqLdBd3MmTP1j3/8Q88884yOPvroDogEAAAAAADQ8RyTqczgSX7HAAAAQC/UriUua2trdd111+nGG29U3759OyoTAAAAAAAAAAAA0GO1awbdLbfcokmTJumMM87oqDwAAAAAAKSU19yiqqefU6K6RtnHH6PIyGF+RwIAAADQy7W5oHvmmWf04Ycf6rnnnuvIPAAAAAAApNT6W3+qxg8/lhyj6mf/qyEP/UqhgQP8jgUAAACgF2tzQffUU0+poqJih33nbr75Zr3wwgt6+OGHU50NAAAAAIB9YuNxNc6clRwkrGzCU8NHcyjoAAAAAPiqzQXdXXfdpebm5u2eO/HEE3XFFVfoc5/7XMqDAQAAAACwz1xXgeIixcsrJM+TJIUG9vc5FAAAAIDers0FXUlJyU6fLygo2OVrAAAAAAD4yRijAXfcqE33/FbxqmrlnXW6Mg6c6HcsAAAAAL1cmws6AAAAAAC6o/CwIRr827v8jgEAAAAArfapoFuyZEmqcgAAAAAAAAAAAAC9guN3AAAAAAAAAAAAAKA3oaADAAAAAAAAAAAAOhF70AEAAAAAAHRx0bXrVPanv8k2tyj/vLOVPnG835EAAACwDyjoAAAAAAAAujAbi2nNNTcqUV0jWauGWXM09E/3K9S3xO9oAAAA2EsscQkAANCLxT1Pa6oa1RCN+x0FAADsQqy8UonKKsnzJGuleFwtK1b6HQsAAAD7gBl0AAAAvVR1U1SXPPGRVlU2KBJwdPdZE3XgwHy/YwEAgM8IFuYrUFigeGWVZK1MIKDI8KF+xwIAAMA+YAYdAABAL/XEx2u1pqpBktQS93TXG0t8TgQAAHbGBIMaePedyjpqmjIOPUgDfnargn1Y3hIAAKA7YwYdAABAL9US91ofW0nRbcYAAKBrCfXvq343XOt3DAAAAKQIM+gAAAB6qXMm9FdWOChJMpK+feiwnR6X8GrUGH9fjfH3lfCqOy8ggC7DWqvYq4+q6adfUfPvrpZXts7vSAAAAADQrTGDDgAAoJfqn5uuJy46VPM31mpAbpoG52fscIy1UTXEX5cUlyTFvY3KCp4mY0KdnBaAn7z57yj+xuOSJFtfrejjdypyxQM+pwIAAACA7ouCDgAAoBfLSQtp2rDCXb6esHWSYts8E1PC1ipgdn0OgJ7HK18vGUeynmQ92YoNfkcCAAAAgG6NJS4BAACwS67J1Paf6QrIMVl+xQHgE3f0QZIxkuNKkpxx03xOBAAAAADdGzPoAAAAsEvGhJUROErNiQWSpLA7To4J+5wKQGdz+g1X+OK7lJj3tkxOkdyDT/M7EgAAAAB0axR0AAAA2C3XKVCGc6TfMQD4zBk4Ws7A0X7HAAAAAIAegSUuAQAAAAAAAAAAgE5EQQcAAAAAAAAAAAB0Igo6AAAAAAAAAAAAoBNR0AEAAAAAAAAAAACdiIIOAAAAAAAAAAAAaKOKigr94Ac/0CGHHKJJkybp4osv1vLly9t1DQo6AAAAAECnsNbzOwIAAAAA7LPLL79cq1ev1kMPPaQnn3xSkUhEF110kZqamtp8jUAH5gMAAAAAQLZxs+y8h6WmzbJ5Y2TGfV0mEPY7FgAAAAC0W01Njfr376/vfOc7GjVqlCTpsssu05lnnqmlS5dqwoQJbboOBR0AAAAAoEPZT56QmsqSg6olsmtflxl6ir+hAAAAAGAv5OTk6O67724dV1ZW6pFHHlGfPn00YsSINl+Hgg4AAAAA0LFaaiXZLQMjRev8TAMAAAAA2rhxo4477rhdvv7aa6/t8Ro33XSTnnjiCYVCIT3wwANKT09v8/3Zgw4AAAAA0KFM/2nbDCTT5yD/wgAAAABAilx44YV66qmndPrpp+vyyy/XggUL2nwuM+gAAACwAy+e0Kyb/qT1L85Q4UGjNfXuSxXMavunwABgW2bAUVJ6idSwScobJZPZz+9IAAAAAHq5vn37tmmW3O58uqTlnXfeqTlz5uivf/2rfvKTn7TpXAo6AAAA7GDBPf/UvJ//XbJWVfNWSpKmPXSNz6kAdGcmf4yUP8bvGAAAAACwTyorKzV9+nSddNJJCgSSNZvjOBoxYoQ2b97c5uuwxCUAACm2aFOtHp+1Wh+vq/I7CrDXKmYvkzFGkmQ9T+UfLvE5EQAAAAAAgP/Ky8t19dVXa/r06a3PxWIxLVy4UMOHD2/zdSjoAABIofdXVegbj8/Qr99aqkv/+ZFeWLjB70jAXul33GRZz5NxHMkY9T9pqt+RAAAAAAAAfDdq1CgdeeSRuuOOOzRz5kx98skn+r//+z/V1tbqoosuavN1WOISAIAU+s+CDZKRZJPjf81dr1P3Y58ddD8jv3GKZIw2vjZL+RNHaNxVX/A7EgAAAAAAQJdwzz336O6779ZVV12luro6TZkyRX/729/Ur1/b3wekoAMAIIXy00Ot/ZxjpMKMkN+R0At4sbg2vPqRTMBV32MnyXHdfb6mMUajvnGKRn3jlBQkBAAAAAAA6DmysrJ0yy236JZbbtnra1DQAQCQQt88dJiWbK7T3A3VGlaQqe8fNdrvSOjhvHhCL510nTa9OUeSNPCMQ3XcM7e37h8HAAAAAACAroeCDgCAFMqJBPXg+VPkWSuHggSdoGzG4tZyTpLWPjddNYtWK3e/If6FAgAAAAAAwG45fgcAAKAnopxDZwlmRHZ4LpCR5kMSAAAAAAAAtBUFHQAA6NI2vPqRPrr+Ya168i1Za/2O0+XkTRimcVef2zqedMuFyhxc4mMiAAAAAAAA7AlLXAIAgC5r9dPv6PXP3yzjOrIJT1N/eZnGXfl5v2N1KcYYTb3rEk344RclxyhSkON3JAAAAAAAAOwBM+gAAECXtfKJNyTHyCY8SdLyv73qc6KuK1KUSzkHAAAAAADQTVDQAQCALitraF8ZJffzM66j7OH9fU7UPS0tq9MrSzZpc12z31EAAAAAAAAglrgEAABd2IQbLlDN0vXa+NosFUweqYN/dZnfkbqd/y7cqFtfWiBJSgu6eviLB2l4YabPqQAAAAAAAHo3CjoAANBlBTPSdOw/b/bt/tbzVDVvpZxQQLljB/uWY188MnNl6+NoPKGn567TtceO8TERAAAAAAAAKOgAAAB2wnqeXv/CLVrzzLuSpP2+/3kdfE/3m8GXGQrIMZJnJSspI8S3fwAAAAAAAH5jDzoAAICdKH13fms5J0kLf/WU6tdu9jHR3rn2mDHKCgclScMLM/XlAwf5nAgAAAAAAAB8hBoAAKAHG9snW/+5+AjVNseUlx6SY4zfkQAAAAAAAHo9ZtABAADsRMm0/TXozGmt4/2uPEeZA4t9TLT3gq6jgoww5RwAAAAAAEAXwQw6AACAnTCOo2OfukWVc1fIDQWUu98QvyMBAAAAAACgh6CgAwAA2AXjOCqYOMLvGAAAAAAAAOhhWOISAAB0S9bzVLtsvVoqa/2OAgAAAAAAALQLBR0AAOh24k0teuHoq/TUqK/p8b5f0Iq/v+53JAAAAAAAAKDNKOgAAEC3s/yvr2rzO/MlSTaW0HuX/krWWp9TAQAAAAAAAG1DQQcAALqdRHNUMqZ17EVjPqYBAAAAAAAA2oeCDgCAXq5qwSpteP1jxZta/I7SZsO+fKyyhvZpHU+69esy2xR2AAAAAAAAQFcW8DsAAADwz7xf/EMf/vAhSVLO2EE6/b17FcrJ9DnVnkUKcnTm7N+r9J15Su9boPwDhvsdCQAAAAAAAGgzZtABANBLeYmEZt34x9ZxzaI1WvnEWz4map9gZpoGnDyVcg4AAAAAAADdDgUdAAC9lDFGJuhu95wTcHdxNAAAAAAAAIBUoaADAKCXMo6jQ++9QsZJfjtQPG2chn7pWJ9TAQAAAAAAAD0fe9ABANCLjfz6yRpw6lS1VNQqZ8yg1rIOAAAAAAAAQMehoAMAoJdLK8lXWkm+3zEAAAAAAACAXoOPyQMAAAAAAAAAAACdiIIOAAAAAAAAAAAA6EQUdAAAAAAAAAAAAEAnoqADAAAAAAAAAAAAOhEFHQAAAAAAAAAAANCJKOgAAAAAAAAAAACATkRBBwAAAAAAAAAAAHQiCjoAAAAAAAAAAACgE1HQAQAAAAAAAAAAAJ2Igg4AAAAAAAAAAADoRBR0AAAAAAAAAAAAQCeioAMAAAAAAAAAAAA6EQUdAAAAAAAAAAAA0Iko6AAASDFrrcpmLtaG1z9WIhrzOw4AAAAAAACALibgdwAAAHqaGVffr4W//pckqejgsTr5jXsUiIR8TgUAAAAAAACgq2AGHQAAKdRSWdtazklS2QeLtOHlD31MBAAAAAAAAKCroaADACCFjOtIjtnuOSfEhHUAAAAAAAAAW1HQAQCQQqGcTB30s4tbx4PPOVz9TjjQx0QAAAAAAAAAuho+0g8AQIrtf815Gvbl4xRvaFbW8H4yxuz5JAAAAAAAAAC9BgUdAAAdIL1vgd8RAAAAAAAAAHRRLHEJAAAAAAAAAAAAdCIKOgAAAAAAAAAAAKATscQlAAApsOmtOVr34kzljRusYRccz75zAAAAAAAAAHaJgg4AgH20/pUP9fLJP5RxHdm4p9rlGzXp5q/5HQsAAAAAAABAF0VBBwDAPlr15NsyTrKck6QVj71KQQcAAAAAAIBuyzbF1PLKJ37H6DC2KSYT8TcDe9ABALCPsof3k/WsJMm4jrJG9Pc5EQAAAAAAAICujBl0AADso/2uPEfVi9ZozbPvKW//IZr24NV+RwIAAAAAAADQhVHQAQCwj9xwSEf86Tq/YwAAAAAAAADoJljiEgAAAAAAAAAAAOhEFHQAAAAAAAAAAABAJ6KgAwAAAAAAAAAAADoRe9ABAIAdbHj1I6166n/KGt5P+11xttxQ0O9IAAAAAAAAQI9BQQcAALaz6a05eumk62RcVzbhqWbJGh3++2v9jgUAAAAAAAD0GCxxCQAAtrP2hQ+S5Vw8IVmrNc+863ckAAAAAAAAoEehoAMAANvJHTsoWc5JMq6j3HFD/A0EAAAAAAAA9DAscQkAALYz4msnqm75Ri1//DXljOyvaXtY3tJLJFS9YJXC+dnKGFDUSSkBAAAAAACA7ouCDgDQJTTFErrj5QWauaZK+5Vk65ZTxik3LeR3rF7JOI4m3/51Tb7963s8Nt4c1Usn/kCb35kvGemQ33xPYy8/q+NDAgAAAAAAAN0YS1wCALqEP76/Qm8s3aza5phmrKnQb95aus/XrF22Xh9d/7Dm/vRxxeoaU5ASn7X6qbeT5ZwkWWnGNQ/I27I8JgAAAAAAAICdYwYdAKBLWF/TJGuTjz0rranet0KtcVOlnpt6qWJ1TbLWas1z7+m0d34jY0wK0uJTNuFtP/asWv9FAgAAAAAAANgpZtABALqEY0YWy0pytxRoJ4wu2afrbXpztqLVDckCybMqm75QzZurUpAU2xr8+SOUP2lE63jy7V+XE+TzPwAAAAAAAMDu8A4aAKBLOGF0H2WEApq1rkpjS7I1rTBNm99fqJwxgxTOzWz39bKG99s6cIyCWekK7cV1sHvBjDSdPv23Kp+xWOHCHOWOGeR3JAAAAAAAAKDLo6ADAHQZhw0t1GFDC1U+6xM9OfVbitU2KpiToVPeuEcFE0fs+QLbKDpojA757RWa++O/KZiTocN+d5XccKiDkvdubiioksPH7/S1ptJKLfzN0/KicY257HPKGtq3k9MBAAAAAAAAXQ8FHQCgy5l9+6OK1TdLkuL1TZpz59907D9vbvd1xl52psZedmaq46GNEtGYnj/iStWv3CRJWvaXl3XO4kcUzsvyORkAAAAAAADgL/agAwB0UXa7f6D7qV26XnXLNsgmPNmEp+ayapV/uMTvWAAAAAAAAIDvKOgAAF3OxBu+omBGRJIUyIzogOu/7HMi7I30/oVy08KSMZIk4zrK3nZvQAAAAAAAAKCXYolLAECXUzhltM5d+ZiqF69V7thBLInYTYVzM3X8s3fog6vukxeNa/Lt31DWMAo6AAAAAAAAgIIOANAlhfOzVXLYOL9jYB/1O26yzp77B79jAAAAAAAAAF0KS1wCAAAAAAAAAAAAnYiCDgAAAAAAAAAAAOhEFHQAAAAAAAAAAABAJ6KgAwAAAAAAAAAAADoRBR0AAAAAAAAAAADQiSjoAAAAAAAAAAAAgE5EQQcA6BTx5qhqlqxVvKnF7ygAAAAAAAAA4KuA3wEAAD1f7bL1euGoq9S0sULhgmyd/Prdyh8/zO9YAAAAAAAAAOALZtABADrc7DseVfPmKklStLpes278o8+JgJ4l7pWrKT5DzfE5sjbqdxwAAAAAAADsATPoAAAdzmuJSTb52FqrREvM30BdTLS2Qe9/9zcq+2CR+p1woKbefanccMjvWOgmErZWjfE3thmXKyN4nI+JAAAAAAAAsCfMoAMAdLhxV50rNxKUJDnBgCb88Is+J+paZl73oFY8/rpql67X4t89p7k/edzvSOhGEt5mJRvw5K+ErZC1cZ9TAQAAAAAAYHeYQQcA6HBFU8fo85/8RZVzlit3/6HKHFjsd6QupXL2ctmElxxYqWrBSn8DoVtxTO42IyOjdEmuT2kAAAAAAADQFhR0AIBOkd6vUOn9Cv2O0SUNOuMwlc9YLOM6sglPA06e6nckdCMBp1AR9yBFvU9kFFEkMEnGGL9jAQAAAAAAYDco6AAA8NmE//clhQuyVT5zsfoeM1HDLjje70joZkLuUIXcoX7HAAAAAAAAQBtR0AEA4DPjOBpzyRnSJWf4HQUAAAAAAABAJ3D8DgAAAAAAAAAAAAD0JhR0AAAAAAAAAAAAQCdiiUsAQIeqnLNcdas2qc8R4xXOz/Y7Dnq4mqXrNPcnj8nGE9r/mvOUf8BwvyMBAAAAAAAAO6CgAwB0mMUPPKvpl/9akhQpztUZMx9Q5sBin1Ohp4o3NuuFI7+vlvIaSdKaf7+rLyz7qyJFuf4GAwAAAAAAAD6DJS4BAB3m41v/0vq4paJWy/70oo9p0NPVLluv5tIq2YQnm/AUq2tS5dwVfscCAAAAAAAAdkBBBwDoMIG0kGSMJMlaKzct7HMi9CTx5qi8WLx1nDW0r4I5GTKOIzlGbiSk3LGDfEwIAAAAAAAA7BwFHQCgwxz24NVy00KSpMIDR2nMJWf4nAg9xayb/qRHM0/Vo1mn65OHn5ckBbPSdfKrd6nv8ZPV56gDdMILP1F6v0KfkwIAAAAAAAA7Yg86AECH6X/iFH2p9Cm1lNcqY2BRcmYTsI/KP1yiOXf+VZLkRWN675JfadDZhytSkKPCA0fppBd/5nNCAAAAAAAAYPco6AAAHSqYkaZgRprfMdCDtFTUbje2nqdYbaMiBTk+JQIAAAAAAADah6kMAACgWyk5coJy9xvcOu5/8kHKHNLHx0QAAAAAAABA+zCDDgAAdCuBtLBOn/5brX7mXbmRkAafNU3GGL9jAQAAAAAAAG1GQQcAALqdYFa6Rnz1BL9jAAAAAAAAAHul3UtcVlRU6Ac/+IEOOeQQTZo0SRdffLGWL1/eEdkAAAAAAAAAAACAHqfdBd3ll1+u1atX66GHHtKTTz6pSCSiiy66SE1NTR2RDwAAAAAAAAAAAOhR2lXQ1dTUqH///rrjjjs0YcIEDR8+XJdddpk2b96spUuXdlRGAAAAAAAAAAAAoMdo1x50OTk5uvvuu1vHlZWVeuSRR9SnTx+NGDEi5eEAAAAAAAAAAACArqS6ulr33HOP3nzzTdXX12v06NG65pprNGXKlDZfo10F3bZuuukmPfHEEwqFQnrggQeUnp6+t5cCAPRy8aYWuZGQjDF+RwEAAAAAAACA3br66qtVVlame+65RwUFBXr00Uf1zW9+U08//bSGDRvWpmu0ew+6T1144YV66qmndPrpp+vyyy/XggUL9vZSAIBexosntPKfb2nRA//Wf4+5Wo9mnKp/DDhfFR+zXDIAAAAAAACArmv16tV69913dcstt2jKlCkaOnSobrrpJhUXF+u5555r83X2uqAbMWKE9t9/f915553q37+//vrXv+7tpQAAvcybX7pdb55/m96//Dfa9NYcSVLTxgq9cMSVql602ud0AAAAAAAAALBzeXl5euihhzR+/PjW54wxMsaotra2zddp1xKXlZWVmj59uk466SQFAslTHcfRiBEjtHnz5vZcCgDQSzWXVWv1U//b6Wvxxha9ds7N+vyiR3Z7jfWvfKiNr89W4YEjNfjzR7I0JgAAAAAAAIB22bhxo4477rhdvv7aa6/t9Pns7GwdddRR2z330ksvafXq1br++uvbfP92zaArLy/X1VdfrenTp7c+F4vFtHDhQg0fPrw9lwIA9FKBjIicUHCXr9ctWy9r7S5fX/Wv/+nlk36o+Xf9Q2+cd5sW/uZfHRETAAAAAAAAAPZo1qxZ+n//7//pxBNP1NFHH93m89o1g27UqFE68sgjdccdd+iOO+5QTk6OHnzwQdXW1uqiiy5qZ2QAQG8USI/oiD//UO988xdKNEc16HPTtPbZ92QlyVoNOmvabmfErfrnm5JjZBOeJGnFY69p3JWf75TsAAAAAAAAAHqGvn377nKWXFu9+uqruvbaazV58mTddddd7Tq3XQWdJN1zzz26++67ddVVV6murk5TpkzR3/72N/Xr16+9lwIA9FLDzj9GQ75wpGzCkxsKqvzDJVrx2GtK61eosd89a7fnZg7pKyMjKyvjOsoe0b9zQgMAAAAAAADAFn/9619155136uSTT9bPfvYzhUKhdp3f7oIuKytLt9xyi2655Zb2ngoA6KaiiSatrPtYLYlG9UkfoeK0Ift8Tcd1JdeVJBVOGa3CKaPbdN4BN16guhUbtOHVj1QweZSm/vKyfc4CAAAAAAAAAG312GOP6fbbb9dXv/pV3XDDDbtdEWxX2l3QAQB6n/mVb6o2VibJqrJlvUJOmnLDJb5kCWak6Zh//MiXewMAAAAAAADo3VauXKkf//jHOuGEE/Sd73xH5eXlra9FIhFlZWW16ToUdACAPfq0nGsdR8t8K+hSxXqeaj5Zp1BOhtL7FvgdBwAAAAAAAEA38NJLLykWi+mVV17RK6+8st1rZ599tn7605+26ToUdACAPcoOFqo2Vq5PS7rsUJG/gfZRIhrTK6ddr42vzZKM0SG/+a7GXn6W37EAAAAAAAAAdHGXXHKJLrnkkn2+jpOCLACAHm7//GPUN32E8sL9tF/eUd1+9tyaf7+XLOckyVp9cPX9SrRE/Q3VTax7cYbm3fWEKmYv8zsKAAAAAAAA0G0xgw4AsEchN02jcw/zO0bKeLH4dmOb8GTtLg5GqwW/ekozrr5fMkbGdXTK63er5PDxfscCAAAAAAAAuh1m0AEAep1BZx6m/IkjWscTb/qaApGQj4m6h8UPPpd8YK1krZY9+sruTwAAAAAAAACwU8ygAwD0OsGMNJ0+/V5tnr5Q4fws5U8Y7neklPESCc257VGt/c/7yp88QlPvvlSh7IyUXDujf6Hqlq3fMuPQKr1fYUquCwAAAAAAAPQ2FHQAgF7JDYfU9+iJfsdIuUW/fUazb39UklQ5d7ls3NMRf7ouJdc+7HdX6bWzb1LNorXqf/JB2v/ac1NyXQAAAAAAAKC3oaADAKAHqfh4qYzrJGe5JTyVz1ycsmtnj+ivs+f9UdZaGWNSdl0AAAAAAACgt2EPOgAAepB+x06WTXiSYyRj1O/EKSm/B+UcAAAAAAAAsG+YQQcAvczyT8p0/13/U011s446YYQu+OZBchwKl55i+FdPkE14Wv/yTOWNH6bxPzjf70gAAAAAAAAAPoOCDgB6md/+/G1VVTTKWunV55do1NhiHXz4EL9jIUWMMRr59ZM18usn+x0FAAAAAAAAwC6wxCUA9CLWWtVUNcna5NgYqbK80d9QAAAAAAAAANDLUNABQC9ijNG0Y4ZteSyFwgFNPnigz6nQncSbWvTG+bfpLxmn6rmDL1P96lK/IwEAAAAAAADdDktcAkAv8/VLD9GYcX1UXdWoKYcOUknfLL8joRuZf/c/teqptyXPqmLWUr13yT068b8/8zsWAHRLtqlcqlwspRXK5I/xOw4AAAAAoBNR0AFAL+O4TussOqC9GtZsljFGVlY24aluFTPoAGBv2PqNsrPukbxY8omhp8sMPt7fUAAAAACATsMSlwAAoM2GfvEYyVoZN/ktxMiLTvI5EfaFtVZxLyr76caUADqN3fyh5CW2jte/5WMaAAAAAEBnYwYdAABos37HTtKp7/xGG175SLnjhmjw2Yf7HQl7Kea1aG7FK6qLVSjkpOuAguOVEczzOxbQa5hgpqy8T0dSkCWnAQAAAKA3oaADgE5ibVxqmC7F1ktuvpR5hIyT5ncsoN2KD9lPxYfs53cM7KM1dfNUF6uUJEW9Ji2tmaGJhcyIBDpNv2lS1VKpcqEUypIZ8yW/EwEAAAAAOhEFHQB0luYFUnRl8nG8VGr4QMo62tdIAHqvuI1uM7KKeS2+ZQF6I+OGZCZcLOvFJePKGON3JAAAAABAJ2IPOgDoLIk6SZ+++WYlr87PNL1OoiWqyrnL1VLF/++AJPVNHymjrYXAwExmRQJ+ME6Acg4AAAAAeiFm0AFAZwkNlqIrlCzprBQa6nciX6x59j198sf/Kr1vgSbfdpEiRbkdfs/GDeV6/vArVb9qk9y0kI5/7sfqd+ykDr8v0JVlh4p0UPGZqomWKiOQp+xQod+RAAAAAAAAeg0KOgDoJCY0UDbreCm2MbkHXWiI35E6XdkHi/Ta2TdJMjKOUeXc5Tr93Xs7/L4LfvWUGtZuliQlmmOaee0DOnPWQx1+X6CrSw9kKz2Q7XcMAAAAAACAXoeCDgA6kQn2k4L9/I7hm9J35ycfWCubsCr7YJGs58k4Hbviso0nth3JiyV2eSwAAAAAAAAAdDT2oAMAdJqiqWMkm3xsXEcFk0Z2eDknSWO/e5bC+dlb7utq8u1f7/B7AgAAAAAAAMCuMIMOANBpSg4fr6Meu0FLfv+80vsV6qCffbtT7ps1rJ/OWfJnVcxaquzh/ZQ5uKRT7gsAAAAAAAAAO0NBBwDoVMO+eKyGffHYTr9vODdT/Y6d1On3BQAAAAAAAIDPYolLAAAAAAAAAAAAoBNR0AFAN2WtVc3Sdapdtt7vKAAAAAAAAACAdqCgA4BuyP7/9u48TK6qwPv479zae9+7s3dWEkL2hEDYQiKIbIqMCwOo8wIjOsrrIIgMCCijg69BNkFgAFHZkUUEJLIICEJICEnIQvaEbJ1O72t1Lfe+fzQpaMjSna6u21X9/TyPz9Pn1l1+ccZOqn51znEc/fPim/TkYd/UE+O+obe+d4scx3E7Fg4g2tKuV77yUz1Y/CX97dQfK1zb6HYkAAAAAAAAAC6hoAOANFS/crPW/e9zifEHdzyjxg8+dDFR32rdsUcvffFqPTXpAq345cNpWUYu++kf9OFTbyhS36ydL76rxZfd6XYkAAAAAAAAAC7xuh0AANBzTtz+zDE7FnchSWq8ds5/q/qt1XLitt698h7ljhqskV85we1YPdK0aWeiWHTitprWszQpAAAAAAAAMFAxgw4A0lDRlNGq/ERBNfLrJ6rwiJEuJupbdSs2JUpJ47FUv2KTy4l6buRXTpAcR8bb+VdvyZHj1bRxp8upAAAAAAAAALiBGXQAkIaMMZr78NWq+eFXJUklsw6TMcblVH1n6KmztfmxV2WMkWPbGnzSDLcj9dior8+TLy9bOxYu1tYn/6HVNz+h1bc8oaNv/4HGX3yG2/EAAAAAAAAApBAFHQCkKWNZKj1yvNsxUuLYey9XwYQRatlcpcqvnqCK4ye7HemQDDt1tpo37VLbzprOA460+Ed3UdABAAAAAAAAAwwFHQAgJRzb1po7nlHd0vUaNH+aRv3r/G7P+vOGApr6k/P7OGFqGMtIzqfGAAAAAAAAAAYUCjoAQEosu/4BLfvp72U8ltbf/4LsaExjv3WK27FSbsz5J2ndPc+rbtkGGcvS7Jv/w+1IAAAAAAAAAFKMgg4AkBLbnv2nJMmJ25JltGPh4gFZ0Plys3TGottVv2qLQmUFyhpc4nYkAAAAAAAAAClmuR0AADAwFE0dI+P5+K+dgokjXUzjLsvnVfHUMZRzAAAAAAAAwADFDDoAQEoceeN3ZHdEtWfxWg05eaYm/ehrSbu34zja+uQ/1LJ1t4afOUd5Y4Yk7d4AAAAAAAAAkGwUdACAlPDnZev4P1zZJ/decsXdWrngMckYLb3mdzpzyZ0qGD+8T54FAAAAAAAAAL3FEpcAgLS39q5nO39wHNkdUW15/DV3AwHoF2J2VLXhHWqJ1rsdBQAAAAAAoAtm0AEA0l5oUJGirWHJtuXEbWUNKnI7EgCXReJhvVvzrDrirZKkMXmzNDTncJdTAQAAAAAAdGIGHQAg7Z3wwH8pe2iJjMfS6PM+pzHfOmWf5zm2rfX3v6Cl1/xONUvXpThl32jauFPr739BNe9mxp8HSJbd7RsT5ZwkbW5+z8U0AAAAAAAAXTGDDgCQ9kpmHqavbnlYjuPIGLPf8xZd+lutufVJGY+lFb98WKf/8zcqmTEuhUmTa887H+j5E34guyMqGen43/9Yo887ye1YQL9gGU+XsZFnP2cCAAAAAACkHjPoAAAZ40DlnCRtfOBFSZITtyXb0dYn/5GKWH1m7V1/kROLdw4caeWvH3c3ENCPVIRGK89XIkkyMhpXcJTLiQAAAAAAAD7GDDoAwICRW1mhusZWOfHOvepyKivcjiRJsuNxfXDHM2pYtUVDvnCkRnzxmG5d5y/MTfxsPJYCRXl9FRFIOx7Lp2klp6o93iSfFZTPCrgdCQAAAAAAIIEZdACAAeOEB69S4eRR8uVna/x3ztDY/7PvvepS7d0r79GiH/xG6+59Xq+cdY22/vnNbl03+cfnqHDyKElSqLxQs2/5Xl/GBNKOMUZZ3nzKOaSFSLxdK+v+rkW7n9KmpnflOLbbkQAAAAAAfYgZdACAASP/sGH64rt3uR3jMz7885uS07n0pvF4tP25Rd2aRRcsydeZS+5UpKFFvrwsWR722AKAdLW24S3VdmyX5OjDlpUKeLI1JHu827EAAAAAAH2EGXQAgLQTaWrVGxct0F9mf1fL/vsBOXZ6zzIoPGKkjKfzr2THjqvg8BHdvtYYo0BhLuUcAKS5llidJOejkVFrtMHFNAAAAACAvsYMOgBA2nnru7do86N/lxO3VbN4rYIl+Rp/8Rluxzpkc+66VJJUt3yThn9xjiZ870vuBgIAHFB7rEmr619Xe6xZZaFKjcmfLcv07ruPJYFh2tH2gSQjyVFRcEhSsgIAAAAA+icKOgBA2tmzaI2ceOesOeOxVLNkraT0LeiCJfma98RP3Y4BAOimNfVvqDnaOeNtZ9s6ZfuKNCT7sF7dc3T+LAW9OWqNNaokMFQlwWHJCQsAAAAA6JdY4hIA4JqOuibF2sI9vm7I52dKxkjGyInbGjRvWq9y2PG41t79rBZfcbd2/3NVr+4FAMh87fFmfbwcpbSzda3idqxX97SMpWE5EzW+YI5KQsN7mRAAAAAA0N8xgw4AkHKObevNi27U+t+9IOPz6Ji7LtXYb53S7euPvPE7CpUVqn7VFg39wpEa/a/ze5XnnR/eqTW3PinjsbTqxsf1hddvVvmcib26JwCkG8eJy1G7jEIyhn0tD6Q8NErbW1cnxq2xem1qXqqx+Ue6mAoAAAAAkE4o6AAAKbfzxXe1/ncvSJKcaFxvfvvXGvnVufJmBbt1vSfg19RrvpG0PJsffqUzS9yW8Xr04dNvUNABOCDHcdQQqZLtxFUQGCRPmhdacadJbdG/y1GHjILK9p0oy+S6HavfGp03Uw2RKrVE6xLHmiM1LiYCAAAAgOSKhY0+XORzO0afiYWN3P7TscQlACDlIk1tXcZONK54R9SlNFLe2CEyns6/Ep1YXLmjB7uWBUB6+KDhTS2v/Zver3tZy2r+qrgTdztSr3TE3pejiCTJUYc64iz3eyDGGFVkjelyrDDA3x0AAAAAgO6joAMApNzQU2Yp77BhifHYfztFgUL3Zmoc/4cfq+TI8QqW5mvC976kcRee6loWAP1fR7xNu9s3JsbN0Vo1dOxyMVHvOYrr4z3VHDlpXjimwpCs8RqbP1ulwREalTdDlbmT3Y4EAAAAAEgjLHEJAEg5X26WznznDm1/YbH8+dka/LnprubJHTVYp795m6sZAKQPax/LWRoZNXRUye8JKcub70Kq3gl4xqstVi3JlmTJ7znM7Uj9njFGQ7LHa0j2eLejAAAAAADSEAUdAPSB5s271PphtYpnjpMvO+R2nP1q3b5H2557W9lDSzX01NkyxqTs2b7cLI38ygkpex4AJIvPCmh03kxtbFoiSSoLjtKGpiVqizVI6tyfbFhOeu1j6bXKlOP7guJOgzymUJbJcjsSAAAAAAAZjYIOAJJs4wMv6h/f+n9ybFvZI8p1+lu/UVZFkduxPqN5S5Wemf7vijS0SpKOuPxrmvXLf3c5FQCkh2E5E1WRNUa2E1dteLuqw5sSr21qWqqh2Yen9EsPyWCZbFkm2+0YAAAAAAAMCOxBBwBJtviK/5Vj25Kktm17tO6e511OtG9bHntVkaa2xHjNb55yMQ0ApB+fFVDAk/WZIi7dijkAAAAAAJB6FHQAkGTG88lfrY4sT//8VRssLZBsp3NgGQWK02/PJADoD8qCI5XnK0mMx+QdSUkHAAAAAAAOqH9+agwAaWz2zf8h4/NIkvLGDtW4fz/N5UT7Nvr8kzTya3MlSYHCXJ3wwH+5GwgA0pTH8mpayRc0s/RMHV3+FQ3OHrfP8xzHUWu0XuF4a4oTAgAAAACA/oY96AAgySq/fJy+tu1Rte2sVcHhI+Tx+9yOtE+W16O5D/9Ex91/hSy/j9keANALxljK8RXu93XbiWtF7ctqiOySJI3Om6VhOYenKh4AAAAAAOhnmEEHAH0gVFao4qlj+m0590megJ9yDgD6WG14e6Kck6SNTUsUd+IuJgIAAAAAAG6ioAMAAAD6mCP7M0fkOK5kAQAAAAAA7qOgAwAAAPpYcXCYcn3FiXFl7hR5LFabBwAAAABgoOJTAQAAAKCPeYxX00q+oKZIjbyW/4D71QEAAAAAgMxHQQcAGHAa125T1esrVDR5lEpnT3A7DoABwjIeFQTK3Y4BAAAAAAD6AQo6AMCAUv3WKv117qWyozFJ0rG/+5HGfvPzLqcCAAAAAAAAMJCwBx0AYEBZ97/Py7HtxHj1LU+6mAYAAAAAAADAQERBBwAYUALFeYmfjcdSsDTfxTQAAAAAAAAABiIKOgDAgDL5ynNUPGOcJClraKlm3/I9lxMBQPLE7Ii2tazSh80rFYmH3Y4DAAAAAAD2gz3oAAAp07h2m7Y+/YZyhpdr5Nfmylip/55IoChPZ7x9u6Kt7fJmBWWMSXkGAOgL4Vir3qt5Xh12myRpZ9tazSo9Ux7L53IyAAAAAADwaRR0AICUaPjgQz0z49uKd0Ql21H126t1lIuz13zZIdeeDQDJ1hpt1NKaZxV3Yolj4XiLmqK1KgxUuJgMAAAAAADsC0tcAgBSYsufXpfdEZNsR5K0/t7nXU4EAJljZ9taxZ34Z44HPFkupAEAAAAAAAfDDDoAQEpkDy2RY9uSJGNZyhpS4nIiAHCX7cRV17FTliwVBgbJmEP/7pzHfPqf9Ubj8o9SljevdyF7wHZsbWp6V3UdO5TrK9bY/NnyWv6UPR8AAAAAgHRCQQcASInR55+k6rdWa8PvFyp7aKlOePhqtyMBQLc4TXVymmtlyitlvMnZz8124lpW84KaojWSpJLgcE0snHvI+2IOzT5cNeEP1RZrlMf4NLn4c8r3lyUla3dtb12t7a2rJUltsSZJRhMKj01pBgAAAAAA0gUFHQAgJSyPR8fcdamOuetSt6MAQLfFVrym6GO/khxbpnSoAv9+o0xWbq/v2xipTpRzklQT/lDheItC3kO7t98T1KzSMxWOt8nvCe5jRl3fa4nWf2LkqCVal/IMAAAAAACkC/agAwAAAPYj+tzdktO5PK9Ts0Oxdxcm5b77KtCsXpZqxlgKeXNcKeckqSgweG8SSVJxcKgrOQAAAAAASAfMoAMAoJvsWFzV/1wlT8CnkiPHH/JSdADSifOpobPv03oo11eiIVnjtaPtA0nSqLwZCnhCSbm3WyqyRsvIqK5jp3J8hRqaPcHtSP1e3Inpg/o3VBveppA3X0cUzVUohfsGAgAAAADcQ0EHAEA32NGYFp5yhar+vkySNO7CU3XM3T90NxSAPuc75QJFn/i15DgyhYPknXFyUu5rjNHYgtkakTtFxljyWf6k3Ndt5VmjVJ41yu0YaWN7yxrtCW+VJLXGGrS24S1NLfm8y6kAAAAAAKlAQQcA6NfsaExbn35TdkdEw790rHw57swwqXp9RaKck6R19zyvKT85XznDylzJAyA1vNPmy6o8Qk5TrazBo2V8gaTe3+8JJvV+/UFbrEmbm95T3IlqWM5EFQYGuR0pqSLxsBzZCniyen2vjnirOpcEdSQ5Csdbe31PAAAAAEB6oKADAPRbjuPopS9erR0vLJYkFUys1Bnv3CFvKLkfkHeH5d/HflE+/hoFMpET3S21LZKcuBSaIqtwlFRY7nastGA7tpbVLFTEbpfkqL5jl44s+5JC3ly3oyXFh83va1PzUknSoNAYjSuY06vljstCI7WzbZ32lnSDssYmJygAAAAAoN+z3A4AAMD+NG/alSjnJKlh1RbtfuN9V7KUH3OERv3r/MR46rXfVFZFkStZAPQdx4lJzS9L8QbJbpZa35ATb3A7VtqIxNsUsdu0d+8+R7ZaonXuhkqSSLw9Uc5J0q72DWqK7OnVPQsC5ZpRcppG5k7VxMITNTzniN7GBAAAAACkCb76DwDot/z52TKWJce2E8cCRXmuZDGWpeP/eKWm/fRb8gR8yh5a6koOAH3MbpcU63os3ix5CtxIk3b8niwFrCx1fDSDzshSji8zvsxgO/HPHIt/+v9XDkGuv1i5/uJe30eS6jt2qa5jp3K8hSoLjezV7D4AAAAAQN9iBh0AoN/YsXCxHhtxjh4s+ZJW3fQnBUvydfRvf9C5vKRlNOWq81QyY5xr+Ywxyhs9mHIOyGRWtmQVqHPJQSMZv+Tlf/PdZRlLU0o+r7LgCBUHhmpK8UkZs7xl0JujstCoxDjPV6oCf/9Z+rQ2vF3La/+mbS2rtKbhH/qwxZ0Z5wAAAACA7mEGHQCgX4i1d+iVs69TrL1Dchy988Pfqvy4STrsotM05psny7EdeYN+t2MCyHDGWHLyTpbCayTFpcA4GSvodqy0kuXN0+FFJ7gdo09MKDhWg7LGynbiKgxUyDIetyMl7Gnfor172UnS7vbNGpE72c1IAAAAAIADoKADAPQLkfpmxdrCXY61bN2tkpmHyeP3uZQKwEBkrKCUNc3tGOiHjDEqDFS4HWOfgt5c7S3nJKOsDJm5CAAAAACZiiUuASBJwjWNev1bN+jZOd/X6tuekuM4B78ICaFBxSo/bpJkjIxlKVhaoIq5U9yOBQBAWhiWc4TKQqPkNQEV+Ms1Nv8otyMBAAAAAA6AGXQAkCSvnfcL7Xp5qZy4rT1vr1bWoCJV/ktmLvHVF4wxOvmvN2jt/z6nWEtYo79xkoLF+W7HAgAgLXiMR4cXHud2DAAAAABAN1HQAUCS1CxeKyduS5KM19KexWsp6HrImxXUxP97ttsxAAAAAAAAAKBPscQlACTJ4M9Nl7EsyRg5MVuDTpzqdqSM1bpjj9677vda/osH1VHf7HYcAAAGjMaOau1q26BwrMXtKAAAAACQ1phBBwBJcuy9lyunskItm3ep8l9O0NBTjnQ7UkaKNLXq2dn/ofbd9ZLjaNPDr+iL790ty+txOxoAABlte8sabWh6R5JkGa9mlJymbF+Bu6EAAAAAIE1R0AFAkvhyQpr1y393O0bG27Nojdp21ibGDau2qGn9dhVMGOFiKgAAMt+2lpWJn20nrqq2DRqdP9PFRAAAAACQvljiEgCQVnIqKyRjOgfGyAr4FKoocjcUAGSolmidtrWsVn3HLrejoB/wWoFPjJxPjQEAAAAAPUFBBwBIK/ljh+rY+y5X1uBi5Ywo17w/XadAYa7bsQAgbcXsiDY3vad1DW+rKVKTON7QsVvv7nlWG5sWa3nt37Sj9QMXUx66mB3V9tY12taySpF42O04/Urzpp168Yz/0jMzL9a6e58/6PmHFcyR76NSLt9friHZ45OSoyVar8XVz+jNqke0qWmpHMdJyn0BAAAAoD9jiUsASKFYe4fqlm1Q1tBS5Qwr67PntO+uU7S5XbmjB8vsnW0myXEcrbn9z9rx10UqnDRKU6/9hryh9Pv2+9hvfl5jv/l5t2MAQEZ4v+4VNUaqJUm72tZrVtmZyvLmq6p9oz5Zk+xoXZu0Qqav2I4ty3z8HUTHsbW8dqGao51LI+9o/UAzS8+U1/K5FbFfefH0/1LT+h1y4rbevOhG5Y0ZoooTpuz3/Dx/ieaUf1VxJyaP8XX5N0ZvrKr7u9rjLZIcfdjyvnJ9xSoNsXQ1AAAAgMxGQQcAKdJeXa/n5nxfzZt2yXgsHf+HKzXqnHlJf87q3zytRf/3N5LjaOhpR2n+Uz+T5fVIkjbcv1CLLrlNkrRj4WJ1NLTomDv/M+kZAADpIe7E1BjZnRg7ctTQUaUsb778VvATZxoFrFDqA3ZTa7RB79e9onC8WYX+wZpYNFdey6e2WFOinJOkcLxFTZE9KgoOdjFt/2DH4mr8YFuXY3UrNh2woJMkYyx5jT+pWcIflXN7tceak3p/AAAAAOiPWOISAFJk3T3Pq2VL54egTtzWO5ffmfRnxNrCeuc/b5c+Whpq+3Nva9tzbyde3/2P92U8nb/6HdtR1avLkp4BAJA+LHkUsLIlfTwTKstbIEkannOECvzlkqSQN09jC45KWa5IvF114Z3qiLd26/x1jW9/VPJI9ZGd2t66WpLk9wRl1HWWV8CTldywaSqsFgVml0mW6fyPx6jomHGuZCkNVX70k5GRpeLgEFdyAAAAAEAqMYMOAFKkcxko51Pj5HJsR47ddd8WOxJL/Fx61AStv/+FzudblsqPnZT0DACA9GGM0eTi+VrX+LYidlhDsw9XQaCzlPNafk0t+bwcx5YxqfteX3O0TstqXlDcicrI0uTiz6kwMOiA10Tibfr471ijSLxdkuSzgppQeLzWN74t27E1Km+6sn0FfZo/XUTi7Sq/b54ab3tf8Zp25Xx1jHImuTOzcHzBMcr3l6kj3qayUKWyfYWu5AAAAACAVKKgA4AUGXfRaVp//wtqWr9DxuvRkTd+J+nP8OWENOnyr+n9//eIJKlo2hgNO212lwzR5jZte36RiiaN0vSf/5+kZwAAuMdxHNV17FDEbldxYKj8noMvS5ntK9S0ki/s9/VUlnOStL1lleJO55dLHNna2rzioAXdkOwJ2tD0jqTOOVgVWaMTr5WFKlWWmKHlvnC8VdtaVslxbA3NmaAsb74rOXL9JcotLpXn6hmdY1+xsl3KYhlPv9/fEAAAAACSjYIOAFIkWJKvLy6/R/Xvb1L2kBJlDS7pk+fMvOEiVX7lBEUaWlR+7BHyBD7eJ8YYoyN++FUd8cOv9smzAQDu2ti0JLG8o88KambpGWm3pKPpsgq/6daM86E5E5Tly1dbtFGFgYoez8ByHEdbW1aoqm2Dgp4cHVYwRyFvbg+TH1zcieu9Pc+rw+6c4Vfdvlmzy78snxVI+rMOxmO8mlZyqqrbN8nIUnloZMrLWAAAAAAYyCjoACCFvEG/Smf1/TfES2a4s4cMAMA9juNoR+uaxDhqh7WnfauG5kxwMVXPDc+dlJgF6DFejcqd0a3rigKDVRToXKLRcWztbFuntliTSoLDDjoDb094q7Y0L5PUOcNtVf2rmll6Rq/+HPvSHmtUh92WGMeciFqidQfN11d8lp+ZawAAAADgEgo6AAAAIEN4jF8xpyMxdmNmVm9lefM0u/zLao81K+jJkdfy9fgeG5qWfFRWGu1oXaMpxScfsARrizVK2rtXrKO2WNOhxj+ggCdHlvHK/mgJTyNLIW9enzwLAAAAANC/sYYJAAAAkAGMMZpQeJw8prPQKg1WqrQf7b3WEx7jVY6v8JDKOUna077lo58cGRnVhrcd8Py9M+86SzqpJDDskJ57MD7Lr8lF85XrK1GOr0hHFJ2ooCe7T54FAAAAAOjfmEEHACnmOI6W/eyP2vTwy8obO1TH3PWffbYfHQAMRLYTV1Nkj7yWXzm+IrfjpFRxcIiOrfi6bCcuzyGWW5kgy5uvSCQsyZEjRyFv/gHPz/OXamrx51XdvllBT06fLgtaEKjQjNLT+uz+AAAAAID0QEEHACm28YGXtOynv5ckNW/cqdfO+x994ZUbXU4FAJkhbsf0Xu0LaonWSpJG5EzWyLxpLqdKLWMseUx6LJSxrWWVPmx5Xx7j02EFc5K2F9v4wmP1Qf2baos1qjQ0QoOzxh70moJAuQoC5Ul5PgAAAABg4Ljrrrv0xhtv6I9//GOPrkuPd+4AkEHq398k4+n89evEbdW/v8nlRACQOWo7tiXKOUna2rJCcTvqYiLsT2NkjzY2LVHU7lA43qKVdX+X7cSTcu+gJ1tTS07WnIqvaGz+kTJpUlj2JduJa0frB9rc9J5aow1uxwEAAACAjPDggw/q5ptvPqRreacKACk25JQj5dh2Z0lnjIadcbTbkQAgY5jP/PPWSMa4kgUHFo63dBnHnahidsSlNJlvTf0bWt+4SFtb3te7Nc+qLdbkdiQAAAAASFu7d+/WxRdfrAULFqiysvKQ7kFBBwCSmjfv0ubHXlXj2m19/qzB86bppOf+R2O/dYpm/PwCzfntD/r8mQAwUBQHh6nQ//EyiWPyZsljWNW9Pyr0V8hr/JI6C9R8f7l8VtDdUBnKcRztCW/ZO5LtxFUb3u5mJAAAAABIa6tWrZLP59MzzzyjKVOmHNI9+LQCwIC3+5+r9ML8H8ruiMp4PZr/9PUadursPn3m0FOO1NBTjuzTZwDAQGQZS5OLT1JbrFFey6+AJ8vtSNgPvyekGaVnaHf7BnmMT4OzDpPJoNmOteEd2tq8TMZ4NCpvhvL9pa5lMcYoYGWrw25NHAt5cvZ5blusSR/Uv6FwvEUVWWM0MndaRv3fBQAAAAD22rVrl+bPn7/f119++eX9vjZv3jzNmzevV89nBh2AAW/1rU/KiXbueePEba1c8KjLiQAAvWGMUbavgHIuDYS8OarMnaphORPlsTLnu4PhWItW1r2ipmiNGiO7taL2RcVc3gvxiKITleXNl9f4NTxnkoqDw/Z53uq619QUrVHEbteHLe+run1zipMCAAAAwMCQOe+CAeAQ+XJCe1fXkrGMfLl8oNsX7GhM7//qUdUt36jB86dr3EWn8Y18AMgQHfE21Ya3y+8JqTgwdMD/fm+LNcqRnRjHnag64i3yWoWuZcr1F+vIsi8d9Ly2eJMk56ORUXucveoAAAAAZKZBgwYdcJZcX6OgAzDgTb3mfFW9ukzNm3YpWFaomb/8d7cjZaR3r7pXK298XDLSlsdfk7GMxl14mtuxAAC9FI63akn1M4o5EUnSkOwJGps/sJdxzvEVy2N8ijsxSVLACinozXM5VfeUBUeoqn2jJCMjqTiw75l2AAAAAIDeoaADMODlDC/Xlz/4vdqr6hQqL5Tl69+/GmPhiDY98KKirWGNOmeeQmXufRu/J3b8bYnkOJIjGcvSrleXU9ABQAbY0741Uc5J0s7WtRqTN2tAz6Lze4KaXvIFbWtdI0uWhuccIY/xuB2rW8YVzFGOr1jheItKQ5XK9Re7HQkAAAAAMlL//hQaAFLE8nqUPbTU7RgH5TiOXj7zKu18aalkjFYueExfev9eBQpy3I52UKWzJ6hh1RY5cVuOY6t42hi3IwEAksBnBbqMvZa/2+Wc7dhqidbJZ/kVSpMZZt2V7SvU+II5bsfoMctYGpozwe0YAAAAAJDxKOgAII2076rtLOckyXHUtqNGu155T5VfPs7dYN1w5I3fkfFYqn13nYZ8fpYO/8HZbkcCACRBWWik6jp2qLp9s7zGr8MLj+/WdXEnpuU1C9UUrZEkjc6bqWE5E/syKgAAAAAA/QYFHQCkEV9+tjxBv+Lhj5cSyxqcHktP+XJCmnPHD9yOAQBIMstYOrzweB1WcIwsWd2ePVfT/mGinJOkTU3vakj2eFlpshQkAAAAAACSdMMNNxzSdVaScwAA+pAvO6QTHr5ageI8eUJ+TfvZv6nsqMPdjgUAgDzGM6D3nespx3HUHK1Va7TB7SgAAAAAABcwgw4A0syILx6jEV88xu0YAAD0SklouHJbS9T80Sy6UXkzBszsOcextbLuVdV2bJMkDcmeoLH5R7qcCgAAAACQShR0AAAAAFLOY7yaVvIFtUTr5LMCCnlz3Y6UMo2R6kQ5J0k7WtdoWM5EBT3ZLqYCAAAAAKQSS1wCgEtq31uvZ2ZerMdGfF0rb3zM7TgAAKScZSzl+UsGVDm3PywOCgAAAAADCwUdALjAcRy9dMZVqlu+Ua3b9mjx5Xdp58tL3Y4FAABSIN9fppLgsMR4aPbhCjB7DgAAAAAGFJa4BAAXxDuiattZ2+VY07rtGjx/ukuJAABAqhhjaWLhiWqN1cvIo2xfvtuRAAAAAAApxgw6AHCBN+jX4JNnSpaR8ViyAj5teeJ1PXv097TxoZfdjtcn7GhM6+9/QStvfEyt2/e4HQcAkIbqO6q0aPeTerPqUW1vWeN2nF4xxijHV0Q5BwAAAAADFDPoAMAl85/8qVbf9pTaqxu09YnXVfXacjlxW3sWrVHuqEEqO+pwtyMm1avn/lxb//S6ZBmt+J+H9aX371HWoGK3YwEA0oTtxLWy7hXFnagkaUPTO8rzlyjPX+pyMgAAAAAAeo4ZdACQJHYsrt1vvK+apevkOM5Bz/dmBTX5inM047//j1o/rJYTtxOv1S3b2JdRUy7a2t5ZzkmS7aijrknb//qOu6EAAGklakcS5dxe4XiLS2kAAAAAAOgdCjoASAI7GtPCky7T88f/QH+Z+R0t+sFvun2tNxRQyazDZDyWjGXJeD0qO2ZiH6ZNPU/QL19+tmRM4lj2kBIXEwEA0o3fCirPV/bRyMhr/CrwV7iaCQAAAACAQ9Xjgq6hoUHXXHONjj/+eE2fPl3nnHOOlixZ0hfZACBt7HrlPVW9tiIxXnPb02rfXdft60967n80/rtf1MivzdXnF/5SRZNG9UVM11gej+b96TqFygvlCfo16Udf79yDDwCAbjLGaHLx5zQqb4ZG5EzSjNLT5feE3I4FAAAAAMAh6fEedJdeeqn27NmjX//61youLtYf//hHXXDBBXrqqac0alRmfaAMAN1lvJ7PHvN89tj+BEvyddQt3zvk5zdt2KHGddtVOuswBUsLDvk+fWnw/On6+s7H3Y4BAEhjXsun4TlHuB2j32mLNaq6fYt8VlCDssbIMt3/NwgAAAAAwB09mkG3detWvfnmm7ruuus0c+ZMjRw5Uj/5yU9UVlamv/zlL32VEQD6vUEnTtWIs49LjKf97N8ULMlPybO3PPG6nhz/Lb10+n/pifHfVOPabSl5LgAgM0TiYa1teEsral9SdfsWt+Ogh9pjzVqy51ltaV6u9Y1va039P9yOBAAAAADohh7NoCssLNTdd9+tSZMmJY4ZY2SMUVNTU9LDAUC6MJalEx+7Vk3rtsuTFVDOsLKDX5Qk7133ezm2LUmKNrdrze1/1lG3HvpsvGRzHEdyHBmLbU8BoD9aVf+qGiPVkhzVdeyQ3wqqIJAZe7vF7ahqwttkGY+Kg8Nkmcz7u6iuY4dsJ5YY7wlvle3YGflnBQAAAIBM0qN3bXl5eTrhhBPk9/sTxxYuXKitW7fquOOOO8CVAJD5jDHKP2xYSss5SfKE/JJlOgeOI0/Ql9LnH8i2597WQyVf0u+Dp2jx5Xd1lnUAgH6lKbJH0se/nxsje9wLk0RxJ66lNX/VmoZ/aFX9q1pZ90pG/j0U8GR3GfutkIzMQa/riLeqNrxd4XhrX0UDAAAAABxAr75WuXTpUl155ZU6+eSTNXfu3CRFAgD0xOxff1e+7KAkKWfkIE289CsuJ+pkR2N69evXK9LQIicW18obH9POF991OxYA4FPy/CXSJwqdPH+pe2GSqDGyW62x+sS4rmOHwvFmFxP1jeLAUA3PmSSP8SnkydURRSfKmAMXdI0d1Vq0+ym9X/ey3tn9lBo7qlOUFgAAAACwV4+WuPykl156SZdddpmmT5+uBQsWJDMTAKAHyo+dpK/teFxtO2uUO3KQLN8h/2pPqng4olhruMux9qo6l9IAAPZnYuGJ2tS8VB3xVlWERqswQ5a39JnAZ455jH8fZ6Y3Y4xG5U3XqLzp3b7mw5aVshWXJNmK68OW9zUpML+vIgIAAAAA9uGQZtA98MAD+v73v68TTzxRd955pwKBz775BQCkji8npPxxw/pNOSdJvtwsVX7lhM6BkULlhRr6hSPdDQUA+Ay/J6jxBXM0pfgklWeNcjtO0uT6izU8p3PvbCOjsflHye8Jupyqf7CMRx/PmjQfjQEAAAAAqdTjT3IfeughXX/99Tr//PN11VVXHXT5FABA/xdr79D6372gWGtYo8/7nLIGFSflvic8eJWGf/EYReqbNeLs4xUsLUjKfQEA6I5RedM1ImeyjKGE+qTK3ClqiFQpaoflswKqzJ3qdiQAAAAAGHB6VNBt3rxZv/jFL3TSSSfp29/+tmpqahKvBYNB5ebmJj0gAKBnHMfR5kf/rtql6zVo3jQNPeXAs9Ycx9GLp/5YVa+vkIzRqpv+pLNW3adAYe9/p1tej0b/K0tmAQDc47H6z+zy/iLbV6Cjys9WONaqoDdbHsN/RwAAAACQaj16J7Zw4UJFo1G9+OKLevHFF7u8dtZZZ+mGG25IajgAQM+t+vXjWnz5XTIeSysXPKYTH79WlWcfv9/z23bWqOq1FZ0Dx1F7VZ12/X2ZKr98XIoSAwCAZHEcW5ub31NN+4fK9hVpXMFR8ln72o/Pq2xfvgsJAQAAAABSDwu6iy++WBdffHFfZQEAJMGmR16RJDlxW7KMtjzx+gELOn9Bjjwhv+LhiOR0HsseVpqKqAAAIMl2tK7Vhy0rJUlt8WapwdHEornuhgIAAAAAfIbldgAAwP61bt+jd6+6V0t/8ju1VdV165q8sUNlPB//es8dNfiA5/uyQzrx0WsUKi+SLzekmTdcpNJZ43uVGwAAuKMlVi9p7z7hjlqi3fv3AwAAAAAgtdhsAAD6qWhLu549+ntq/6iY2/jQSzpr1e/kDfoPeN1Rt3xPHXXNql26XkNOmqHBJ03Xhj++qIq5U5QzrGyf1ww7/Wh9fefjSf8zAACA1CoKDFZV23p1lnSOioPD3I4EAAAAANgHCjoA6Kdq31uvth01iXHL5io1rNqikhnjDnhdsLRAn3/hl5KkD+78i1448YeSJG92UKe/fbsKJ1b2WWYAAOCuslClJKkuvEPZvgINyZ7gbiAAAAAAwD6xxCUA9FM5lRUyXk/nwBhZfm+P94Z7//89kvg5Ho5o/b3PJzMiAADoh8pClRpfeIyG5UyUZXjLBwAAAAD9Ee/WAKAXos1t2vrUG6p6bbkcx0nqvXOGlWnuw1crd8wQ5Y0donl/uk6hssIe3cNfmCNZH/2qdxz5C3KSmhEAAKSe4zj6sGWl3t3zrNbU/0NRu8PtSAAAAACAHmKJSwA4RJHGFj0z6ztq3rBTknT4D87W7F9/N6nPqDz7eFWeffwhXz/nzv/Ui6deqY7aJpXMnqDDf3B2EtMBAAA37G7fpE1N70qSmqN1itkRTSqe73IqAAAAAEBPUNABwCH68M//TJRzkrT6lic14+cXyBsKuJiqq9JZ4/X1XX9SpLFFgaI8GWPcjgQAAHqpJVorIyNHjiRHzdFatyMBAAAAAHqIJS4B4BD5crO6jC2/V9bePeP6EcvrUbA4n3IOAIAMURAY9FE516kwMNjFNAAAAACAQ0FBBwCHaNiZR2vEv3QuP2l8Hh37vz+U5WNiMgAA6FslwWE6vPB4lQYrNSJnssYVHOV2pAOK2VFF4mG3YwAAAABAv8InyQBwiCyPR/Meu1bt1fXyZgXlywm5HQkAAAwQZaGRKguNdDvGQe1sXaf1jW/LkaPy0GiNLziGWf0AAAAAIGbQAUCvhcoKKecAAAA+JW5HE+WcJO1u36j6jp0HuQoAAAAABgYKOgAAAABA0tmyu+yVJ0kxJ+pSGgAAAADoXyjoAAAAAACHJBJv17qGt7Wy7lXVhnd0ec1nBTQoNCYxzvLmqygwJNURAQAAAKBfYg86AAAAAMAheb/uZTVH6yQ5qglv1YyS05XrL068Pq5gjkqzRipuR1UUGCyP5XMvLAAAAAD0IxR0AAAAAIAesx1bzdHaLscaI9VdCjpjjIoCg1MdDQAAAAD6PZa4BAAAAAD0mGUsZXsLJJnEsU+WcwAAAACA/WMGHQAAAADgkEwq/pw2Ni5RxG7X4OzDlO8vczsSAAAAAKQFCjoA6AN2LK53/+sebX9+kYqnj9VRt31f/vwct2MBAAAkVdCTrYlFJ7gdAwAAAADSDgUdgAGjoa5NK5ftUnFptiZMqujymuM4qnptudqr6jTk5JkKFOX16lmrbn5CK298XHIcNa7dJlmWjr//il7dEwAADAzhWIvWNrylcLxZ5VmjNSJnsowxB78QAAAAAJA2KOgADAg11S265tLn1NoSkSR96euTddbXpyReX3r1fVrxPw9JkrIGF+vMpXcpVFZ4yM+rX7FRxjJy4o6cuK2699b37g8AAAAGjFX1r6k5WivJ0ZbmZcry5qksNLLLOXE7Kst4ZAzbigMAAABAOuLdHIAB4a3XN6utNZIYv/Dn1YmfHdvWygWPJcZtu2q1+bHXevW8IZ+fJSduy3gsyUhDTz2qV/cDAAADR1usUZLz0cioNdqQeM124lpZ94r+UfWQ3qx6VPUdVW5EBAAAAAD0EjPoAAwI2TkBOR99zmWMlJ0d+PhFY+TNCSrS0NL5WZgj+fOze/W80ed+TpK086V3VTR5tCZ8/6xe3Q8AAAwcxcGhqm7fLMlIclQUHJJ4rapto2rC2yRJMSeiD+rf0NEV/+JOUAAAAADAIaOgAzAgHDd/tJYt2a7lS3YoGPLpov87J/GaMUbH/e4KvXrO9Yq3RzTsjKM16usn9vqZo8/9XKKoAwAA6K7DCo5RtrdQ4XiLykKVyveXJV6L2h3aW9xJUszpcCckAAAAAKBXKOgADAg+n0eXXj1P7W0R+QNeeTxdV/gdfuYcnVv3Z0Vb2hUszncpJQAAgOQxHo3InbTP18pDI7WtZaViTufS3UOzJ6YyGgAAAAAgSSjoAAwooSz/fl/zBPzyBPb/OgAAgNuC3hzNKvui6jp2KODJVqF/kNuRAAAAAACHgIIOAAAAANJIwJOlQVlj3Y4BAAAAAOgFCjoAAAAAgJqjddrVuk5ey69hORPlswJuRwIAAACAjEVBBwAAAAADXHusRe/VPC/bsSVJ9R27NL3kVBljXE4GAAAAAJmJgg4AAAAABrjGyG7ZTjwxbo7WKOZE5DPMogMAAAAGonDY1j9faXE7Rp8JV9ryuZyBgg4AAAAABrgsb/4nRkY+KyCvcfvtKgAAAABkLsvtAAAAAAAAd+X5S3RYwRxlefOV5yvR5OKTZAxvFwEAAACgrzCDDgAAAACgQVljNShrrNsxAAAAAGBA4CuRAAAAAAAAAAAAQApR0AEAAAAAAAAAAAApREEHAAAAAAAAAAAApBAFHQAAAAAAAAAAAJBCXrcDAAAAAEB3xZ2YtjYvV2u0UcXBoRqUNVbGGLdjAQAAAADQIxR0AAAAANLGuoa3tbt9oySptmObPMar8qxRLqfq38KxFu1q2yCP5dXgrMPktXxuRwIAAACAAY+CDgAAAEDaaIhUJX42MmqMVFPQHUAkHtaSPc8q5kQkOapp36ppJacy6xAAAAAAXEZBBwAAACBt5PvKVB3fIsmRI0e5/hK3I/VrjZHdijkdiXFTtEYRu00BT/Z+r2mO1Gpt4z8VtTs0LGeihmZPSEVUAAAAABhQKOgAAAAApI1xBUfJ2+RXa6xeJcHhqgiNdjtSvxb05HQZW8YrrxXY7/mO42hF3UuK2h2SHG1ofEc53iIVBMr7OCkAAAAADCwUdAAAAADShtfya1zBUW7HSBu5/mKNzZ+tLc3L5TFeHVYwRx6z/7eBcSemqB3ucqw91kRBBwAAAABJRkEHAAAAABlsSPZ4Dcke361zvZZP+f5yNUZ2SzKyjKWCQEXfBgQAAACAAYiCDgAAAACgjnirWqONGp8/R9XhLYraHarIGqOQN9ftaAAAAACQcSjoAAAAAGCAa+io0oral2QrLo/xamrxKcr1F7sdCwAAAAAyluV2AAAAAACAu7Y0r5CtuCQp7sS1rXWVy4kAAAAAILNR0AEAAADAAGcZS5JJjA1vFQEAAACgT/GuCwAAAAAGuJF50+Q1PkmSzwpoRO4klxMBAAAAQGZjDzoAAAAAGOByfcU6qvxfFI63KOTNlcfwVhEAAAAA+hLvugAAAAAA8lo+5ViFbscAAAAAgAGBJS4BAAAAAAAAAACAFKKgAwAAAAAAAAAAAFKIgg4AAAAAAAAAAABIIQo6AAAAAECPReJh1YV3qD3W4nYUAAAAAEg7XrcDAAAAAADSS2u0Qe/V/FUxJyIjo4lFJ6okOMztWAAAAACQNphBBwAAAADokR2taxRzopIkR462NC9zNxAAAAAApBkKOgAAAABAjxjj6TK25NnPmQAAAACAfaGgAwAAAAD0yLCciQp4siRJHuPV6PyZLicCAAAAgPTCHnQAAAAAgB4JerI1u+wstceaFfBky2v53I4EAAAAAGmFgg4AAAAA0GOW8SjbV+B2DAAAAABISyxxCQAAAAAAAAAAAKQQBR0AAAAAAAAAAACQQhR0AAAAAAAAAAAAQApR0AEAAAAAAAAAAAApREEHAAAAAAAAAAAApBAFHQAAAAAAAAAAAJBCXrcDAAAAAAD6j4aO3WqKVCvPX6qCQIXbcQAAAAAgI1HQAQAAAAAkSdXtW7S6/rXEeELh8SoPjXQxEQAAAABkJpa4BAAAAIAM5TiOGjqqVBfeIduJH/T8qrYNnxqv76toAAAAADCgMYMOAAAAADLU2oY3VdW+UZKU5yvR1JJTZBnPfs8PeLIlGUmOJPPRGAAAAACQbMygAwAAAIAM1BFvS5RzktQUrVFDR9UBrxmZO035/lIZGeX5SjQqd3pfxwQAAACAAYkZdAAAAACQgcw+vo95oNlzkuT3BDWt5At9FQkAAAAA8BFm0AEAAABAP+U4jpqjtWqMVMtx7B5d6/cENSpvRmJcERqtfH95siMCAAAAAA4BM+gAAAAAoJ9a37hIO9vWSpIK/YM0qfhzskz3v2c5POcIVYTGyFGc/eQAAAAAoB9hBh0AAAAA9EMd8dZEOSdJ9ZFdaozs7vF9/J4g5RwAAAAA9DMUdAAAAADQL3327ZqRcSEHAAAAACDZKOgAAAAAoB8KeEIakTM5MS4NjmAPOQAAAADIEOxBBwAAAAD91Mi8aarIGivbiSvLmydjmEEHAAAAAJmAgg4AAAAA+rGQN8eV5+5sXacPW96Xx/g0ruAo5fvLXMkBAAAAAJmIJS4BAAAAAF00R2q1rvEtheMtao3V6/3al2U7cbdjAQAAAEDGoKADAAAAAHTRFm/qMo45EUXtiEtpAAAAACDzUNABAAAAALoo8JfLY3ySjCSjXF+x/FbQ7VgAAAAA0C/Ytq1bb71Vxx13nKZOnaqLLrpI27Zt69E9KOgAAAAAAF0EPFmaXnKahmZPUGXuZE0uPlnGGLdjAQAAAEC/cMcdd+ihhx7S9ddfr0ceeUS2bevCCy9UJNL9lUco6AAAAAAAn5Hty9eY/FmqzJ0qn+V3Ow4AAAAA9AuRSET33XefLrnkEs2dO1fjx4/XTTfdpKqqKv3tb3/r9n0o6AAAAAAAAAAAAIBu+OCDD9Ta2qqjjz46cSwvL0+HH364Fi9e3O37ePsiHAAAAAAAAAAAANBf7dq1S/Pnz9/v6y+//PI+j1dVVUmSBg0a1OV4WVlZ4rXuYAYdAAAAAAAAAAAA0A3t7e2SJL+/61YAgUBAHR0d3b4PM+gAAAAAAAAAAAAwoAwaNGi/s+QOJBgMSurci27vz5LU0dGhUCjU7fswgw4AAAAAAAAAAADohr1LW1ZXV3c5Xl1drfLy8m7fh4IOAAAAAAAAAAAA6Ibx48crJydHixYtShxramrS6tWrNWvWrG7fhyUuAQAAAAAAAAAAgG7w+/0677zztGDBAhUVFWnIkCH61a9+pYqKCp188sndvg8FHQAAAAAAAAAAANBNl1xyiWKxmK6++mqFw2HNmjVL9957r3w+X7fvQUEHAAAAAANcdfsWbWxcIsnR6PyZKguNdDsSAAAAAPRbHo9Hl19+uS6//PJDvgd70AEAAADAANYRb9Oa+tfVYbeqw27T6vp/KBxvdTsWAAAAAGQ0CjoAAAAAGMA64m1y5HziiKMOCjoAAAAA6FMUdAAAAAAwgGX7ChX05EoykoyCnhzleIsO+X6O48h27KTlAwAAAIBMxB50AAAAADCAeYxH00tO1c62tZKkwVnj5LEO7a1iXXiHVte/rpgTUUVojA4rmCNjTDLjAgAAAEBGoKADAAAAgAHO7wmqMndKr+7hOE6inJOkqvYNKg4OVWloRDIiAgAAAEBGYYlLAAAAAECvOXIS5dxeETvsUhoAAAAA6N8o6AAAAAAAvWYZS4OyxiXGPiugkuAwFxMBAAAAQP/FEpcAAAAAgEPSGKlWdfsWBT3ZGpI9XuPyj1JRYLCidljFweEKeEJuRwQAAACAfomCDgAAAADwGR3xVm1rWS1HjoZkj1eWN6/L602RGr1X84KMOpe3bOzYrYlFc9lzDgAAAAC6gSUuAQAAAABd2E5c79W8oO2ta7Sj9QMt3fO8onZHl3PqOnZI6iznJKmmY5sW7/mLInH2nQMAAACAg6GgAwAAAAB00RZrUjjeIsmR5CjmdKglWtflnM4Zdc6nrmvU9tbVKcsJAAAAAOmKgg4AAAAA0EXAky3LfLwjgpFRyJPb5ZzSYKWGZB3+qSsdxZ1YChICAAAAQHqjoAMAAAAAdOGz/JpUNF85viJlews1sWiugt6cLucYYyTjfObawVmHpSomAAAAAKQt78FPAQAAAAAMNIWBCs0sPeOA59hOXJLR3qUus70Fyvbl9304AAAAAEhzzKADAAAAABySodnj5floKUwjo5G501xOBAAAAADpgRl0AAAAAIBDku0r1Oyys9QcrVWWN08hb57bkQAAAAAgLVDQAQAAAAAOmd8TUrFnqNsxAAAAACCtUNABAAAAAA7IcRzVR3apI96qosAQBTxZbkcCAAAAgLRGQQcAAAAAOKCtLcu1pXm5JMlr/JpRerpC3lyXUwEAAABA+rLcDgAAAAAA6N+2taxO/Bxzoqpu33zA8x3HVnusWXE71tfRAAAAACAtMYMOAAAAAHBAXsuveDz60ciR1wrs99yoHdaymoVqjTXIY3yaVDRPBYGK1AQFAAAAgDTBDDoAAAAAwAFNKDhWXuOXJBUHhmlQ1pj9nru9ZY1aY42SpLgT1frGd1KSEQAAAADSCTPoAAAAAAAHVBCo0DEVX1Pcictr+Q54ru3EPzVmmUsAAAAA+DRm0AEAAAAADsoY66DlnCQNyh4nr/n4vBG5U/oyFgAAAACkJWbQAQAAAACSJsubpyPLzlJTtFohT56yfQVuRwIAAACAfoeCDgAAAACQVH5PUCWe4W7HAAAAAIB+iyUuAQAAAAAAAAAAgBSioAMAAAAAAAAAAABSiIIOAAAAAAAAAAAASCEKOgAAAAAAAAAAACCFKOgAAAAAAAAAAACAFKKgAwAAAAAAAAAAAFKIgg4AAAAAAAAAAABIIQo6AAAAAAAAAAAAIIUo6AAAAAAAAAAAAIAUoqADAAAAAAAAAAAAUqhXBd1dd92l888/P1lZAAAAAAAAAAAAgIx3yAXdgw8+qJtvvjmJUQAAAAAAAAAAAIDM5+3pBbt379a1116rRYsWqbKysg8iAQAAAAAAAAAAAJmrxzPoVq1aJZ/Pp2eeeUZTpkzpi0wAAAAAAAAAAABAxurxDLp58+Zp3rx5fZEFAAAAAAAAAAAAyHiHvAcdAAAAAAAAAAAAgJ6joAMAAAAAAAAAAABSiIIOAAAAAAAAAAAASCEKOgAAAAAAAAAAACCFKOgAAAAAAAAAAACAFKKgAwAAAAAAAAAAAFLI25uLb7jhhmTlAAAAAAAAAAAAAAYEZtABAAAAAAAAAAAAKURBBwAAAAAAAAAAAKRQr5a47K3q6mrF43HNnz/fzRgAAAAAAAAAAKAf2LVrlzwej9sxBrwmb1y/rdzldow+0+SNK9flDK4WdIFAQJFIxM0IAAAAAAAAAACgn/B6vfL7/W7HGNAGDRrkdoQ+lyv3/5zGcRzH1QQAAAAAAAAAAADAAMIedAAAAAAAAAAAAEAKUdABAAAAAAAAAAAAKURBBwAAAAAAAAAAAKQQBR0AAAAAAAAAAACQQhR0AAAAAAAAAAAAQApR0AEAAAAAAAAAAAApREEHAAAAAAAAAAAApBAFHQAAAAAAAAAAAJBCFHQAAAAAAAAAAABAClHQAQAAAAAAAAAAAClEQQcAAAAAAAAAAACkEAUdAAAAAAAAAAAAkEIZW9DZtq1bb71Vxx13nKZOnaqLLrpI27ZtczsWgAzS0NCga665Rscff7ymT5+uc845R0uWLHE7FoAMtnnzZk2bNk1PPvmk21EAZKCnn35ap556qiZNmqTTTjtNf/3rX92OBCDDxGIx3XLLLTrxxBM1bdo0nXvuuVq2bJnbsQBkkLvuukvnn39+l2Nr1qzReeedp6lTp2revHn6wx/+4FI6AOgqYwu6O+64Qw899JCuv/56PfLII7JtWxdeeKEikYjb0QBkiEsvvVTvvfeefv3rX+uJJ57QhAkTdMEFF2jTpk1uRwOQgaLRqC677DK1tbW5HQVABvrzn/+sq666Sueee66ee+45nX766Yl/6wBAsvz2t7/V448/ruuvv15PP/20Ro4cqQsvvFDV1dVuRwOQAR588EHdfPPNXY7V19fr3/7t3zR8+HA98cQT+o//+A8tWLBATzzxhDshAeATMrKgi0Qiuu+++3TJJZdo7ty5Gj9+vG666SZVVVXpb3/7m9vxAGSArVu36s0339R1112nmTNnauTIkfrJT36isrIy/eUvf3E7HoAMdNtttyknJ8ftGAAykOM4uuWWW/SNb3xD5557roYPH67vfOc7mjNnjt555x234wHIIC+99JJOP/10HXvssRoxYoR+/OMfq7m5mVl0AHpl9+7duvjii7VgwQJVVlZ2ee2xxx6Tz+fTz372M40ePVpnn322vvWtb+nuu+92JywAfEJGFnQffPCBWltbdfTRRyeO5eXl6fDDD9fixYtdTAYgUxQWFuruu+/WpEmTEseMMTLGqKmpycVkADLR4sWL9eijj+qGG25wOwqADLR582bt2LFDZ5xxRpfj9957r7797W+7lApAJiouLtbf//53bd++XfF4XI8++qj8fr/Gjx/vdjQAaWzVqlXy+Xx65plnNGXKlC6vLVmyREceeaS8Xm/i2FFHHaUtW7aopqYm1VEBoIuMLOiqqqokSYMGDepyvKysLPEaAPRGXl6eTjjhBPn9/sSxhQsXauvWrTruuONcTAYg0zQ1NelHP/qRrr766s/82wYAkmHz5s2SpLa2Nl1wwQU6+uij9ZWvfEWvvPKKy8kAZJqrrrpKPp9P8+fP16RJk3TTTTfp1ltv1fDhw92OBiCNzZs3T7fddpuGDRv2mdeqqqpUUVHR5VhZWZkkadeuXSnJBwD7k5EFXXt7uyR1+eBckgKBgDo6OtyIBCDDLV26VFdeeaVOPvlkzZ071+04ADLIddddp2nTpn1mZgsAJEtLS4sk6YorrtDpp5+u++67T8ccc4y++93v6q233nI5HYBMsmHDBuXm5ur222/Xo48+qi9/+cu67LLLtGbNGrejAchQ4XB4n58RS+JzYgCu8x78lPQTDAYlde5Ft/dnqfOXbigUcisWgAz10ksv6bLLLtP06dO1YMECt+MAyCBPP/20lixZwt6WAPqUz+eTJF1wwQU666yzJEkTJkzQ6tWr9bvf/a7L1gEAcKh27dqlH/7wh7r//vs1c+ZMSdKkSZO0YcMG3XbbbbrjjjtcTgggEwWDQUUikS7H9hZzWVlZbkQCgISMnEG3d/mn6urqLserq6tVXl7uRiQAGeqBBx7Q97//fZ144om68847E9/CAoBkeOKJJ1RbW6u5c+dq2rRpmjZtmiTp2muv1YUXXuhyOgCZYu97pHHjxnU5PmbMGG3fvt2NSAAy0PLlyxWNRrvs4y1JU6ZM0datW11KBSDTVVRU7PMzYkl8TgzAdRk5g278+PHKycnRokWLEuuYNzU1afXq1TrvvPNcTgcgUzz00EO6/vrrdf755+uqq66SMcbtSAAyzIIFCxQOh7scO/nkk3XJJZfozDPPdCkVgEwzceJEZWdna/ny5YlZLZK0bt069oUCkDR794Bau3atJk+enDi+bt06VVZWupQKQKabNWuWHnnkEcXjcXk8HknS22+/rZEjR6q4uNjldAAGuows6Px+v8477zwtWLBARUVFGjJkiH71q1+poqJCJ598stvxAGSAzZs36xe/+IVOOukkffvb31ZNTU3itWAwqNzcXBfTAcgU+/tGZ3FxMd/2BJA0wWBQF154oW6//XaVl5dr8uTJeu655/Tmm2/q/vvvdzsegAwxefJkzZgxQ1dccYWuvfZaVVRU6Omnn9Zbb72lhx9+2O14ADLU2WefrXvuuUdXXXWVLrzwQq1YsUL333+/fvrTn7odDQAys6CTpEsuuUSxWExXX321wuGwZs2apXvvvTexvwIA9MbChQsVjUb14osv6sUXX+zy2llnnaUbbrjBpWQAAAA9993vflehUEg33XSTdu/erdGjR+u2227T7Nmz3Y4GIENYlqXf/va3uvnmm3XllVeqsbFR48aN0/33368pU6a4HQ9AhiouLtY999yjn//85zrrrLNUWlqqH/3oR4l9dwHATcZxHMftEAAAAAAAAAAAAMBAYbkdAAAAAAAAAAAAABhIKOgAAAAAAAAAAACAFKKgAwAAAAAAAAAAAFKIgg4AAAAAAAAAAABIIQo6AAAAAAAAAAAAIIUo6AAAAAAAAAAAAIAUoqADAAAAAAAAAAAAUoiCDgAAAAAAAAAAAEghCjoAAAAAAAAAAAAghSjoAAAAAAAAAAAAgBSioAMAAAAAAAAAAABS6P8DcWP5Ku24/QkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 2500x1500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_latent_dim(net, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d43aa18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train[0/2][0/938] Loss: 0.2412574291229248\n",
      "Train[0/2][1/938] Loss: 0.2353697419166565\n",
      "Train[0/2][2/938] Loss: 0.23845350742340088\n",
      "Train[0/2][3/938] Loss: 0.23043055832386017\n",
      "Train[0/2][4/938] Loss: 0.22870972752571106\n",
      "Train[0/2][5/938] Loss: 0.230546772480011\n",
      "Train[0/2][6/938] Loss: 0.2346862107515335\n",
      "Train[0/2][7/938] Loss: 0.23500317335128784\n",
      "Train[0/2][8/938] Loss: 0.23437409102916718\n",
      "Train[0/2][9/938] Loss: 0.24121591448783875\n",
      "Train[1/2][0/938] Loss: 0.22867894172668457\n",
      "Train[1/2][1/938] Loss: 0.2302873283624649\n",
      "Train[1/2][2/938] Loss: 0.23779545724391937\n",
      "Train[1/2][3/938] Loss: 0.22321262955665588\n",
      "Train[1/2][4/938] Loss: 0.2212371677160263\n",
      "Train[1/2][5/938] Loss: 0.23417195677757263\n",
      "Train[1/2][6/938] Loss: 0.227905735373497\n",
      "Train[1/2][7/938] Loss: 0.23197801411151886\n",
      "Train[1/2][8/938] Loss: 0.22612155973911285\n",
      "Train[1/2][9/938] Loss: 0.2296372354030609\n"
     ]
    }
   ],
   "source": [
    "# Profiler setup\n",
    "my_schedule = schedule(skip_first=0, wait=1, warmup=1, active=2, repeat=2)\n",
    "my_schedule = schedule(skip_first=0, wait=1, warmup=1, active=2, repeat=2)\n",
    "\n",
    "def trace_handler(p):\n",
    "    output = p.key_averages().table(sort_by=\"self_cuda_time_total\", row_limit=50)\n",
    "    print(output)\n",
    "    p.export_chrome_trace(base_path + \"/tmp/trace_\" + str(p.step_num) + \".json\")\n",
    "\n",
    "# Run training with profiler\n",
    "#with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], profile_memory=True, record_shapes=True,\n",
    "#    schedule=my_schedule, on_trace_ready=trace_handler) as p:\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], profile_memory=True, record_shapes=True) as prof:\n",
    "\n",
    "    train_loss = net.train_net(train_loader, optimizer, max_batch, start_epoch, max_epoch, save_output=False, save_model=False)\n",
    "    #test_loss = net.test_net(train_loader, max_batch, start_epoch, max_epoch, save_output=False)\n",
    "    \n",
    "# Show\n",
    "print(prof.key_averages(group_by_input_shape=True).table(sort_by=\"cuda_time_total\", row_limit=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ad63249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU used: 310320640/2729745408\n"
     ]
    }
   ],
   "source": [
    "print(f'GPU used: {torch.cuda.memory_allocated()}/{torch.cuda.max_memory_allocated()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fc693d",
   "metadata": {},
   "source": [
    "### Show animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a64e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.12174132466316223\n"
     ]
    }
   ],
   "source": [
    "# Define Network and optimizer\n",
    "net = SAE_3Dconv()\n",
    "net = net.to(device)\n",
    "load_epoch = 19\n",
    "image_nr = 1\n",
    "\n",
    "# Load model\n",
    "net.load_state_dict(torch.load(base_path + f'models/epoch{load_epoch}.pth'))\n",
    "\n",
    "net = net.eval()\n",
    "for batch_idx, (real_img, labels) in enumerate(train_loader):\n",
    "    \n",
    "    real_img = real_img.permute(0, 2, 1, 3, 4).to(device) # Swap channel and depth pos\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    #Pass data into network, and return reconstructed image from Membrane Potential at t = -1\n",
    "    with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], profile_memory=True, record_shapes=True) as prof:\n",
    "        with record_function(\"model_inference\"):\n",
    "            #model(inputs)\n",
    "            x_recon = net(real_img) #Dimensions passed in: [Batch_size, Channels, Image_Depth, Image_Height, Image_Width]\n",
    "    \n",
    "    #Calculate loss\n",
    "    loss = F.mse_loss(x_recon, real_img)            \n",
    "    print(f'Loss: {loss.item()}')\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91372345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
      "                                 Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls                                                                      Input Shapes  \n",
      "-------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
      "                      model_inference         6.47%      14.230ms       100.00%     220.018ms     220.018ms       3.862ms         1.76%     219.375ms     219.375ms           0 b           0 b     506.04 Mb    -830.07 Mb             1                                                                                []  \n",
      "                         aten::conv3d         0.00%       9.000us         0.13%     280.000us     280.000us       4.000us         0.00%      43.915ms      43.915ms           0 b           0 b      32.00 Mb           0 b             1                     [[64, 2, 32, 32, 32], [32, 2, 3, 3, 3], [32], [], [], [], []]  \n",
      "                    aten::convolution         0.01%      23.000us         0.12%     271.000us     271.000us       4.000us         0.00%      43.911ms      43.911ms           0 b           0 b      32.00 Mb           0 b             1             [[64, 2, 32, 32, 32], [32, 2, 3, 3, 3], [32], [], [], [], [], [], []]  \n",
      "                   aten::_convolution         0.02%      34.000us         0.11%     248.000us     248.000us      14.000us         0.01%      43.907ms      43.907ms           0 b           0 b      32.00 Mb     -16.00 Mb             1  [[64, 2, 32, 32, 32], [32, 2, 3, 3, 3], [32], [], [], [], [], [], [], [], [], []  \n",
      "              aten::cudnn_convolution         0.06%     130.000us         0.06%     130.000us     130.000us      36.915ms        16.83%      36.915ms      36.915ms           0 b           0 b      32.00 Mb      32.00 Mb             1               [[64, 2, 32, 32, 32], [32, 2, 3, 3, 3], [], [], [], [], [], [], []]  \n",
      "                     aten::is_nonzero         0.02%      51.000us        84.43%     185.764ms      20.640ms      32.000us         0.01%      24.644ms       2.738ms           0 b           0 b           0 b           0 b             9                                                                              [[]]  \n",
      "                           aten::item         0.06%     142.000us        84.41%     185.713ms      20.635ms      44.000us         0.02%      24.612ms       2.735ms           0 b           0 b           0 b           0 b             9                                                                              [[]]  \n",
      "            aten::_local_scalar_dense        84.34%     185.571ms        84.34%     185.571ms      20.619ms      24.568ms        11.20%      24.568ms       2.730ms           0 b           0 b           0 b           0 b             9                                                                              [[]]  \n",
      "                                 ATan         0.10%     216.000us         0.58%       1.278ms     319.500us      25.000us         0.01%      21.228ms       5.307ms           0 b           0 b     128.00 Mb     -32.00 Mb             4                                                            [[64, 32, 16, 16, 16]]  \n",
      "                          aten::copy_         0.06%     123.000us         0.06%     123.000us      20.500us      17.606ms         8.03%      17.606ms       2.934ms           0 b           0 b           0 b           0 b             6                                  [[64, 32, 16, 16, 16], [64, 32, 16, 16, 16], []]  \n",
      "                         aten::conv3d         0.01%      14.000us         0.17%     374.000us     374.000us       4.000us         0.00%      14.263ms      14.263ms           0 b           0 b       8.00 Mb           0 b             1                   [[64, 32, 16, 16, 16], [64, 32, 3, 3, 3], [64], [], [], [], []]  \n",
      "                    aten::convolution         0.01%      27.000us         0.16%     360.000us     360.000us       4.000us         0.00%      14.259ms      14.259ms           0 b           0 b       8.00 Mb           0 b             1           [[64, 32, 16, 16, 16], [64, 32, 3, 3, 3], [64], [], [], [], [], [], []]  \n",
      "                   aten::_convolution         0.02%      48.000us         0.15%     333.000us     333.000us      10.000us         0.00%      14.255ms      14.255ms           0 b           0 b       8.00 Mb           0 b             1  [[64, 32, 16, 16, 16], [64, 32, 3, 3, 3], [64], [], [], [], [], [], [], [], [],   \n",
      "                             aten::to         0.01%      25.000us         0.44%     962.000us     240.500us      12.000us         0.01%      13.530ms       3.382ms           0 b           0 b     128.00 Mb           0 b             4                                            [[64, 32, 16, 16, 16], [], [], [], []]  \n",
      "                       aten::_to_copy         0.05%     103.000us         0.43%     937.000us     234.250us      19.000us         0.01%      13.518ms       3.380ms           0 b           0 b     128.00 Mb           0 b             4                                    [[64, 32, 16, 16, 16], [], [], [], [], [], []]  \n",
      "              aten::cudnn_convolution         0.12%     256.000us         0.12%     256.000us     256.000us      13.281ms         6.05%      13.281ms      13.281ms           0 b           0 b       8.00 Mb       8.00 Mb             1             [[64, 32, 16, 16, 16], [64, 32, 3, 3, 3], [], [], [], [], [], [], []]  \n",
      "                            aten::mul         0.29%     635.000us         0.29%     635.000us     158.750us      12.450ms         5.68%      12.450ms       3.112ms           0 b           0 b     128.00 Mb     128.00 Mb             4                                                        [[64, 32, 16, 16, 16], []]  \n",
      "                            aten::sub         0.57%       1.262ms         0.57%       1.262ms     315.500us      12.000ms         5.47%      12.000ms       3.000ms           0 b           0 b     128.00 Mb     128.00 Mb             4                                                    [[64, 32, 16, 16, 16], [], []]  \n",
      "                          aten::copy_         0.04%      79.000us         0.04%      79.000us      13.167us       8.244ms         3.76%       8.244ms       1.374ms           0 b           0 b           0 b           0 b             6                                        [[64, 64, 8, 8, 8], [64, 64, 8, 8, 8], []]  \n",
      "                            aten::sub         0.25%     547.000us         0.25%     547.000us     273.500us       8.240ms         3.76%       8.240ms       4.120ms           0 b           0 b      64.00 Mb      64.00 Mb             2                                  [[64, 32, 16, 16, 16], [64, 32, 16, 16, 16], []]  \n",
      "                     aten::batch_norm         0.01%      12.000us         0.30%     667.000us     333.500us       7.000us         0.00%       8.062ms       4.031ms           0 b           0 b      64.00 Mb           0 b             2                    [[64, 32, 16, 16, 16], [32], [32], [32], [32], [], [], [], []]  \n",
      "         aten::_batch_norm_impl_index         0.01%      31.000us         0.30%     655.000us     327.500us       6.000us         0.00%       8.055ms       4.027ms           0 b           0 b      64.00 Mb           0 b             2                    [[64, 32, 16, 16, 16], [32], [32], [32], [32], [], [], [], []]  \n",
      "               aten::cudnn_batch_norm         0.11%     244.000us         0.28%     624.000us     312.000us       8.027ms         3.66%       8.049ms       4.024ms           0 b           0 b      64.00 Mb           0 b             2                        [[64, 32, 16, 16, 16], [32], [32], [32], [32], [], [], []]  \n",
      "                             aten::gt         0.05%     100.000us         0.05%     100.000us      25.000us       7.673ms         3.50%       7.673ms       1.918ms           0 b           0 b      32.00 Mb      32.00 Mb             4                                                        [[64, 32, 16, 16, 16], []]  \n",
      "                            aten::mul         0.03%      69.000us         0.03%      69.000us      34.500us       7.217ms         3.29%       7.217ms       3.608ms           0 b           0 b      64.00 Mb      64.00 Mb             2                                                        [[], [64, 32, 16, 16, 16]]  \n",
      "                                 ATan         0.08%     176.000us         0.20%     433.000us     108.250us      21.000us         0.01%       6.552ms       1.638ms           0 b           0 b      32.00 Mb      -8.00 Mb             4                                                               [[64, 64, 8, 8, 8]]  \n",
      "                            aten::add         0.02%      34.000us         0.02%      34.000us      17.000us       5.641ms         2.57%       5.641ms       2.821ms           0 b           0 b      64.00 Mb      64.00 Mb             2                                  [[64, 32, 16, 16, 16], [64, 32, 16, 16, 16], []]  \n",
      "                        aten::detach_         0.72%       1.587ms         0.72%       1.593ms       3.471us       4.362ms         1.99%       5.358ms      11.673us           0 b           0 b           0 b           0 b           459                                                                             [[0]]  \n",
      "                            aten::mul         0.04%      78.000us         0.04%      78.000us      19.500us       4.647ms         2.12%       4.647ms       1.162ms           0 b           0 b      32.00 Mb      32.00 Mb             4                                                           [[64, 64, 8, 8, 8], []]  \n",
      "                          aten::clone         0.02%      35.000us         0.03%      75.000us      37.500us       9.000us         0.00%       4.385ms       2.192ms           0 b           0 b      16.00 Mb           0 b             2                                                           [[64, 64, 8, 8, 8], []]  \n",
      "-------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
      "Self CPU time total: 220.018ms\n",
      "Self CUDA time total: 219.375ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show\n",
    "print(prof.key_averages(group_by_input_shape=True).table(sort_by=\"cuda_time_total\", row_limit=30))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
